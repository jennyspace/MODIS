{
 "metadata": {
  "name": "",
  "signature": "sha256:d93dfeacba9c0ef91bc9663962324828ae3df4006320a3bf596d6e497b128d5e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Apply SODA at 14th/Dec\n",
      "### Upgrading at 7th/Sep\n",
      "### ALL 5th/Sep/2016 --------------------------------------------------------"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### what this should do is ---- plot tracks and cal reff to plot reff of MODIS and aircraft\n",
      "#1. get Sync_sec \n",
      "#2. Decide Target_st_sec, Target_end_sec\n",
      "#3. get df & df_clouds              ### input(Target_st_sec, Target_end_sec), output(df, df_clouds)\n",
      "#2. get Target coordinates          ### input(target_st_time, target_end_time) output(target_coordinates)\n",
      "#4. plot flight track (green & red) ### Green: whole track during the target time (get all df), Red: cloud track\n",
      "                                    ### input(df,df_clouds ), output(None)\n",
      "#5. Cal ac avg                      ### input(df_clouds) output(reff, etc)\n",
      "#6. Cal MODIS avg                   ### input (target_coordinates) output(reff, etc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### 1. GetSyncSec: to get Synchronized time between aircraft ad MODIS\n",
      "def GetSyncSec (AC_st_time, MODIS_time):\n",
      "    Start_sec = int(AC_st_time[0:2])*3600 + int(AC_st_time[2:4])*60 + int(AC_st_time[4:6])\n",
      "    MODIS_time_local_sec = (int(MODIS_time[0:2])+10)*3600 + int(MODIS_time[2:4])*60 + int(MODIS_time[5:6])*6 ### seconds\n",
      "    Sync_sec = MODIS_time_local_sec - Start_sec ### Synchronized time between aircraft ad MODIS\n",
      "    print \"Sync_sec : \", Sync_sec \n",
      "    \n",
      "    return Sync_sec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### 2. Decide the target start and end time\n",
      "def GetTargetSecs(FDate, Sync_sec):\n",
      "    '''\n",
      "    1) Exact time: Target_secs (6km)\n",
      "    2) +- 2 ms = Target_secs + 2*60 (12km)\n",
      "    3) +- 5 ms = Target_secs + 5*60 (30km)\n",
      "    4) +- 10 ms = Target_secs + 10*60 (60km)\n",
      "    '''\n",
      "    if FDate == \"20130614_133658\" :  ### for this flight, there is no clouds during MODIS overpass so decided 20 mis plus\n",
      "        Target_st_sec = Sync_sec   \n",
      "        Target_end_sec = Sync_sec + 20*60\n",
      "    else: \n",
      "        Target_st_sec = Sync_sec - 10*60  \n",
      "        Target_end_sec = Sync_sec + 10*60  ### 10 mis plus after MODIS overpass\n",
      "    \n",
      "    return Target_st_sec, Target_end_sec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Part of 3. ---------------------------------------------------------------------------------------------------\n",
      "### Be careful, this one doesn't matter in or base of clouds!\n",
      "def Query_forCloud(C_Flag):\n",
      "    if C_Flag == 'Liq':\n",
      "        ### set CIPFirstBin = 3 for clouds \n",
      "        #query_cloud ='(TWC156>0.01) & (LWCC+(LWCCIP-CIPLWC_Drizzle))>0.01 & (TWC156>LWC083)'  \n",
      "        query_cloud ='(TWC156>0.01) & (TWC156>LWC083)' ### include cloud base and top\n",
      "    elif C_Flag == 'ND':\n",
      "        query_cloud ='(TWC156>0.01) & (LWCC+(LWCCIP-CIPLWC_Drizzle))>0.01 & (TWC156>LWC083) & (CIPLWC_Drizzle<0.005)'\n",
      "    elif C_Flag == 'D':\n",
      "        ### Dizzling clouds,(LWCC+(LWCCIP-CIPLWC_Drizzle))>0.005: for excluding cloud over and below\n",
      "        ### CIPLWC_Drizzle ( >= 112.5) >= 0.005: is too low of drizzle         \n",
      "        query_cloud ='(TWC156>0.01) & (LWCC+(LWCCIP-CIPLWC_Drizzle))>0.01 & (TWC156>LWC083) & (CIPLWC_Drizzle>=0.005)'\n",
      "    return query_cloud"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### Part of 3 ----------------------------------------------------------------------------------------------\n",
      "def FirstMethod(ncname, FType, F_Desc, SP, query1, query2, slope):\n",
      "\n",
      "    import numpy as np\n",
      "    import netCDF4\n",
      "    import pandas as pd\n",
      "    \n",
      "    ncfile = netCDF4.Dataset(ncname)\n",
      "\n",
      "### Sampling ###########################################################\n",
      "    Range_List = [0]*len(SP) \n",
      "    SamplingPeriod = [0]*len(SP)\n",
      "    for i in range(len(SP)):\n",
      "        Range_List[i] = range(SP[i][0],SP[i][1])\n",
      "        SamplingPeriod[i] = (SP[i][1]-SP[i][0])\n",
      "\n",
      "##############################################################################################################################\n",
      "    # For Spectra, Effective Radius #####################################################\n",
      "    # This is for calculating the range of the bins \n",
      "    # the numbers of the array(CellSize) is the detectable minimum size(detectable starting point in the bin) \n",
      "\n",
      "    Dp = ncfile.groups[\"CAS\"].variables['ForwardCounts_CAS'].getncattr('CellSizes')\n",
      "        # Dp = Diameter of a particle detected in the bin = bin size\n",
      "    Dp = np.append(Dp,50)  ### inserting the size of the last bin maximum, so len(Dp)=31, len(Rp)=30\n",
      "\n",
      "    Rp = [0.]*30         ### Number of bins ###\n",
      "    for i in range(30):\n",
      "        Rp[i] = np.sqrt([Dp[i]*Dp[i+1]])*.5   ### geometric mean r in n*r^3/n*r^2 ###\n",
      "\n",
      "    CIPLastBin = 33 ### So, CIPLastBin = 30 in CAS !!! ######################\n",
      "    CIPDrizzleBin = 5 ### For discriminating drizzle ( > 112.5 microns) clouds' LWCCIP > 0.01 \n",
      "    Dp_CIP = ncfile.groups[\"CIP\"].variables['CountsPerBin_CIP'].getncattr('CellSizes')[0:CIPLastBin] ##len(Dp_CIP) = 34\n",
      "    Dp_CIP = np.append(Dp_CIP,837.5)\n",
      "        # Dp = Diameter of a particle detected in the bin = bin size\n",
      "    #Dp_CIP=np.append(Dp_CIP,1562.5)  ### inserting the size of the last bin maximum ###\n",
      "                                     ### the last bin should be deleted for plot to make the array size the same ###\n",
      "    \n",
      "    Rp_CIP = [0.]*(CIPLastBin)  \n",
      "    for i in range(CIPLastBin):\n",
      "        Rp_CIP[i] = np.sqrt([Dp_CIP[i]*Dp_CIP[i+1]])*.5   ### geometric mean r in n*r^3/n*r^2 ###\n",
      "    '''\n",
      "    For 2013 flights (no Korolev tips)\n",
      "    CellSizes [   12.5    37.5    62.5    87.5   112.5   137.5   162.5   187.5   212.5    237.5   \n",
      "                  262.5   287.5   312.5   337.5   362.5   387.5   412.5   437.5  462.5   487.5   \n",
      "                  512.5   537.5   562.5   587.5   612.5   637.5   662.5   687.5   712.5   737.5  \n",
      "                  762.5   787.5   812.5   837.5   862.5   887.5   912.5   937.5   962.5   987.5  \n",
      "                  1012.5  1037.5  1062.5  1087.5  1112.5  1137.5  1162.5  1187.5  1212.5  1237.5  \n",
      "                  1262.5  1287.5  1312.5  1337.5  1362.5  1387.5  1412.5  1437.5  1462.5  1487.5  \n",
      "                  1512.5  1537.5]\n",
      "  '''               \n",
      "##############################################################################################################################\n",
      "    ### To produce basic MP except Reff for the whole sampling duration (RL) ################\n",
      "    ### Reff will be calcuated after filtering the condition ################################\n",
      "    \n",
      "    RL = Range_List[0] ### RL = the list of sampling duration ([time_start, ... .., time_end])\n",
      "\n",
      "    long1 = ncfile.groups[\"OEM4\"].variables[\"Longitude\"][RL]\n",
      "    lat1 = ncfile.groups[\"OEM4\"].variables[\"Latitude\"][RL]#[LWC_CAS > 0.01] This part has gone to the later part\n",
      "\n",
      "    PStat = ncfile.groups[\"AirState\"].variables[\"StaticPress_Fuselage\"][RL]  \n",
      "    PA_FuseOEM = ncfile.groups[\"AirState\"].variables[\"PressureAltitudeCorrected_Fuselage\"][RL]#[LWC_CAS >0.01]\n",
      "    PA_Shadin = ncfile.groups[\"Shadin\"].variables[\"PressAltitude\"][RL]\n",
      "    TStat = ncfile.groups[\"AirState\"].variables[\"AmbientTemp_TP3S\"][RL]\n",
      "\n",
      "    CDNC_Clouds= ncfile.groups[\"CAS\"].variables[\"ForwardTotalConc_CAS\"][RL]\n",
      "    LWC_CAS= ncfile.groups[\"CAS\"].variables[\"LWC_CAS\"][RL]\n",
      "    LWCHotWire=ncfile.groups[\"CAS\"].variables[\"LWCHotWire_CAS\"][RL]\n",
      "\n",
      "    PLWC021= ncfile.groups[\"WCM\"].variables[\"PLWC021\"][RL]\n",
      "    PLWC083= ncfile.groups[\"WCM\"].variables[\"PLWC083\"][RL]\n",
      "    PTWC156 = ncfile.groups[\"WCM\"].variables[\"PTWC156\"][RL]\n",
      "\n",
      "    ### To get CIPConc &  CIPLWC = from \"3rd bin\" ~ \"where we want\" ##############################\n",
      "    #CIPTotalConc  = ncfile.groups[\"CIP\"].variables[\"TotalConc_CIP\"][RL] # This is for CIP concentration, all bins\n",
      "    CIPConc = [0.]*len(RL) ### from 3rd bin ~ 33th bin ###\n",
      "    \n",
      "    CDNC_CIP_bin = ncfile.groups[\"CIP\"].variables['Conc_CIP'][RL]  ### CDNC_CIP_bin = array (RL rows X # of bins)\n",
      "                                                                   ###             = 45?? X 62   \n",
      "    ### 11/Sep/2015 added: to get LWC_CIP (from the 3rd bin) to modify filtering option as LWC_CAS + LWC_CIP > 0.01 ###\n",
      "    CIPLWC_Drizzle = [0.]*len(RL)\n",
      "    CIPLWC = [0.]*len(RL)\n",
      "    LWC_CIP_bin = ncfile.groups[\"CIP\"].variables['LWCPerBin_CIP'][RL] ## CIP LWC, per bin\n",
      "    \n",
      "    ### CIP LWC to discriminate bigger than 112.5 microns\n",
      "    for i in range(len(RL)):\n",
      "        for j in range(CIPLastBin - CIPDrizzleBin):   ### repeat times\n",
      "             CIPLWC_Drizzle[i] += LWC_CIP_bin[i][j+CIPDrizzleBin-1]\n",
      "\n",
      "    ### for all CIP CDNC & LWC except first 2 bins\n",
      "    for i in range(len(RL)):\n",
      "        for j in range(CIPLastBin - 2):   ### repeat 31(33-3+1), CIP_Conc should exclude 1st & 2nd bin #####################\n",
      "            CIPConc[i] += CDNC_CIP_bin[i][j+2]   ### calcurate from 3rd bin ~ 32+2 = 34th bin\n",
      "                                                      ### CIPConc = only bigger drolpets > 62.5 micron\n",
      "            CIPLWC[i] += LWC_CIP_bin[i][j+2]\n",
      "    # -----------------------------------------------------------------------------------------#\n",
      "\n",
      "    MeanDia_CAS  = ncfile.groups[\"CAS\"].variables[\"MeanDia_CAS\"][RL]\n",
      "    MeanDia_CIP  = ncfile.groups[\"CIP\"].variables[\"MeanDia_CIP\"][RL]\n",
      "    Wind_Speed  = ncfile.groups[\"AirState\"].variables[\"Wind_Speed\"][RL]\n",
      "    Wind_Direction  = ncfile.groups[\"AirState\"].variables[\"Wind_Direction\"][RL]\n",
      "    TAS = ncfile.groups[\"AirState\"].variables[\"TrueAirSpeedCorrected_TP3S\"][RL]\n",
      "    CIPLWC_Allbins = ncfile.groups[\"CIP\"].variables['LWC_CIP'][RL]\n",
      "\n",
      "    time = ncfile.variables[\"Time\"][RL]\n",
      "    \n",
      "    df= pd.DataFrame({'Time' : time, 'PStat' : PStat,'PA_FO' : PA_FuseOEM,'PA_S' : PA_Shadin,\\\n",
      "                  'long1': long1,'lat1': lat1,\\\n",
      "                  'TStat': TStat,'CDNC' : CDNC_Clouds, 'LWCC': LWC_CAS, 'LWCHW' : LWCHotWire, \\\n",
      "                  'LWC021' : PLWC021, 'LWC083' : PLWC083,'TWC156' : PTWC156, \\\n",
      "                  'CIPLWC_Drizzle': CIPLWC_Drizzle, 'LWCCIP': CIPLWC, 'LWCCIP_All': CIPLWC_Allbins,\\\n",
      "                  'CIPTo' : CIPConc, 'MD': MeanDia_CAS, 'MDCIP': MeanDia_CIP, \\\n",
      "                  'W_S': Wind_Speed, 'W_D': Wind_Direction, 'TAS': TAS })\n",
      "    ###---------------------------------------------------------------------------------------###\n",
      "    \n",
      "    CDNC_bin = ncfile.groups[\"CAS\"].variables['ForwardConc_CAS'][RL] ### Range_List[0] = RL  ######\n",
      "    for m in range(30):\n",
      "        name = 'CDNC_bin'+ np.str(m)\n",
      "    #    df[name] = pd.Series( np.float(CDNC_bin[:,m]), index=df.index )\n",
      "        df[name] = pd.Series( CDNC_bin[:,m], index=df.index )\n",
      "        \n",
      "    ### Add CIP bins to df_basic ############\n",
      "    #CDNC_CIP_bin = ncfile.groups[\"CIP\"].variables['Conc_CIP'][RL] ### Range_List[0] = RL  ######\n",
      "    for m in range(CIPLastBin): ### repeat 33 (incluing 1st & 2nd bin), m:0~32\n",
      "        name = 'CDNC_CIP_bin'+ np.str(m)   ### making from 1st bin upto where we want (0~39th bin)\n",
      "    #    df[name] = pd.Series( np.float(CDNC_bin[:,m]), index=df.index )\n",
      "        df[name] = pd.Series( CDNC_CIP_bin[:,m], index=df.index )      \n",
      "        \n",
      "    ### Then, filter with query 1 ##########################################################################  \n",
      "    ### df1 = after appling 1st query ###\n",
      "    \n",
      "    if ncname == '../../../../Data/2013/nc/20130723_130219.nc':\n",
      "        df1 = df\n",
      "    else:\n",
      "    \n",
      "        df1 = df.query(query1)  ### same as df1 = df[(df.a < df.b) & (df.b < df.c)] \n",
      "                                              ### http://pandas.pydata.org/pandas-docs/dev/indexing.html\n",
      "### This is for calibration of WCM LWC083 ###       \n",
      "    offset = 1-slope ### However, offset0.45 is the best\n",
      "    df1['LWC083'] = df1['LWC083'] + offset*df1['TWC156']\n",
      "\n",
      "    beta = 0.1*1.12\n",
      "    Wi = (df1['TWC156']-df1['LWC083'])/(1.12-beta)\n",
      "    Wl = (df1['TWC156']-1.12*Wi)\n",
      "    \n",
      "    df1['Wi'] = pd.Series(Wi, index=df1.index)\n",
      "    df1['Wl'] = pd.Series(Wl, index=df1.index)\n",
      "    \n",
      "    ### process when Wi < 0   ### No zeroing needed\n",
      "    #index_minus = df1[df1['Wi'] < 0].index.tolist()\n",
      "    #df1.loc[index_minus, 'Wi'] = 0\n",
      "\n",
      "    Mew3 = df1['Wi']/(df1['Wi']+df1['Wl'])\n",
      "    df1['Mew3'] = pd.Series(Mew3, index=df1.index)    \n",
      "    \n",
      "    if ncname == '../../../../Data/2013/nc/20130723_130219.nc':\n",
      "        df1['Mew3'] = pd.Series(0, index=df1.index) \n",
      "    else:\n",
      "        df1['Mew3'] = pd.Series(Mew3, index=df1.index)  \n",
      "\n",
      "    Len_AllClouds = len(df1) ### Length of all clouds\n",
      "    \n",
      "###########################################################################################################\n",
      "#### Reff: is calculated for the index item from df1 (after filtering) #####################################\n",
      "    \n",
      "    #CDNC_bin = ncfile.groups[\"CAS\"].variables['ForwardConc_CAS'][RL] ### Range_List[0] = RL  ######\n",
      "    R_eff_Sec = [np.NaN] * len(df1.index)  ### List, only for the NECESSARY length, not len(Range_List[0]) ###\n",
      "    Child_Sec = [np.NaN] * len(df1.index)\n",
      "    Parent_Sec = [np.NaN] * len(df1.index)\n",
      "    N_bin = [0.]*30  ### total N for RL for each bin, for only Spectra\n",
      "    NoOfTime = 0   ### for only Spectra\n",
      "\n",
      "    for j in range(len(df1.index)):   ### only creates for the effective rows from df5 ###    \n",
      "        k = df1.index[j]\n",
      "        Child_Sec[j]  = 0.\n",
      "        Parent_Sec[j]  = 0.\n",
      "        for m in range(30):\n",
      "            a = np.float(CDNC_bin[k][m]*pow(Rp[m],3))      ### change array to float, otherwise ###\n",
      "                                                       ### Child_Sec[j]:array,(BUT Child_Sec: array list) ###\n",
      "            Child_Sec[j] = a + Child_Sec[j]  \n",
      "            b = np.float(CDNC_bin[k][m]*np.square(Rp[m]))\n",
      "            Parent_Sec[j] = b + Parent_Sec[j]\n",
      "            N_bin[m] += CDNC_bin[k][m]   ### For only Spectra ###\n",
      "        NoOfTime = NoOfTime +1       ### For only Spectra ###\n",
      "        if Parent_Sec[j] <> 0:       ### added on 14/Sep/2015\n",
      "            R_eff_Sec[j] = Child_Sec[j]/Parent_Sec[j]    ### This division only possible with array ###\n",
      "\n",
      "    ################## create and append the Reff row to df1 #############################################\n",
      "    df1['Reff'] = pd.Series(R_eff_Sec, index=df1.index)   \n",
      "\n",
      "###########################################################################################################\n",
      "### For Spectra (CAS) ##################################################################\n",
      "\n",
      "    #Spectrum = [0.]*31\n",
      "    Spectrum = [np.NaN]*31\n",
      "    AvgN_bin = [0.]*30\n",
      "    for i in range(30):         \n",
      "        AvgN_bin[i] = N_bin[i]/NoOfTime  ### AvgN_bin = dN\n",
      "\n",
      "    #Spectrum[0] = 0  ### for Step plot, making the y[0] = 0 ###\n",
      "    for i in range(30):\n",
      "         Spectrum[i+1] = AvgN_bin[i]/(np.log10(Dp[i+1])-np.log10(Dp[i]))  ### dN/dLogDp, dN = AvgN_bin\n",
      "    \n",
      "###########################################################################################################\n",
      "#### Reff_Total including CIP #### take 3rd bin from CIP ##################################################\n",
      "#CDNC_CIP_bin = ncfile.groups[\"CIP\"].variables['Conc_CIP'][RL] ### Range_List[0] = RL  ## CIP concentration, per bin\n",
      "    R_eff_Total_Sec = [np.NaN] * len(df1.index)  ### List, only for the NECESSARY length, not len(Range_List[0]) ###\n",
      "    Child_Sec = [np.NaN] * len(df1.index)\n",
      "    Parent_Sec = [np.NaN] * len(df1.index)\n",
      "    #N_CIP_bin = [0.]*(CIPLastBin - 2)  ### For Spectra only,All suitable CIP bin Conc ###\n",
      "    #NoOfTime = 0 ### For Spectra only,\n",
      "\n",
      "    for j in range(len(df1.index)):   ### only creates for the effective rows from df5 ###    \n",
      "        k = df1.index[j]\n",
      "        Child_Sec[j]  = 0.\n",
      "        Parent_Sec[j]  = 0.\n",
      "\n",
      "        for m in range(30):\n",
      "            a = np.float(CDNC_bin[k][m]*pow(Rp[m],3))      ### change array to float, otherwise ###\n",
      "                                                       ### Child_Sec[j]:array,(BUT Child_Sec: array list) ###\n",
      "            Child_Sec[j] = a + Child_Sec[j]  \n",
      "            b = np.float(CDNC_bin[k][m]*np.square(Rp[m]))\n",
      "            Parent_Sec[j] = b + Parent_Sec[j]\n",
      "            N_bin[m] += CDNC_bin[k][m]   ### For Spectra only ###\n",
      "\n",
      "        for m in range(CIPLastBin - 2):  ### repeat 31 times for Reff_Total, 3rd~33rd bins (33-3+1)\n",
      "            a2 = np.float(CDNC_CIP_bin[k][m+2]*pow(Rp_CIP[m+2],3))      ### change array to float, otherwise ###\n",
      "                                                       ### Child_Sec[j]:array,(BUT Child_Sec: array list) ###\n",
      "            Child_Sec[j] = a2 + Child_Sec[j]  \n",
      "            b2 = np.float(CDNC_CIP_bin[k][m+2]*np.square(Rp_CIP[m+2]))\n",
      "            Parent_Sec[j] = b2 + Parent_Sec[j]\n",
      "            #N_CIP_bin[m] += CDNC_CIP_bin[k][m+2]   ### For Spectra only, so uncomment if you want to calculate for spectra###        \n",
      "        #NoOfTime = NoOfTime +1       ### For Spectra only, so uncomment if you want to calculate for spectra ###\n",
      "        if Parent_Sec[j] <> 0:\n",
      "            R_eff_Total_Sec[j] = Child_Sec[j]/Parent_Sec[j]    ### This division only possible with array ###\n",
      "\n",
      "    ################## create and append the Reff row to df1 #############################################\n",
      "    df1['Reff_Total'] = pd.Series(R_eff_Total_Sec, index=df1.index)   \n",
      "\n",
      "#### For Spectra (CIP) ##############################################################################\n",
      "### N_CIP_bin & NoOfTime needs to calculate #########################################################\n",
      "\n",
      "#### case 1) For CIP Spectra only louds from the 3rd bin #############################################   \n",
      "#    Spectrum_CIP = [0.]*62   ### changed from 62 => 60\n",
      "#    AvgN_CIP_bin = [0.]*60\n",
      "#    for i in range(60):         \n",
      "#        AvgN_CIP_bin[i] = N_CIP_bin[i]/NoOfTime\n",
      "\n",
      "#    for i in range(60):\n",
      "#        if i == 59:\n",
      "#            Spectrum_CIP[i+2] = AvgN_CIP_bin[i]/(np.log10(1562.5)-np.log10(Dp_CIP[i+2])) ### dN/dLogDp, dN = AvgN_bin\n",
      "#        else:\n",
      "#            Spectrum_CIP[i+2] = AvgN_CIP_bin[i]/(np.log10(Dp_CIP[i+3])-np.log10(Dp_CIP[i+2]))\n",
      "#    Spectrum_CIP[0] = np.NaN\n",
      "#    Spectrum_CIP[1] = np.NaN        \n",
      "###---------------------------------------------------------------------------------------###        \n",
      "\n",
      "#### Case 2) For CIP Spectra only from the 1st bin #######################################################\n",
      "### N_CIP_bin & NoOfTime needs to calculate #########################################################\n",
      "    \n",
      "    CDNC_CIP_bin = ncfile.groups[\"CIP\"].variables['Conc_CIP'][RL] ### CIP concentration, per bin\n",
      "    N_CIP_bin = [0.]*(CIPLastBin)  ### Redefine N_CIP_bin for Spectra (1st bin ~ CIPLastBin bin) only\n",
      "    NoOfTime = 0\n",
      "    for j in range(len(df1.index)):   ### only creates for the effective rows from df5 ###    \n",
      "        k = df1.index[j]\n",
      "        for m in range(CIPLastBin):\n",
      "            N_CIP_bin[m] += CDNC_CIP_bin[k][m]   ### For Spectra only from the 1st bin###\n",
      "        NoOfTime = NoOfTime +1       ### For Spectra only ###\n",
      "\n",
      "    Spectrum_CIP = [np.NaN]*(CIPLastBin+1)\n",
      "    AvgN_CIP_bin = [0.]*(CIPLastBin)\n",
      "    for i in range(CIPLastBin):  \n",
      "        AvgN_CIP_bin[i] = N_CIP_bin[i]/NoOfTime   ### AvgN_CIP_bin = dN \n",
      "\n",
      "    #Spectrum_CIP[0] = 0  ### for Step plot, making the y[0] = 0 ###\n",
      "    for i in range(CIPLastBin): \n",
      "        Spectrum_CIP[i+1] = AvgN_CIP_bin[i]/(np.log10(Dp_CIP[i+1])-np.log10(Dp_CIP[i]))  ### dN/dLogDp, dN = AvgN_CIP_bin\n",
      "\n",
      "########################################################################################################\n",
      "    ### producing MP by press and a whole flight ###########################################################      \n",
      "      \n",
      "    if ncname == '../../../../Data/2013/nc/20130723_130219.nc':### For 0723 Flight, couldn't create Mew3 because of WCM no working\n",
      "        df_Liq2 = df1\n",
      "    else:                 \n",
      "        df_Liq2 = df1.query('(Mew3 <= 0.1 | TStat >= 0)')   ### New (10/Nov/2015) \n",
      "        #df_Liq2 = df1.query('Mew3 > 0.1 & TStat <= 0')   ### for mixed phase clouds\n",
      "        \n",
      "        #### This is for deleting LWC CAPS outliers ########################################################\n",
      "        SD = (df_Liq2['TWC156']-(df_Liq2['LWCC']+df_Liq2['LWCCIP'])).std()\n",
      "        dftemp = df_Liq2[(df_Liq2['LWCC'] + df_Liq2['LWCCIP']- df_Liq2['TWC156']) > 2*SD]\n",
      "        index01 = df_Liq2.index.tolist()\n",
      "        index02 = dftemp.index.tolist()\n",
      "        minus = list(set(index01) - set(index02))\n",
      "        df_Liq2 = df_Liq2.loc[minus]\n",
      "        #################################################################################################\n",
      "    \n",
      "    #### Dealing with exceptional case such as high CDNC #################################################\n",
      "    #if query2 <> 0:\n",
      "    #    #df3_NoHighCDNC = df_Liq2.drop((df_Liq2.query('(PStat >= 710 & PStat < 730) & (CDNC > 50)')).index)\n",
      "    #    df_Liq2 = df_Liq2.drop((df_Liq2.query(query2)).index)\n",
      "    \n",
      "    df3 = df_Liq2   ### Need to separate df_Liq2 from df3 ### IMportant !!! #####################\n",
      "\n",
      "    #df3.PStat = np.round (np.round(df3.PStat,0)/10)*10 ### This was exchanged to the below one\n",
      "    df3.PStat = np.round (np.round(df3.PStat,-1)/10)*10 ### making the height as 10hPa unit eg. 762hPa => 760 ###\n",
      "    \n",
      "    #if ncname == '../../../Data/2013/nc/20130907_122442.nc': ### No reason to put this\n",
      "    #    df3 = df3.drop((df3.query('PStat == 810')).index)\n",
      "\n",
      "###--------------Adding in additional info. to df3 for analysis ------------------------------------###############    \n",
      "    df3['TWCCAPS'] = pd.Series( df3['LWCC']+df3['LWCCIP'], index=df3.index ) \n",
      "    df3['FDate'] = pd.Series( ncname[22:37], index=df3.index )   ### This doesn't work for df4 but df4 can be calcurated\n",
      "    df3['FType'] = pd.Series( FType, index=df3.index )           ### This doesn't work for df4 but df4 can be calcurated\n",
      "    df3['Mon'] = pd.Series( int(ncname[26:28]), index=df3.index )\n",
      "#   print \"Length of liquid clouds: \", len(df3)  \n",
      "\n",
      "### Creating df4 #####################################################################################\n",
      "\n",
      "    #del df3['Time']\n",
      "    \n",
      "    df4= df3.groupby('PStat').mean()    \n",
      "    \n",
      "    ### Formatting ##################################################################\n",
      "    df4.PA_FO = np.round(df4.PA_FO ,0) ; df4.PA_S = np.round(df4.PA_S,0)\n",
      "    df4.lat1 = np.round(df4.lat1,1) ; df4.TStat = np.round(df4.TStat,1); df4.long1 = np.round(df4.long1,1) ;\n",
      "    df4.CDNC = np.round(df4.CDNC,1) ; df4.Reff = np.round(df4.Reff,1); df4.Reff_Total = np.round(df4.Reff_Total,1)\n",
      "\n",
      "    df4.LWCC = np.round(df4.LWCC,3) ; df4.LWCHW = np.round(df4.LWCHW,3)\n",
      "    df4.LWC021 = np.round(df4.LWC021,3) ; df4.LWC083 = np.round(df4.LWC083,3)\n",
      "    df4.LWCCIP = np.round(df4.LWCCIP,3) ; df4.LWCCIP_All = np.round(df4.LWCCIP_All,3)\n",
      "    df4.TWC156 = np.round(df4.TWC156,3) ; df4.TWCCAPS = np.round(df4.TWCCAPS,3); df4.Mew3 = np.round(df4.Mew3,2)\n",
      "\n",
      "    df4.MD = np.round(df4.MD,1) ;df4.CIPTo = np.round(df4.CIPTo,2);df4.MDCIP = np.round(df4.MDCIP,1)\n",
      "    df4.W_S = np.round(df4.W_S,0) ;df4.W_D = np.round(df4.W_D,0); df4.TAS = np.round(df4.TAS,0)\n",
      "\n",
      "    df4['PStat2'] = pd.Series(np.unique(df3['PStat']), index=df4.index) ### Because PStat is needed to plot, having PStat as\n",
      "                                                            ### a column is needed. \n",
      "    df4['Count'] = pd.Series(df3.groupby('PStat').count()['LWCHW'], index=df4.index)  ### adding count\n",
      "    \n",
      "    #return df3, df4, Len_AllClouds   ### ========== For 01 Create Flight Summary =============================################\n",
      "    \n",
      "    #return df3, df4, Spectrum, Spectrum_CIP, Dp, Dp_CIP, SpectrumT, SpectrumT_CIP, df_Spectrum\n",
      "    return df3, df4, Spectrum, Spectrum_CIP, Dp, Dp_CIP\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###3. get df & df_clouds              ### input(Target_st_sec, Target_end_sec), output(df, df_clouds)\n",
      "def Get_dfNdf_clouds (FDate, Target_st_sec, Target_end_sec, query1, slope):\n",
      "\n",
      "    import netCDF4\n",
      "    import pandas as pd\n",
      "    \n",
      "    if FDate[0:4] == '2013':\n",
      "        ncname = \"../../../../Data/2013/nc/\" + FDate + \".nc\"  \n",
      "    elif FDate[0:4] == '2014':\n",
      "        ncname = \"../../../../Data/2014/nc/\" + FDate + \".nc\"\n",
      "    elif FDate[0:4] == '2015':\n",
      "        ncname = \"../../../../Data/2015/nc/\" + FDate + \".nc\"\n",
      "        \n",
      "    SP = [[Target_st_sec,Target_end_sec]] ### align the time with MODIS overpass\n",
      "\n",
      "    ### Start of Get df -------------------------------------------------------------------\n",
      "    ncfile = netCDF4.Dataset(ncname)\n",
      "\n",
      "    Range_List = [0]*len(SP) \n",
      "    SamplingPeriod = [0]*len(SP)\n",
      "    for i in range(len(SP)):\n",
      "        Range_List[i] = range(SP[i][0],SP[i][1])\n",
      "        SamplingPeriod[i] = (SP[i][1]-SP[i][0])\n",
      "\n",
      "    RL = Range_List[0] \n",
      "    lat1= ncfile.groups[\"AirState\"].variables[\"Latitude\"][RL]\n",
      "    long1= ncfile.groups[\"AirState\"].variables[\"Longitude\"][RL]\n",
      "    Time = ncfile.variables[\"Time\"][RL]\n",
      "\n",
      "    df= pd.DataFrame({'Time' : Time, 'long1': long1,'lat1': lat1})\n",
      "    ### --- End of Get df ---------------------------------------------------------\n",
      "    \n",
      "    ### Start of df_clouds ---------------------------------------------------------\n",
      "    df_clouds, df4, Spectrum, Spectrum_CIP, Dp, Dp_CIP = FirstMethod(ncname,'R', '', SP,query1, 0, slope)\n",
      "    \n",
      "    return df, df_clouds, df4  ### df: aligned, df_clouds: whole flight in clouds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### 5. Retrieve Reff for the coordinates from the existing MODIS file and compare this to AC's Reff\n",
      "def Get_MODISReff(FDate, df):\n",
      "    import numpy as npMODIS_reff_\n",
      "    import pandas as pd\n",
      "\n",
      "    ### Get coordinates from the existing MODIS file -----------------------------------\n",
      "    df_MODIS = pd.read_csv('MODIS_'+ FDate + '.csv')     ### Read(Get) MODIS data\n",
      "    #df_MODIS['CTT'] = (df_MODIS['CTT']/0.009999+15000)*0.01-273.15\n",
      "    df_MODIS['CTT'] = df_MODIS['CTT']-273.15\n",
      "    \n",
      "    ### 1) For exact location(flight track) -----------------------------\n",
      "    lat_min = str(df['lat1'].min())\n",
      "    lat_max = str(df['lat1'].max())\n",
      "    long_min = str(df['long1'].min())\n",
      "    long_max = str(df['long1'].max())   \n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_16 > 0 & CPOP == 2'\n",
      "    df_MODIS_1km_16 = df_MODIS.query(query_Liq)  ### MODIS reff default = 1km\n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_21 > 0 & CPOP == 2'\n",
      "    df_MODIS_1km_21 = df_MODIS.query(query_Liq)  \n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_37 > 0 & CPOP == 2'\n",
      "    df_MODIS_1km_37 = df_MODIS.query(query_Liq)  \n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_16_PCL > 0 & CPOP == 2'\n",
      "    df_MODIS_1km_16_PCL = df_MODIS.query(query_Liq)  ### MODIS reff default = 1km\n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_21_PCL > 0 & CPOP == 2'\n",
      "    df_MODIS_1km_21_PCL = df_MODIS.query(query_Liq)  \n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_37_PCL > 0 & CPOP == 2'\n",
      "    df_MODIS_1km_37_PCL = df_MODIS.query(query_Liq) \n",
      "    \n",
      "    ### 2) For 0.05 (5km X 5km) from the exact location(flight track) -----------------------------\n",
      "    lat_min = str(df['lat1'].min() - 0.05)  ### 1 degree = 100km, 0.05 = 10km\n",
      "    lat_max = str(df['lat1'].max()+ 0.05)\n",
      "    long_min = str(df['long1'].min()- 0.05)\n",
      "    long_max = str(df['long1'].max()+ 0.05)   \n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_16 > 0 & CPOP == 2'                                                                                \n",
      "    df_MODIS_5km_16 = df_MODIS.query(query_Liq)  ### MODIS reff default = 1km\n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_21 > 0 & CPOP == 2'                                                                                \n",
      "    df_MODIS_5km_21 = df_MODIS.query(query_Liq)  \n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_37 > 0 & CPOP == 2'                                                                                \n",
      "    df_MODIS_5km_37 = df_MODIS.query(query_Liq)  \n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_16_PCL > 0 & CPOP == 2'                                                                                \n",
      "    df_MODIS_5km_16_PCL = df_MODIS.query(query_Liq)  ### MODIS reff default = 1km\n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_21_PCL > 0 & CPOP == 2'                                                                                \n",
      "    df_MODIS_5km_21_PCL = df_MODIS.query(query_Liq)  \n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_37_PCL > 0 & CPOP == 2'                                                                                \n",
      "    df_MODIS_5km_37_PCL = df_MODIS.query(query_Liq) \n",
      "    \n",
      "    df_MODIS_5km = df_MODIS.query(query_Liq)  \n",
      "\n",
      "    ### 3) For 0.1 (10km X 10km) from the exact location(flight track) -----------------------------\n",
      "    lat_min = str(df['lat1'].min() - 0.1)  ### 1 degree = 100km, 0.1 = 25-30km\n",
      "    lat_max = str(df['lat1'].max()+ 0.1)\n",
      "    long_min = str(df['long1'].min()- 0.1)\n",
      "    long_max = str(df['long1'].max()+ 0.1)   \n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_16 > 0 & CPOP == 2'                                                                                \n",
      "    df_MODIS_10km_16 = df_MODIS.query(query_Liq)  ### MODIS reff default = 1km\n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_21 > 0 & CPOP == 2'                                                                                \n",
      "    df_MODIS_10km_21 = df_MODIS.query(query_Liq)  \n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_37 > 0 & CPOP == 2'                                                                                \n",
      "    df_MODIS_10km_37 = df_MODIS.query(query_Liq)  \n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_16_PCL > 0 & CPOP == 2'                                                                                \n",
      "    df_MODIS_10km_16_PCL = df_MODIS.query(query_Liq)  ### MODIS reff default = 1km\n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_21_PCL > 0 & CPOP == 2'                                                                                \n",
      "    df_MODIS_10km_21_PCL = df_MODIS.query(query_Liq)  \n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_37_PCL > 0 & CPOP == 2'                                                                                \n",
      "    df_MODIS_10km_37_PCL = df_MODIS.query(query_Liq) \n",
      "\n",
      "#    return df_MODIS_1km_16, df_MODIS_1km_21, df_MODIS_1km_37,\\\n",
      "#df_MODIS_1km_16_PCL, df_MODIS_1km_21_PCL, df_MODIS_1km_37_PCL\n",
      "\n",
      "#    return df_MODIS_5km_16, df_MODIS_5km_21, df_MODIS_5km_37,\\\n",
      "#df_MODIS_5km_16_PCL, df_MODIS_5km_21_PCL, df_MODIS_5km_37_PCL\n",
      "\n",
      "    return df_MODIS_10km_16, df_MODIS_10km_21, df_MODIS_10km_37,\\\n",
      "df_MODIS_10km_16_PCL, df_MODIS_10km_21_PCL, df_MODIS_10km_37_PCL\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Plots MODIS sampled pixels alighed with AC track --------------------------------------------------\n",
      "\n",
      "def Plot_MODISPixel(FDate, df, f1, f2, df_MODIS):\n",
      "\n",
      "    import matplotlib.pyplot as plt\n",
      "    from scipy import array\n",
      "    from mpl_toolkits.basemap import Basemap, cm\n",
      "    from pylab import imshow,colorbar,title,savefig\n",
      "    import pandas as pd\n",
      "    import numpy as np\n",
      "    import netCDF4\n",
      "\n",
      "    from matplotlib import gridspec\n",
      "    from matplotlib import rc\n",
      "    rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
      "    plt.rcParams['ps.useafm'] = True\n",
      "    plt.rcParams['pdf.fonttype'] = 42 \n",
      "\n",
      "    fig1=plt.figure(num=1,figsize=(16,16))\n",
      "    #fig1.suptitle(ncname[22:37], fontsize=14)\n",
      "    plt.subplots_adjust(left=0.04, right=0.9, top=0.8, bottom=0.1)\n",
      "      # deciding subplots sizes by indicating positions. 1 is the largest.\n",
      "    gs = gridspec.GridSpec(2, 2, width_ratios=[1, 1]) \n",
      "    fig1.subplots_adjust( hspace=.1, wspace = 0.1 )\n",
      "\n",
      "    # Set the title and fonts for the whole figure\n",
      "    #font = {'weight' : 'bold', 'size' : 12}\n",
      "    font = {'size' : 12} ### this sets the font of color bar(cbar) tick label and lebel size\n",
      "    plt.rc('font', **font)\n",
      "\n",
      "### plot reff ################################################################################################\n",
      "    ax0 = plt.subplot(gs[0])\n",
      "    ax0.set_title(r'Effective Radius (r$_{eff}$): '+FDate, size=12)\n",
      "\n",
      "    ### ----Get MODIS data from MODIS files ----------------------------------\n",
      "    data=array(f1.select('Cloud_Effective_Radius').get()) * 0.01 ### 2.1 micron band\n",
      "    lat1 = array(f2.select('Latitude').get())  ### these lat, long are the same for Cloud phase\n",
      "    long1 = array(f2.select('Longitude').get())\n",
      "\n",
      "    ### draw basemap ---------------------------------------------------------\n",
      "    latcorners = ([-46,-41.5])\n",
      "    loncorners = ([144.5,149])\n",
      "    m = Basemap(projection='cyl',llcrnrlat=latcorners[0],urcrnrlat=latcorners[1],\\\n",
      "                llcrnrlon=loncorners[0],urcrnrlon=loncorners[1],\\\n",
      "                resolution = 'i')\n",
      "    # Draw coastlines, state and country boundaries, edge of map.\n",
      "    m.drawcoastlines()\n",
      "    m.drawstates()\n",
      "    m.drawcountries()\n",
      "    parallels = np.arange(-46.,-41.5,.5)\n",
      "    m.drawparallels(parallels,labels=[True,False,True,False],fontsize=8) \n",
      "    meridians = np.arange(144.5,149,.5)\n",
      "    m.drawmeridians(meridians,labels=[False,False,False,True],fontsize=8)\n",
      "\n",
      "    # Draw filled contours.\n",
      "    clevs = np.arange(0,40,10)\n",
      "\n",
      "    # Plot every masked value as white\n",
      "    cmap = cm.GMT_drywet\n",
      "    \n",
      "    # Plot the data (MODIS reff)----------------------------------------------------\n",
      "    # make data as basemap coordinations\n",
      "    cs = m.contourf(long1,lat1,data,clevs,cmap=cmap,latlon=True)\n",
      "\n",
      "    # Add colorbar\n",
      "    cbar = m.colorbar(cs,location='right',pad=\"3%\")\n",
      "    cbar.set_label(r'r$_{eff}$ [$\\mu$m]')\n",
      "    \n",
      "    ###-------- Plot Flight track------------------------------------------------\n",
      "    lat2 = list(df['lat1'][:])\n",
      "    long2 = list(df['long1'][:])\n",
      "\n",
      "    # convert the flight track latitude and longitude to base map coordinates\n",
      "    x,y = m(long2,lat2)\n",
      "    # plot the flight track\n",
      "    m.plot(x,y,color=\"red\",mfc=\"red\",mec=\"red\",marker=\",\",markersize=4,alpha=0.5)\n",
      "###############################################################################-End of plot reff ############\n",
      "    \n",
      "### plot MODIS sampled pixels ###############################################################################\n",
      "    ax0 = plt.subplot(gs[2])\n",
      "    ax0.set_title(r'Effective Radius (r$_{eff}$): '+FDate, size=12)\n",
      "\n",
      "    data= array(df_MODIS['reff_21'])\n",
      "    lat1 = array(df_MODIS['lat1'])\n",
      "    long1 = array(df_MODIS['long1'])\n",
      "\n",
      "    ### draw basemap ---------------------------------------------------------\n",
      "    latcorners = ([-46,-41.5])\n",
      "    loncorners = ([144.5,149])\n",
      "    m = Basemap(projection='cyl',llcrnrlat=latcorners[0],urcrnrlat=latcorners[1],\\\n",
      "                llcrnrlon=loncorners[0],urcrnrlon=loncorners[1],\\\n",
      "                resolution = 'i')\n",
      "    # Draw coastlines, state and country boundaries, edge of map.\n",
      "    m.drawcoastlines()\n",
      "    m.drawstates()\n",
      "    m.drawcountries()\n",
      "    parallels = np.arange(-46.,-41.5,.5)\n",
      "    m.drawparallels(parallels,labels=[True,False,True,False],fontsize=8) \n",
      "    meridians = np.arange(144.5,149,.5)\n",
      "    m.drawmeridians(meridians,labels=[False,False,False,True],fontsize=8)\n",
      "\n",
      "    x,y = m(long1,lat1) ### MODIS pixels\n",
      "    m.plot(x,y,color=\"blue\",mfc=\"blue\",mec=\"blue\",marker=\"o\",markersize=4,alpha=0.5)  \n",
      "    \n",
      "    lat2 = list(df['lat1'][:])\n",
      "    long2 = list(df['long1'][:])\n",
      "    x,y = m(long2,lat2) ### flight track\n",
      "    m.plot(x,y,color=\"red\",mfc=\"red\",mec=\"red\",marker=\",\",markersize=4,alpha=0.5)\n",
      "######################################################################## End of MODIS sampled pixels #############\n",
      "    \n",
      "    \n",
      "    ### plot Cloud Phase ----------------------------------------------------------------------------------------------------\n",
      "    ax1 = plt.subplot(gs[1])\n",
      "    ax1.set_title('MODIS Cloud Phase Optical Properties (CPOP):'+FDate, size=12)\n",
      "\n",
      "    ### ----Get MODIS data from MODIS files --------------------------------------------------------\n",
      "    data=array(f1.select('Cloud_Phase_Optical_Properties').get())\n",
      "    lat1 = array(f2.select('Latitude').get())\n",
      "    long1 = array(f2.select('Longitude').get())\n",
      "\n",
      "    ### ----draw basemap  ---------------------------------------------------------------------------\n",
      "    latcorners = ([-46,-41.5])\n",
      "    loncorners = ([144.5,149])\n",
      "    m = Basemap(projection='cyl',llcrnrlat=latcorners[0],urcrnrlat=latcorners[1],\\\n",
      "                llcrnrlon=loncorners[0],urcrnrlon=loncorners[1],\\\n",
      "                resolution = 'i')\n",
      "    # Draw coastlines, state and country boundaries, edge of map.\n",
      "    m.drawcoastlines()\n",
      "    m.drawstates()\n",
      "    m.drawcountries()   \n",
      "    parallels = np.arange(-46.,-41.5,.5)\n",
      "    m.drawparallels(parallels,labels=[True,False,True,False], fontsize = 8)\n",
      "    meridians = np.arange(144.5,149,.5)\n",
      "    m.drawmeridians(meridians,labels=[False,False,False,True], fontsize = 8)\n",
      "\n",
      "    # Draw filled contours.\n",
      "    clevs = np.arange(0.5,5.5,1) \n",
      "    cmap = plt.cm.gist_earth\n",
      "\n",
      "    # Plot the data\n",
      "    #### make data as basemap coordinations\n",
      "    cs = m.contourf(long1,lat1,data,clevs,cmap=cmap,latlon=True)\n",
      "\n",
      "    # Add colorbar   \n",
      "    cbar = m.colorbar(cs,location='right',ticks=[1, 2, 3, 4], pad=\"3%\") ### this should be co-related to clevs values\n",
      "    cbar.set_ticklabels([ 'clear sky', 'Liquid', 'Ice', 'Undetermined \\n Cloud Phase']) \n",
      "\n",
      "    ###-------- Plot Flight track--------------------------------------------------------------\n",
      "    lat2 = list(df['lat1'][:])\n",
      "    long2 = list(df['long1'][:])\n",
      "    Time = list(df['Time'][:])\n",
      "\n",
      "    df= pd.DataFrame({'Time' : Time, 'long2': long2,'lat2': lat2})\n",
      "\n",
      "    # convert the flight track latitude and longitude to base map coordinates\n",
      "    x,y = m(long2,lat2)\n",
      "    # plot the flight track\n",
      "    m.plot(x,y,color=\"red\",mfc=\"red\",mec=\"red\",marker=\",\",markersize=4,alpha=0.5)\n",
      "    ##--------------------------------------------------------------------End of plot Phase ---------------------    \n",
      "    \n",
      "    #plt.savefig(FDate+'ReffNCPhase.png',dpi=200)\n",
      "    plt.show()\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "######################################################################################################\n",
      "### Main script ######################################################################################\n",
      "import pandas as pd\n",
      "\n",
      "C_Flag = 'Liq'\n",
      "df_FInfo= pd.read_csv('Flight_info2.csv')\n",
      "\n",
      "FDate = \"20130614_133658\"\n",
      "AC_st_time = '133658'\n",
      "F_Desc = \"Research\"\n",
      "#MODIS_Time = '0421.6' ### This should be saved in the FlightInfo, and should be provide this form including decimal\n",
      "MODIS_Time = '0420.0'\n",
      "query1 = '(lat1 < -43.) & '+ Query_forCloud(C_Flag)\n",
      "slope = 0.732\n",
      "M_fname1 = \"./20130614/Reff/MYD06_L2.A2013165.0420.006.2014266205611.hdf\"\n",
      "M_fname2 = \"./20130614/Reff/MYD03.A2013165.0420.006.2013165155508.hdf\"\n",
      "'''\n",
      "FDate = \"20130628_130139\"\n",
      "AC_st_time = FDate[9:15]\n",
      "MODIS_Time = '0434.0'   \n",
      "F_Desc = \"Research\"\n",
      "#query_part = df_FInfo[df_FInfo.query('F_date == '+FDate)]['Query1']\n",
      "#query1 = query_part + Query_forCloud(C_Flag) \n",
      "query1 = '(lat1 < -43.5 | long1 < 146) & '+ Query_forCloud(C_Flag) ### for long1<145.4, the result is same \n",
      "slope = 0.720\n",
      "M_fname1 = \"./20130628/Reff/MYD06_L2.A2013179.0430.006.2014267001301.hdf\"\n",
      "M_fname2 = \"./20130628/Reff/MYD03.A2013179.0430.006.2013179161739.hdf\"\n",
      "\n",
      "FDate = \"20130707_125944\"\n",
      "AC_st_time = '125944'\n",
      "MODIS_Time = '0428.0' ### This should be saved in the FlightInfo, and should be provide this form including decimal\n",
      "query1 = '(lat1 < -43.5 & long1 < 147.5) & '+ Query_forCloud(C_Flag)\n",
      "slope = 0.678\n",
      "\n",
      "FDate = \"20130723_130219\"\n",
      "AC_st_time = FDate[9:15]\n",
      "MODIS_Time = '0427.8'   ### should be provide this form including decimal\n",
      "F_Desc = \"Research\"\n",
      "query1 = '(LWCC+LWCCIP > 0.01) & (LWCC+(LWCCIP-CIPLWC_Drizzle))>0.01 & '+ Query_forCloud(C_Flag)\n",
      "slope = 0.75\n",
      "M_fname1 = \"./20130723/Reff/MYD06_L2.A2013204.0425.006.2014267101648.hdf\"  \n",
      "M_fname2 = \"./20130723/Reff/MYD03.A2013204.0425.006.2013205024031.hdf\"\n",
      "\n",
      "FDate = \"20130806_151347\" ### AC flew after MODIS overpass\n",
      "AC_st_time = FDate[9:15]\n",
      "MODIS_Time = '0440.0'   ### should be provide this form including decimal\n",
      "F_Desc = \"Research\"\n",
      "query1 = '(long1 < 145.5 & lat1 < -42.1) & '+ Query_forCloud(C_Flag)\n",
      "slope = 0.75\n",
      "M_fname1 = \"./20140806/Reff/MYD06_L2.A2014218.0405.006.2014271211204.hdf\"  \n",
      "M_fname2 = \"./20140806/Reff/MYD03.A2014218.0405.006.2014220175309.hdf\"\n",
      "\n",
      "FDate = \"20130907_122442\"\n",
      "AC_st_time = FDate[9:15]\n",
      "MODIS_Time = '0439.0'   ### should be provide this form including decimal\n",
      "F_Desc = \"Research\"\n",
      "query1 = '(long1 < 145.6 | lat1 < -43.3) & '+ Query_forCloud(C_Flag)\n",
      "slope = 0.538\n",
      "M_fname1 = \"./20130907/Reff/MYD06_L2.A2013250.0435.006.2014267090313.hdf\"  \n",
      "M_fname2 = \"./20130907/Reff/MYD03.A2013250.0435.006.2013250172454.hdf\"\n",
      "\n",
      "FDate = \"20150830_130524\"\n",
      "AC_st_time = '130525'\n",
      "MODIS_Time = '0426.0'   ### should be provide this form including decimal\n",
      "F_Desc = \"Research, Baseline, Ocean(S), Not associated, Open MCC\"\n",
      "query1 = 'lat1 < -43.7 & '+ Query_forCloud(C_Flag) ### for long1<145.4, the result is same \n",
      "slope = 0.535\n",
      "M_fname1 = \"./20150830/Reff/MYD06_L2.A2015242.0425.006.2015243234239.hdf\"\n",
      "M_fname2 = \"./20150830/Reff/MYD03.A2015242.0425.006.2015243130645.hdf\"\n",
      "\n",
      "FDate = \"20151001_123025\"\n",
      "AC_st_time = FDate[9:15]\n",
      "MODIS_Time = '0427.5'   ### should be provide this form including decimal\n",
      "F_Desc = \"Research\"\n",
      "query1 = '(lat1 < -43.6 ) & '+ Query_forCloud(C_Flag)\n",
      "slope = 0.783\n",
      "M_fname1 = \"./20151001/Reff/MYD06_L2.A2015274.0425.006.2015274203619.hdf\"  \n",
      "M_fname2 = \"./20151001/Reff/MYD03.A2015274.0425.006.2015274154732.hdf\"\n",
      "FDate=\"20151001_123025\"\n",
      "'''\n",
      "Sync_sec = GetSyncSec(AC_st_time, MODIS_Time) ### 1. Synchronized time between aircraft ad MODIS\n",
      "Target_st_sec, Target_end_sec = GetTargetSecs(FDate, Sync_sec)  ### 2. \n",
      "df, df_clouds, df4 = Get_dfNdf_clouds(FDate, Target_st_sec, Target_end_sec, query1, slope) ### 3. \n",
      "  ### df: aligned, df_clouds: whole flight in clouds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Sync_sec :  2582\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### 7. retrieve MODIS reff\n",
      "if FDate == \"20130723_130219\":    ### exceptional flight eg.when there is no data for lat, long\n",
      "    df_MODIS_10km_16, df_MODIS_10km_21, df_MODIS_10km_37,\\\n",
      "df_MODIS_10km_16_PCL, df_MODIS_10km_21_PCL, df_MODIS_10km_37_PCL = Get_MODISReff_2(FDate, df)  ### 5\n",
      "else:\n",
      "    df_MODIS_10km_16, df_MODIS_10km_21, df_MODIS_10km_37,\\\n",
      "df_MODIS_10km_16_PCL, df_MODIS_10km_21_PCL, df_MODIS_10km_37_PCL = Get_MODISReff(FDate, df)  ### 5\n",
      "\n",
      "#Save_reff(FDate, df_MODIS_1km, df_MODIS_5km, df_MODIS_10km, df_clouds) ### 6. save"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyhdf.SD import SD\n",
      "\n",
      "### read a file\n",
      "f1=SD(M_fname1)\n",
      "f2=SD(M_fname2)\n",
      "\n",
      "df_MODIS = df_MODIS_10km_21\n",
      "Plot_MODISPixel(FDate, df, f1, f2, df_MODIS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "WARNING: x coordinate not montonically increasing - contour plot\n",
        "may not be what you expect.  If it looks odd, your can either\n",
        "adjust the map projection region to be consistent with your data, or\n",
        "(if your data is on a global lat/lon grid) use the shiftgrid\n",
        "function to adjust the data to be consistent with the map projection\n",
        "region (see examples/contour_demo.py).WARNING: x coordinate not montonically increasing - contour plot\n",
        "may not be what you expect.  If it looks odd, your can either\n",
        "adjust the map projection region to be consistent with your data, or\n",
        "(if your data is on a global lat/lon grid) use the shiftgrid\n",
        "function to adjust the data to be consistent with the map projection\n",
        "region (see examples/contour_demo.py)."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/eunmia/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/matplotlib/font_manager.py:1236: UserWarning: findfont: Font family ['sans-serif'] not found. Falling back to Bitstream Vera Sans\n",
        "  (prop.get_family(), self.defaultFamily[fontext]))\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "pd.set_option('display.max_columns', None)\n",
      "pd.set_option('display.max_rows', None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    }
   ],
   "metadata": {}
  }
 ]
}