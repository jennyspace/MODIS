{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### ALL 5th/Sep/2016 --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### what this should do is ---- plot tracks and cal reff to plot reff of MODIS and aircraft\n",
    "#1. get Sync_sec \n",
    "#2. Decide Target_st_sec, Target_end_sec\n",
    "#3. get df & df_clouds              ### input(Target_st_sec, Target_end_sec), output(df, df_clouds)\n",
    "#2. get Target coordinates          ### input(target_st_time, target_end_time) output(target_coordinates)\n",
    "#4. plot flight track (green & red) ### Green: whole track during the target time (get all df), Red: cloud track\n",
    "                                    ### input(df,df_clouds ), output(None)\n",
    "#5. Cal ac avg                      ### input(df_clouds) output(reff, etc)\n",
    "#6. Cal MODIS avg                   ### input (target_coordinates) output(reff, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### 1. GetSyncSec: to get Synchronized time between aircraft ad MODIS\n",
    "def GetSyncSec (AC_st_time, MODIS_time):\n",
    "    Start_sec = int(AC_st_time[0:2])*3600 + int(AC_st_time[2:4])*60 + int(AC_st_time[4:6])\n",
    "    MODIS_time_local_sec = (int(MODIS_time[0:2])+10)*3600 + int(MODIS_time[2:4])*60 + int(MODIS_time[5:6])*6 ### seconds\n",
    "    Sync_sec = MODIS_time_local_sec - Start_sec ### Synchronized time between aircraft ad MODIS\n",
    "    print Sync_sec \n",
    "    \n",
    "    return Sync_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### 2. Decide the target start and end time\n",
    "def GetTargetSecs(FDate, Sync_sec):\n",
    "    '''\n",
    "    1) Exact time: Target_secs (6km)\n",
    "    2) +- 2 ms = Target_secs + 2*60 (12km)\n",
    "    3) +- 5 ms = Target_secs + 5*60 (30km)\n",
    "    4) +- 10 ms = Target_secs + 10*60 (60km)\n",
    "    '''\n",
    "    if FDate == \"20130614_133658\" :  ### for this flight, there is no clouds during MODIS overpass so decided 20 mis plus\n",
    "        Target_st_sec = Sync_sec   \n",
    "        Target_end_sec = Sync_sec + 20*60\n",
    "    else: \n",
    "        Target_st_sec = Sync_sec - 10*60  \n",
    "        Target_end_sec = Sync_sec + 10*60  ### 10 mis plus after MODIS overpass\n",
    "    \n",
    "    return Target_st_sec, Target_end_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Part of 3. ---------------------------------------------------------------------------------------------------\n",
    "### Be careful, this one doesn't matter in or base of clouds!\n",
    "def Query_forCloud(C_Flag):\n",
    "    if C_Flag == 'Liq':\n",
    "        ### set CIPFirstBin = 3 for clouds \n",
    "        #query_cloud ='(TWC156>0.01) & (LWCC+(LWCCIP-CIPLWC_Drizzle))>0.01 & (TWC156>LWC083)'  \n",
    "        query_cloud ='(TWC156>0.01) & (TWC156>LWC083)' ### include cloud base and top\n",
    "    elif C_Flag == 'ND':\n",
    "        query_cloud ='(TWC156>0.01) & (LWCC+(LWCCIP-CIPLWC_Drizzle))>0.01 & (TWC156>LWC083) & (CIPLWC_Drizzle<0.005)'\n",
    "    elif C_Flag == 'D':\n",
    "        ### Dizzling clouds,(LWCC+(LWCCIP-CIPLWC_Drizzle))>0.005: for excluding cloud over and below\n",
    "        ### CIPLWC_Drizzle ( >= 112.5) >= 0.005: is too low of drizzle         \n",
    "        query_cloud ='(TWC156>0.01) & (LWCC+(LWCCIP-CIPLWC_Drizzle))>0.01 & (TWC156>LWC083) & (CIPLWC_Drizzle>=0.005)'\n",
    "    return query_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Part of 3 ----------------------------------------------------------------------------------------------\n",
    "def FirstMethod(ncname, FType, F_Desc, SP, query1, query2, slope):\n",
    "\n",
    "    import numpy as np\n",
    "    import netCDF4\n",
    "    import pandas as pd\n",
    "    \n",
    "    ncfile = netCDF4.Dataset(ncname)\n",
    "\n",
    "### Sampling ###########################################################\n",
    "    Range_List = [0]*len(SP) \n",
    "    SamplingPeriod = [0]*len(SP)\n",
    "    for i in range(len(SP)):\n",
    "        Range_List[i] = range(SP[i][0],SP[i][1])\n",
    "        SamplingPeriod[i] = (SP[i][1]-SP[i][0])\n",
    "\n",
    "##############################################################################################################################\n",
    "    # For Spectra, Effective Radius #####################################################\n",
    "    # This is for calculating the range of the bins \n",
    "    # the numbers of the array(CellSize) is the detectable minimum size(detectable starting point in the bin) \n",
    "\n",
    "    Dp = ncfile.groups[\"CAS\"].variables['ForwardCounts_CAS'].getncattr('CellSizes')\n",
    "        # Dp = Diameter of a particle detected in the bin = bin size\n",
    "    Dp = np.append(Dp,50)  ### inserting the size of the last bin maximum, so len(Dp)=31, len(Rp)=30\n",
    "\n",
    "    Rp = [0.]*30         ### Number of bins ###\n",
    "    for i in range(30):\n",
    "        Rp[i] = np.sqrt([Dp[i]*Dp[i+1]])*.5   ### geometric mean r in n*r^3/n*r^2 ###\n",
    "\n",
    "    CIPLastBin = 33 ### So, CIPLastBin = 30 in CAS !!! ######################\n",
    "    CIPDrizzleBin = 5 ### For discriminating drizzle ( > 112.5 microns) clouds' LWCCIP > 0.01 \n",
    "    Dp_CIP = ncfile.groups[\"CIP\"].variables['CountsPerBin_CIP'].getncattr('CellSizes')[0:CIPLastBin] ##len(Dp_CIP) = 34\n",
    "    Dp_CIP = np.append(Dp_CIP,837.5)\n",
    "        # Dp = Diameter of a particle detected in the bin = bin size\n",
    "    #Dp_CIP=np.append(Dp_CIP,1562.5)  ### inserting the size of the last bin maximum ###\n",
    "                                     ### the last bin should be deleted for plot to make the array size the same ###\n",
    "    \n",
    "    Rp_CIP = [0.]*(CIPLastBin)  \n",
    "    for i in range(CIPLastBin):\n",
    "        Rp_CIP[i] = np.sqrt([Dp_CIP[i]*Dp_CIP[i+1]])*.5   ### geometric mean r in n*r^3/n*r^2 ###\n",
    "    '''\n",
    "    CellSizes [   12.5    37.5    62.5    87.5   112.5   137.5   162.5   187.5   212.5    237.5   \n",
    "                  262.5   287.5   312.5   337.5   362.5   387.5   412.5   437.5  462.5   487.5   \n",
    "                  512.5   537.5   562.5   587.5   612.5   637.5   662.5   687.5   712.5   737.5  \n",
    "                  762.5   787.5   812.5   837.5   862.5   887.5   912.5   937.5   962.5   987.5  \n",
    "                  1012.5  1037.5  1062.5  1087.5  1112.5  1137.5  1162.5  1187.5  1212.5  1237.5  \n",
    "                  1262.5  1287.5  1312.5  1337.5  1362.5  1387.5  1412.5  1437.5  1462.5  1487.5  \n",
    "                  1512.5  1537.5]\n",
    "  '''               \n",
    "##############################################################################################################################\n",
    "    ### To produce basic MP except Reff for the whole sampling duration (RL) ################\n",
    "    ### Reff will be calcuated after filtering the condition ################################\n",
    "    \n",
    "    RL = Range_List[0] ### RL = the list of sampling duration ([time_start, ... .., time_end])\n",
    "\n",
    "    long1 = ncfile.groups[\"OEM4\"].variables[\"Longitude\"][RL]\n",
    "    lat1 = ncfile.groups[\"OEM4\"].variables[\"Latitude\"][RL]#[LWC_CAS > 0.01] This part has gone to the later part\n",
    "\n",
    "    PStat = ncfile.groups[\"AirState\"].variables[\"StaticPress_Fuselage\"][RL]  \n",
    "    PA_FuseOEM = ncfile.groups[\"AirState\"].variables[\"PressureAltitudeCorrected_Fuselage\"][RL]#[LWC_CAS >0.01]\n",
    "    PA_Shadin = ncfile.groups[\"Shadin\"].variables[\"PressAltitude\"][RL]\n",
    "    TStat = ncfile.groups[\"AirState\"].variables[\"AmbientTemp_TP3S\"][RL]\n",
    "\n",
    "    CDNC_Clouds= ncfile.groups[\"CAS\"].variables[\"ForwardTotalConc_CAS\"][RL]\n",
    "    LWC_CAS= ncfile.groups[\"CAS\"].variables[\"LWC_CAS\"][RL]\n",
    "    LWCHotWire=ncfile.groups[\"CAS\"].variables[\"LWCHotWire_CAS\"][RL]\n",
    "\n",
    "    PLWC021= ncfile.groups[\"WCM\"].variables[\"PLWC021\"][RL]\n",
    "    PLWC083= ncfile.groups[\"WCM\"].variables[\"PLWC083\"][RL]\n",
    "    PTWC156 = ncfile.groups[\"WCM\"].variables[\"PTWC156\"][RL]\n",
    "\n",
    "    ### To get CIPConc &  CIPLWC = from \"3rd bin\" ~ \"where we want\" ##############################\n",
    "    #CIPTotalConc  = ncfile.groups[\"CIP\"].variables[\"TotalConc_CIP\"][RL] # This is for CIP concentration, all bins\n",
    "    CIPConc = [0.]*len(RL) ### from 3rd bin ~ 33th bin ###\n",
    "    \n",
    "    CDNC_CIP_bin = ncfile.groups[\"CIP\"].variables['Conc_CIP'][RL]  ### CDNC_CIP_bin = array (RL rows X # of bins)\n",
    "                                                                   ###             = 45?? X 62   \n",
    "    ### 11/Sep/2015 added: to get LWC_CIP (from the 3rd bin) to modify filtering option as LWC_CAS + LWC_CIP > 0.01 ###\n",
    "    CIPLWC_Drizzle = [0.]*len(RL)\n",
    "    CIPLWC = [0.]*len(RL)\n",
    "    LWC_CIP_bin = ncfile.groups[\"CIP\"].variables['LWCPerBin_CIP'][RL] ## CIP LWC, per bin\n",
    "    \n",
    "    ### CIP LWC to discriminate bigger than 112.5 microns\n",
    "    for i in range(len(RL)):\n",
    "        for j in range(CIPLastBin - CIPDrizzleBin):   ### repeat times\n",
    "             CIPLWC_Drizzle[i] += LWC_CIP_bin[i][j+CIPDrizzleBin-1]\n",
    "\n",
    "    ### for all CIP CDNC & LWC except first 2 bins\n",
    "    for i in range(len(RL)):\n",
    "        for j in range(CIPLastBin - 2):   ### repeat 31(33-3+1), CIP_Conc should exclude 1st & 2nd bin #####################\n",
    "            CIPConc[i] += CDNC_CIP_bin[i][j+2]   ### calcurate from 3rd bin ~ 32+2 = 34th bin\n",
    "                                                      ### CIPConc = only bigger drolpets > 62.5 micron\n",
    "            CIPLWC[i] += LWC_CIP_bin[i][j+2]\n",
    "    # -----------------------------------------------------------------------------------------#\n",
    "\n",
    "    MeanDia_CAS  = ncfile.groups[\"CAS\"].variables[\"MeanDia_CAS\"][RL]\n",
    "    MeanDia_CIP  = ncfile.groups[\"CIP\"].variables[\"MeanDia_CIP\"][RL]\n",
    "    Wind_Speed  = ncfile.groups[\"AirState\"].variables[\"Wind_Speed\"][RL]\n",
    "    Wind_Direction  = ncfile.groups[\"AirState\"].variables[\"Wind_Direction\"][RL]\n",
    "    TAS = ncfile.groups[\"AirState\"].variables[\"TrueAirSpeedCorrected_TP3S\"][RL]\n",
    "    CIPLWC_Allbins = ncfile.groups[\"CIP\"].variables['LWC_CIP'][RL]\n",
    "\n",
    "    time = ncfile.variables[\"Time\"][RL]\n",
    "    \n",
    "    df= pd.DataFrame({'Time' : time, 'PStat' : PStat,'PA_FO' : PA_FuseOEM,'PA_S' : PA_Shadin,\\\n",
    "                  'long1': long1,'lat1': lat1,\\\n",
    "                  'TStat': TStat,'CDNC' : CDNC_Clouds, 'LWCC': LWC_CAS, 'LWCHW' : LWCHotWire, \\\n",
    "                  'LWC021' : PLWC021, 'LWC083' : PLWC083,'TWC156' : PTWC156, \\\n",
    "                  'CIPLWC_Drizzle': CIPLWC_Drizzle, 'LWCCIP': CIPLWC, 'LWCCIP_All': CIPLWC_Allbins,\\\n",
    "                  'CIPTo' : CIPConc, 'MD': MeanDia_CAS, 'MDCIP': MeanDia_CIP, \\\n",
    "                  'W_S': Wind_Speed, 'W_D': Wind_Direction, 'TAS': TAS })\n",
    "    ###---------------------------------------------------------------------------------------###\n",
    "    \n",
    "    CDNC_bin = ncfile.groups[\"CAS\"].variables['ForwardConc_CAS'][RL] ### Range_List[0] = RL  ######\n",
    "    for m in range(30):\n",
    "        name = 'CDNC_bin'+ np.str(m)\n",
    "    #    df[name] = pd.Series( np.float(CDNC_bin[:,m]), index=df.index )\n",
    "        df[name] = pd.Series( CDNC_bin[:,m], index=df.index )\n",
    "        \n",
    "    ### Add CIP bins to df_basic ############\n",
    "    #CDNC_CIP_bin = ncfile.groups[\"CIP\"].variables['Conc_CIP'][RL] ### Range_List[0] = RL  ######\n",
    "    for m in range(CIPLastBin): ### repeat 33 (incluing 1st & 2nd bin), m:0~32\n",
    "        name = 'CDNC_CIP_bin'+ np.str(m)   ### making from 1st bin upto where we want (0~39th bin)\n",
    "    #    df[name] = pd.Series( np.float(CDNC_bin[:,m]), index=df.index )\n",
    "        df[name] = pd.Series( CDNC_CIP_bin[:,m], index=df.index )      \n",
    "        \n",
    "    ### Then, filter with query 1 ##########################################################################  \n",
    "    ### df1 = after appling 1st query ###\n",
    "    '''\n",
    "    if ncname == '../../../Data/2013/nc/20130723_130219.nc':\n",
    "        df1 = df\n",
    "    else:\n",
    "    '''\n",
    "    df1 = df.query(query1)  ### same as df1 = df[(df.a < df.b) & (df.b < df.c)] \n",
    "                                              ### http://pandas.pydata.org/pandas-docs/dev/indexing.html\n",
    "### This is for calibration of WCM LWC083 ###       \n",
    "    offset = 1-slope ### However, offset0.45 is the best\n",
    "    df1['LWC083'] = df1['LWC083'] + offset*df1['TWC156']\n",
    "\n",
    "    beta = 0.1*1.12\n",
    "    Wi = (df1['TWC156']-df1['LWC083'])/(1.12-beta)\n",
    "    Wl = (df1['TWC156']-1.12*Wi)\n",
    "    \n",
    "    df1['Wi'] = pd.Series(Wi, index=df1.index)\n",
    "    df1['Wl'] = pd.Series(Wl, index=df1.index)\n",
    "    \n",
    "    ### process when Wi < 0   ### No zeroing needed\n",
    "    #index_minus = df1[df1['Wi'] < 0].index.tolist()\n",
    "    #df1.loc[index_minus, 'Wi'] = 0\n",
    "\n",
    "    Mew3 = df1['Wi']/(df1['Wi']+df1['Wl'])\n",
    "    df1['Mew3'] = pd.Series(Mew3, index=df1.index)    \n",
    "    \n",
    "    if ncname == '../../../Data/2013/nc/20130723_130219.nc':\n",
    "        df1['Mew3'] = pd.Series(0, index=df1.index) \n",
    "    else:\n",
    "        df1['Mew3'] = pd.Series(Mew3, index=df1.index)  \n",
    "\n",
    "    Len_AllClouds = len(df1) ### Length of all clouds\n",
    "    \n",
    "###########################################################################################################\n",
    "#### Reff: is calculated for the index item from df1 (after filtering) #####################################\n",
    "    \n",
    "    #CDNC_bin = ncfile.groups[\"CAS\"].variables['ForwardConc_CAS'][RL] ### Range_List[0] = RL  ######\n",
    "    R_eff_Sec = [np.NaN] * len(df1.index)  ### List, only for the NECESSARY length, not len(Range_List[0]) ###\n",
    "    Child_Sec = [np.NaN] * len(df1.index)\n",
    "    Parent_Sec = [np.NaN] * len(df1.index)\n",
    "    N_bin = [0.]*30  ### total N for RL for each bin, for only Spectra\n",
    "    NoOfTime = 0   ### for only Spectra\n",
    "\n",
    "    for j in range(len(df1.index)):   ### only creates for the effective rows from df5 ###    \n",
    "        k = df1.index[j]\n",
    "        Child_Sec[j]  = 0.\n",
    "        Parent_Sec[j]  = 0.\n",
    "        for m in range(30):\n",
    "            a = np.float(CDNC_bin[k][m]*pow(Rp[m],3))      ### change array to float, otherwise ###\n",
    "                                                       ### Child_Sec[j]:array,(BUT Child_Sec: array list) ###\n",
    "            Child_Sec[j] = a + Child_Sec[j]  \n",
    "            b = np.float(CDNC_bin[k][m]*np.square(Rp[m]))\n",
    "            Parent_Sec[j] = b + Parent_Sec[j]\n",
    "            N_bin[m] += CDNC_bin[k][m]   ### For only Spectra ###\n",
    "        NoOfTime = NoOfTime +1       ### For only Spectra ###\n",
    "        if Parent_Sec[j] <> 0:       ### added on 14/Sep/2015\n",
    "            R_eff_Sec[j] = Child_Sec[j]/Parent_Sec[j]    ### This division only possible with array ###\n",
    "\n",
    "    ################## create and append the Reff row to df1 #############################################\n",
    "    df1['Reff'] = pd.Series(R_eff_Sec, index=df1.index)   \n",
    "\n",
    "###########################################################################################################\n",
    "### For Spectra (CAS) ##################################################################\n",
    "\n",
    "    #Spectrum = [0.]*31\n",
    "    Spectrum = [np.NaN]*31\n",
    "    AvgN_bin = [0.]*30\n",
    "    for i in range(30):         \n",
    "        AvgN_bin[i] = N_bin[i]/NoOfTime  ### AvgN_bin = dN\n",
    "\n",
    "    #Spectrum[0] = 0  ### for Step plot, making the y[0] = 0 ###\n",
    "    for i in range(30):\n",
    "         Spectrum[i+1] = AvgN_bin[i]/(np.log10(Dp[i+1])-np.log10(Dp[i]))  ### dN/dLogDp, dN = AvgN_bin\n",
    "    \n",
    "###########################################################################################################\n",
    "#### Reff_Total including CIP #### take 3rd bin from CIP ##################################################\n",
    "#CDNC_CIP_bin = ncfile.groups[\"CIP\"].variables['Conc_CIP'][RL] ### Range_List[0] = RL  ## CIP concentration, per bin\n",
    "    R_eff_Total_Sec = [np.NaN] * len(df1.index)  ### List, only for the NECESSARY length, not len(Range_List[0]) ###\n",
    "    Child_Sec = [np.NaN] * len(df1.index)\n",
    "    Parent_Sec = [np.NaN] * len(df1.index)\n",
    "    #N_CIP_bin = [0.]*(CIPLastBin - 2)  ### For Spectra only,All suitable CIP bin Conc ###\n",
    "    #NoOfTime = 0 ### For Spectra only,\n",
    "\n",
    "    for j in range(len(df1.index)):   ### only creates for the effective rows from df5 ###    \n",
    "        k = df1.index[j]\n",
    "        Child_Sec[j]  = 0.\n",
    "        Parent_Sec[j]  = 0.\n",
    "\n",
    "        for m in range(30):\n",
    "            a = np.float(CDNC_bin[k][m]*pow(Rp[m],3))      ### change array to float, otherwise ###\n",
    "                                                       ### Child_Sec[j]:array,(BUT Child_Sec: array list) ###\n",
    "            Child_Sec[j] = a + Child_Sec[j]  \n",
    "            b = np.float(CDNC_bin[k][m]*np.square(Rp[m]))\n",
    "            Parent_Sec[j] = b + Parent_Sec[j]\n",
    "            N_bin[m] += CDNC_bin[k][m]   ### For Spectra only ###\n",
    "\n",
    "        for m in range(CIPLastBin - 2):  ### repeat 31 times for Reff_Total, 3rd~33rd bins (33-3+1)\n",
    "            a2 = np.float(CDNC_CIP_bin[k][m+2]*pow(Rp_CIP[m+2],3))      ### change array to float, otherwise ###\n",
    "                                                       ### Child_Sec[j]:array,(BUT Child_Sec: array list) ###\n",
    "            Child_Sec[j] = a2 + Child_Sec[j]  \n",
    "            b2 = np.float(CDNC_CIP_bin[k][m+2]*np.square(Rp_CIP[m+2]))\n",
    "            Parent_Sec[j] = b2 + Parent_Sec[j]\n",
    "            #N_CIP_bin[m] += CDNC_CIP_bin[k][m+2]   ### For Spectra only, so uncomment if you want to calculate for spectra###        \n",
    "        #NoOfTime = NoOfTime +1       ### For Spectra only, so uncomment if you want to calculate for spectra ###\n",
    "        if Parent_Sec[j] <> 0:\n",
    "            R_eff_Total_Sec[j] = Child_Sec[j]/Parent_Sec[j]    ### This division only possible with array ###\n",
    "\n",
    "    ################## create and append the Reff row to df1 #############################################\n",
    "    df1['Reff_Total'] = pd.Series(R_eff_Total_Sec, index=df1.index)   \n",
    "\n",
    "#### For Spectra (CIP) ##############################################################################\n",
    "### N_CIP_bin & NoOfTime needs to calculate #########################################################\n",
    "\n",
    "#### case 1) For CIP Spectra only louds from the 3rd bin #############################################   \n",
    "#    Spectrum_CIP = [0.]*62   ### changed from 62 => 60\n",
    "#    AvgN_CIP_bin = [0.]*60\n",
    "#    for i in range(60):         \n",
    "#        AvgN_CIP_bin[i] = N_CIP_bin[i]/NoOfTime\n",
    "\n",
    "#    for i in range(60):\n",
    "#        if i == 59:\n",
    "#            Spectrum_CIP[i+2] = AvgN_CIP_bin[i]/(np.log10(1562.5)-np.log10(Dp_CIP[i+2])) ### dN/dLogDp, dN = AvgN_bin\n",
    "#        else:\n",
    "#            Spectrum_CIP[i+2] = AvgN_CIP_bin[i]/(np.log10(Dp_CIP[i+3])-np.log10(Dp_CIP[i+2]))\n",
    "#    Spectrum_CIP[0] = np.NaN\n",
    "#    Spectrum_CIP[1] = np.NaN        \n",
    "###---------------------------------------------------------------------------------------###        \n",
    "\n",
    "#### Case 2) For CIP Spectra only from the 1st bin #######################################################\n",
    "### N_CIP_bin & NoOfTime needs to calculate #########################################################\n",
    "    \n",
    "    CDNC_CIP_bin = ncfile.groups[\"CIP\"].variables['Conc_CIP'][RL] ### CIP concentration, per bin\n",
    "    N_CIP_bin = [0.]*(CIPLastBin)  ### Redefine N_CIP_bin for Spectra (1st bin ~ CIPLastBin bin) only\n",
    "    NoOfTime = 0\n",
    "    for j in range(len(df1.index)):   ### only creates for the effective rows from df5 ###    \n",
    "        k = df1.index[j]\n",
    "        for m in range(CIPLastBin):\n",
    "            N_CIP_bin[m] += CDNC_CIP_bin[k][m]   ### For Spectra only from the 1st bin###\n",
    "        NoOfTime = NoOfTime +1       ### For Spectra only ###\n",
    "\n",
    "    Spectrum_CIP = [np.NaN]*(CIPLastBin+1)\n",
    "    AvgN_CIP_bin = [0.]*(CIPLastBin)\n",
    "    for i in range(CIPLastBin):  \n",
    "        AvgN_CIP_bin[i] = N_CIP_bin[i]/NoOfTime   ### AvgN_CIP_bin = dN \n",
    "\n",
    "    #Spectrum_CIP[0] = 0  ### for Step plot, making the y[0] = 0 ###\n",
    "    for i in range(CIPLastBin): \n",
    "        Spectrum_CIP[i+1] = AvgN_CIP_bin[i]/(np.log10(Dp_CIP[i+1])-np.log10(Dp_CIP[i]))  ### dN/dLogDp, dN = AvgN_CIP_bin\n",
    "\n",
    "########################################################################################################\n",
    "    ### producing MP by press and a whole flight ###########################################################      \n",
    "      \n",
    "    if ncname == '../../../Data/2013/nc/20130723_130219.nc':### For 0723 Flight, couldn't create Mew3 because of WCM no working\n",
    "        df_Liq2 = df1\n",
    "    else:                 \n",
    "        df_Liq2 = df1.query('(Mew3 <= 0.1 | TStat >= 0)')   ### New (10/Nov/2015) \n",
    "        #df_Liq2 = df1.query('Mew3 > 0.1 & TStat <= 0')   ### for mixed phase clouds\n",
    "        \n",
    "        #### This is for deleting LWC CAPS outliers ########################################################\n",
    "        SD = (df_Liq2['TWC156']-(df_Liq2['LWCC']+df_Liq2['LWCCIP'])).std()\n",
    "        dftemp = df_Liq2[(df_Liq2['LWCC'] + df_Liq2['LWCCIP']- df_Liq2['TWC156']) > 2*SD]\n",
    "        index01 = df_Liq2.index.tolist()\n",
    "        index02 = dftemp.index.tolist()\n",
    "        minus = list(set(index01) - set(index02))\n",
    "        df_Liq2 = df_Liq2.loc[minus]\n",
    "        #################################################################################################\n",
    "    \n",
    "    #### Dealing with exceptional case such as high CDNC #################################################\n",
    "    #if query2 <> 0:\n",
    "    #    #df3_NoHighCDNC = df_Liq2.drop((df_Liq2.query('(PStat >= 710 & PStat < 730) & (CDNC > 50)')).index)\n",
    "    #    df_Liq2 = df_Liq2.drop((df_Liq2.query(query2)).index)\n",
    "    \n",
    "    df3 = df_Liq2   ### Need to separate df_Liq2 from df3 ### IMportant !!! #####################\n",
    "\n",
    "    #df3.PStat = np.round (np.round(df3.PStat,0)/10)*10 ### This was exchanged to the below one\n",
    "    df3.PStat = np.round (np.round(df3.PStat,-1)/10)*10 ### making the height as 10hPa unit eg. 762hPa => 760 ###\n",
    "    \n",
    "    #if ncname == '../../../Data/2013/nc/20130907_122442.nc': ### No reason to put this\n",
    "    #    df3 = df3.drop((df3.query('PStat == 810')).index)\n",
    "\n",
    "###--------------Adding in additional info. to df3 for analysis ------------------------------------###############    \n",
    "    df3['TWCCAPS'] = pd.Series( df3['LWCC']+df3['LWCCIP'], index=df3.index ) \n",
    "    df3['FDate'] = pd.Series( ncname[22:37], index=df3.index )   ### This doesn't work for df4 but df4 can be calcurated\n",
    "    df3['FType'] = pd.Series( FType, index=df3.index )           ### This doesn't work for df4 but df4 can be calcurated\n",
    "    df3['Mon'] = pd.Series( int(ncname[26:28]), index=df3.index )\n",
    "#   print \"Length of liquid clouds: \", len(df3)  \n",
    "\n",
    "### Creating df4 #####################################################################################\n",
    "\n",
    "    #del df3['Time']\n",
    "    \n",
    "    df4= df3.groupby('PStat').mean()    \n",
    "    \n",
    "    ### Formatting ##################################################################\n",
    "    df4.PA_FO = np.round(df4.PA_FO ,0) ; df4.PA_S = np.round(df4.PA_S,0)\n",
    "    df4.lat1 = np.round(df4.lat1,1) ; df4.TStat = np.round(df4.TStat,1); df4.long1 = np.round(df4.long1,1) ;\n",
    "    df4.CDNC = np.round(df4.CDNC,1) ; df4.Reff = np.round(df4.Reff,1); df4.Reff_Total = np.round(df4.Reff_Total,1)\n",
    "\n",
    "    df4.LWCC = np.round(df4.LWCC,3) ; df4.LWCHW = np.round(df4.LWCHW,3)\n",
    "    df4.LWC021 = np.round(df4.LWC021,3) ; df4.LWC083 = np.round(df4.LWC083,3)\n",
    "    df4.LWCCIP = np.round(df4.LWCCIP,3) ; df4.LWCCIP_All = np.round(df4.LWCCIP_All,3)\n",
    "    df4.TWC156 = np.round(df4.TWC156,3) ; df4.TWCCAPS = np.round(df4.TWCCAPS,3); df4.Mew3 = np.round(df4.Mew3,2)\n",
    "\n",
    "    df4.MD = np.round(df4.MD,1) ;df4.CIPTo = np.round(df4.CIPTo,2);df4.MDCIP = np.round(df4.MDCIP,1)\n",
    "    df4.W_S = np.round(df4.W_S,0) ;df4.W_D = np.round(df4.W_D,0); df4.TAS = np.round(df4.TAS,0)\n",
    "\n",
    "    df4['PStat2'] = pd.Series(np.unique(df3['PStat']), index=df4.index) ### Because PStat is needed to plot, having PStat as\n",
    "                                                            ### a column is needed. \n",
    "    df4['Count'] = pd.Series(df3.groupby('PStat').count()['LWCHW'], index=df4.index)  ### adding count\n",
    "    \n",
    "    #return df3, df4, Len_AllClouds   ### ========== For 01 Create Flight Summary =============================################\n",
    "    \n",
    "    #return df3, df4, Spectrum, Spectrum_CIP, Dp, Dp_CIP, SpectrumT, SpectrumT_CIP, df_Spectrum\n",
    "    return df3, df4, Spectrum, Spectrum_CIP, Dp, Dp_CIP\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###3. get df & df_clouds              ### input(Target_st_sec, Target_end_sec), output(df, df_clouds)\n",
    "def Get_dfNdf_clouds (FDate, Target_st_sec, Target_end_sec, query1, slope):\n",
    "\n",
    "    import netCDF4\n",
    "    import pandas as pd\n",
    "    \n",
    "    if FDate[0:4] == '2013':\n",
    "        ncname = \"../../../../Data/2013/nc/\" + FDate + \".nc\"  \n",
    "    elif FDate[0:4] == '2014':\n",
    "        ncname = \"../../../../Data/2014/nc/\" + FDate + \".nc\"\n",
    "    elif FDate[0:4] == '2015':\n",
    "        ncname = \"../../../../Data/2015/nc/\" + FDate + \".nc\"\n",
    "        \n",
    "    SP = [[Target_st_sec,Target_end_sec]]\n",
    "\n",
    "    ### Start of Get df -------------------------------------------------------------------\n",
    "    ncfile = netCDF4.Dataset(ncname)\n",
    "\n",
    "    Range_List = [0]*len(SP) \n",
    "    SamplingPeriod = [0]*len(SP)\n",
    "    for i in range(len(SP)):\n",
    "        Range_List[i] = range(SP[i][0],SP[i][1])\n",
    "        SamplingPeriod[i] = (SP[i][1]-SP[i][0])\n",
    "\n",
    "    RL = Range_List[0] \n",
    "    lat1= ncfile.groups[\"AirState\"].variables[\"Latitude\"][RL]\n",
    "    long1= ncfile.groups[\"AirState\"].variables[\"Longitude\"][RL]\n",
    "    Time = ncfile.variables[\"Time\"][RL]\n",
    "\n",
    "    df= pd.DataFrame({'Time' : Time, 'long1': long1,'lat1': lat1})\n",
    "    ### --- End of Get df ---------------------------------------------------------\n",
    "    \n",
    "    ### Start of df_clouds ---------------------------------------------------------\n",
    "    df_clouds, df4, Spectrum, Spectrum_CIP, Dp, Dp_CIP = FirstMethod(ncname,'R', '', SP,query1, 0, slope)\n",
    "    \n",
    "    return df, df_clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### 4. Plot AC flight track---Green: whole track during the target time (get all df), Red: cloud track\n",
    "def PlotTrack (df, df_clouds):\n",
    "    from mpl_toolkits.basemap import Basemap\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    # create new figure, axes instances.\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "\n",
    "    m = Basemap(llcrnrlon=143.,llcrnrlat=-45.,urcrnrlon=150.,urcrnrlat=-40.,\\\n",
    "                rsphere=(6378137.00,6356752.3142),\\\n",
    "                resolution='l',projection='merc',\\\n",
    "                lat_0=40.,lon_0=-20.,lat_ts=20.)\n",
    "    m.drawcoastlines()\n",
    "    m.drawmapboundary(fill_color='aqua')\n",
    "    m.fillcontinents(color='coral',lake_color='aqua')\n",
    "    # draw parallels\n",
    "    m.drawparallels(np.arange(-40,-50,-1),labels=[1,1,0,1])\n",
    "    # draw meridians\n",
    "    m.drawmeridians(np.arange(140,150,1),labels=[1,1,0,1])\n",
    "    ax.set_title('Flights map')\n",
    "    \n",
    "    ### plot Green: ac track during MODIS overpass ------------------------------\n",
    "    lat = list(df['lat1'][:])\n",
    "    lon = list(df['long1'][:])\n",
    "\n",
    "    # convert the flight track latitude and longitude to base map coordinates\n",
    "    x,y = m(lon,lat)\n",
    "    # plot the flight track\n",
    "    m.plot(x,y,color=\"green\",mfc=\"green\",mec=\"green\",marker=\"o\",markersize=4,alpha=0.5)\n",
    "    \n",
    "    ### plot Red: ac track during MODIS overpass ------------------------------\n",
    "    lat = list(df_clouds['lat1'][:])\n",
    "    lon = list(df_clouds['long1'][:])\n",
    "\n",
    "    # convert the flight track latitude and longitude to base map coordinates\n",
    "    x,y = m(lon,lat)\n",
    "    # plot the flight track\n",
    "    m.plot(x,y,color=\"red\",mfc=\"red\",mec=\"red\",marker=\"o\",markersize=4,alpha=0.5)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### 5. Retrieve Reff for the coordinates from the existing MODIS file and compare this to AC's Reff\n",
    "def Get_MODISReff(FDate, df):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    ### Get coordinates from the existing MODIS file -----------------------------------\n",
    "    df_MODIS = pd.read_csv('MODIS_reff_'+ FDate + '.csv')     ### Read(Get) MODIS data\n",
    "    \n",
    "    ### 1) For exact location(flight track) -----------------------------\n",
    "    lat_min = str(df['lat1'].min())\n",
    "    lat_max = str(df['lat1'].max())\n",
    "    long_min = str(df['long1'].min())\n",
    "    long_max = str(df['long1'].max())   \n",
    "    query0 = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff>0'\n",
    "    df_MODIS_1km = df_MODIS.query(query0)  ### MODIS reff default = 1km\n",
    "\n",
    "    ### 2) For 0.05 (5km X 5km) from the exact location(flight track) -----------------------------\n",
    "    lat_min = str(df['lat1'].min() - 0.05)  ### 1 degree = 10km, 0.05 = 5km\n",
    "    lat_max = str(df['lat1'].max()+ 0.05)\n",
    "    long_min = str(df['long1'].min()- 0.05)\n",
    "    long_max = str(df['long1'].max()+ 0.05)   \n",
    "    query0 = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff>0'\n",
    "    df_MODIS_5km = df_MODIS.query(query0)\n",
    "    \n",
    "    ### 3) For 0.05 (10km X 10km) from the exact location(flight track) -----------------------------\n",
    "    lat_min = str(df['lat1'].min() - 0.1)  ### 1 degree = 10km, 0.05 = 5km\n",
    "    lat_max = str(df['lat1'].max()+ 0.1)\n",
    "    long_min = str(df['long1'].min()- 0.1)\n",
    "    long_max = str(df['long1'].max()+ 0.1)   \n",
    "    query0 = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff>0'\n",
    "    df_MODIS_10km = df_MODIS.query(query0)\n",
    "    \n",
    "    return df_MODIS_1km, df_MODIS_5km, df_MODIS_10km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### 6. Save the reffs to a file --------------------------------------------------------------------------------------------\n",
    "def Save_reff(FDate, df_MODIS2, df_clouds):\n",
    "    import pandas as pd\n",
    "    \n",
    "    MODIS_1km_reff = df_MODIS2['reff'].mean()\n",
    "    MODIS_1km_len = len(df_MODIS2)\n",
    "    MODIS_1km_std = df_MODIS2['reff'].std()\n",
    "    \n",
    "    MODIS_5km_reff = df_MODIS2['reff'].mean()\n",
    "    MODIS_5km_len = len(df_MODIS2)\n",
    "    MODIS_5km_std = df_MODIS2['reff'].std()\n",
    "\n",
    "    MODIS_10km_reff = df_MODIS2['reff'].mean()\n",
    "    MODIS_10km_len = len(df_MODIS2)\n",
    "    MODIS_10km_std = df_MODIS2['reff'].std()\n",
    "\n",
    "    AC_reff = df_clouds['Reff'].mean()\n",
    "    AC_len = len(df_clouds)\n",
    "    AC_std = df_clouds['Reff'].std()\n",
    "    AC_reffT = df_clouds['Reff_Total'].mean()\n",
    "    AC_reffT_std= df_clouds['Reff_Total'].std()\n",
    "    \n",
    "    df_reff = pd.DataFrame({'FDate': FDate, \\\n",
    "                            'MODIS_1km_reff':MODIS_reff, 'MODIS_1km_len':MODIS_len, 'MODIS_1km_std':MODIS_std,\\\n",
    "                            'MODIS_5km_reff':MODIS_reff, 'MODIS_5km_len':MODIS_len, 'MODIS_5km_std':MODIS_std,\\\n",
    "                            'MODIS_10km_reff':MODIS_reff, 'MODIS_10km_len':MODIS_len, 'MODIS_10km_std':MODIS_std,\\\n",
    "                            'MODIS_reff':MODIS_reff, 'MODIS_len':MODIS_len, 'MODIS_std':MODIS_std,\\\n",
    "                            'AC_reff': AC_reff, 'AC_len': AC_len, 'AC_std': AC_std, \\\n",
    "                            'AC_reffT': AC_reffT, 'AC_reffT_std': AC_reffT_std}, index = [FDate]) \n",
    "    \n",
    "    if FDate == \"20130614_133658\":\n",
    "        df_reff.to_csv('MODIS_reff_Smry.csv', mode='w')\n",
    "    else:\n",
    "        df_reff.to_csv('MODIS_reff_Smry.csv', mode='a', index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FDate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-5efbe4388872>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mFDate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'FDate' is not defined"
     ]
    }
   ],
   "source": [
    "print FDate[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eunmia/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/io/excel.py:626: UserWarning: Installed openpyxl is not supported at this time. Use >=1.6.1 and <2.0.0.\n",
      "  .format(openpyxl_compat.start_ver, openpyxl_compat.stop_ver))\n",
      "-c:132: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_index,col_indexer] = value instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-c:151: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_index,col_indexer] = value instead\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################\n",
    "### Main script ######################################################################################\n",
    "import pandas as pd\n",
    "\n",
    "C_Flag = 'Liq'\n",
    "df_FInfo= pd.read_csv('Flight_info2.csv')\n",
    "'''\n",
    "FDate = \"20130614_133658\"\n",
    "AC_st_time = '133658'\n",
    "MODIS_Time = '0421.6' ### This should be saved in the FlightInfo, and should be provide this form including decimal\n",
    "query1 = '(lat1 < -43.) & '+ Query_forCloud(C_Flag)\n",
    "slope = 0.732\n",
    "\n",
    "FDate = \"20130628_130139\"\n",
    "AC_st_time = FDate[9:15]\n",
    "MODIS_Time = '0434.0'   \n",
    "F_Desc = \"Research\"\n",
    "#query_part = df_FInfo[df_FInfo.query('F_date == '+FDate)]['Query1']\n",
    "#query1 = query_part + Query_forCloud(C_Flag) \n",
    "query1 = '(lat1 < -43.5 | long1 < 146) & '+ Query_forCloud(C_Flag) ### for long1<145.4, the result is same \n",
    "slope = 0.720\n",
    "'''\n",
    "FDate = \"20130707_125944\"\n",
    "AC_st_time = '125944'\n",
    "MODIS_Time = '0428.0' ### This should be saved in the FlightInfo, and should be provide this form including decimal\n",
    "query1 = '(lat1 < -43.5 & long1 < 147.5) & '+ Query_forCloud(C_Flag)\n",
    "slope = 0.678\n",
    "'''\n",
    "FDate = \"20150830_130524\"\n",
    "AC_st_time = '130525'\n",
    "MODIS_Time = '0426.0'   ### should be provide this form including decimal\n",
    "F_Desc = \"Research, Baseline, Ocean(S), Not associated, Open MCC\"\n",
    "query1 = 'lat1 < -43.7 & '+ Query_forCloud(C_Flag) ### for long1<145.4, the result is same \n",
    "slope = 0.535\n",
    "'''\n",
    "Sync_sec = GetSyncSec(AC_st_time, MODIS_Time) ### 1. Synchronized time between aircraft ad MODIS\n",
    "Target_st_sec, Target_end_sec = GetTargetSecs(FDate, Sync_sec)  ### 2. \n",
    "df, df_clouds = Get_dfNdf_clouds(FDate, Target_st_sec, Target_end_sec, query1, slope) ### 3. \n",
    "PlotTrack(df, df_clouds) ### 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750 24.139065852 10.9439692015\n",
      "960 25.2059270719 11.9591418268\n",
      "1201 26.5870079775 12.7000434709\n",
      "52 16.5352577184 3.31854710837 33.6713976076 19.2243957201\n"
     ]
    }
   ],
   "source": [
    "df_MODIS_1km, df_MODIS_5km, df_MODIS_10km = Get_MODISReff(FDate, df)  ### 5\n",
    "print len(df_MODIS_1km), df_MODIS_1km['reff'].mean(), df_MODIS_1km['reff'].std()\n",
    "print len(df_MODIS_5km), df_MODIS_5km['reff'].mean(), df_MODIS_5km['reff'].std()\n",
    "print len(df_MODIS_10km), df_MODIS_10km['reff'].mean(), df_MODIS_10km['reff'].std()\n",
    "print len(df_clouds), df_clouds['Reff'].mean(), df_clouds['Reff'].std(), df_clouds['Reff_Total'].mean(),df_clouds['Reff_Total'].std()\n",
    "#Save_reff(FDate, df_MODIS2,df_clouds) ### 6. save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>AC_len</th>\n",
       "      <th>AC_reff</th>\n",
       "      <th>AC_reffT</th>\n",
       "      <th>AC_reffT_std</th>\n",
       "      <th>AC_std</th>\n",
       "      <th>FDate</th>\n",
       "      <th>MODIS_len</th>\n",
       "      <th>MODIS_reff</th>\n",
       "      <th>MODIS_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 20130614_133658</td>\n",
       "      <td> 81</td>\n",
       "      <td> 9.3195</td>\n",
       "      <td> 9.773117</td>\n",
       "      <td> 1.291381</td>\n",
       "      <td> 1.074057</td>\n",
       "      <td> 20130614_133658</td>\n",
       "      <td> 398</td>\n",
       "      <td> 16.399767</td>\n",
       "      <td> 4.035156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  AC_len  AC_reff  AC_reffT  AC_reffT_std    AC_std  \\\n",
       "0  20130614_133658      81   9.3195  9.773117      1.291381  1.074057   \n",
       "\n",
       "             FDate  MODIS_len  MODIS_reff  MODIS_std  \n",
       "0  20130614_133658        398   16.399767   4.035156  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_reff = pd.read_csv('MODIS_reff_Smry.csv')\n",
    "df_reff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eunmia/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/io/excel.py:626: UserWarning: Installed openpyxl is not supported at this time. Use >=1.6.1 and <2.0.0.\n",
      "  .format(openpyxl_compat.start_ver, openpyxl_compat.stop_ver))\n",
      "-c:130: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_index,col_indexer] = value instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-43.6791810489 -43.6711590933 -43.6836145833\n",
      "148.371609193 148.381621218 148.353457113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-c:149: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_index,col_indexer] = value instead\n"
     ]
    }
   ],
   "source": [
    "### Main Script (Testing) ########################################################################################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import netCDF4\n",
    "import pandas as pd\n",
    "\n",
    "C_Flag = 'Liq'\n",
    "'''\n",
    "ncname = \"../../../../Data/2015/nc/20150830_130524.nc\" \n",
    "F_Desc = \"Research, Baseline, Ocean(S), Not associated, Open MCC\"\n",
    "#SP = [[4236,5496]]\n",
    "SP = [[4242,5442]]\n",
    "query1 = 'lat1 < -43.7 & '+ Query_forCloud(C_Flag) ### for long1<145.4, the result is same \n",
    "df3, df4, Spectrum, Spectrum_CIP, Dp, Dp_CIP = FirstMethod(ncname,'R', F_Desc, SP,query1, 0, 0.535)\n",
    "#df_Avg = Print_MP2(ncname, F_Desc, 'R', df3, df4)\n",
    "PlotTrack(df3)\n",
    "'''\n",
    "\n",
    "ncname = \"../../../../Data/2013/nc/20130614_133658.nc\"\n",
    "F_Desc = \"Research, Base, Ocean(SE), Notassociated\"\n",
    "#SP = [[2078, 3278]]\n",
    "SP = [[2078, 3278]]\n",
    "query1 = '(lat1 < -43.) & '+ Query_forCloud(C_Flag)\n",
    "df3, df4, Spectrum, Spectrum_CIP, Dp, Dp_CIP = FirstMethod(ncname,'R', F_Desc, SP,query1, 0, 0.732)\n",
    "\n",
    "PlotTrack(df3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### New - plot cmparision of LWC instruments ################################\n",
    "\n",
    "import matplotlib ### for greek symbols ###\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [0., .1,.2,.3,.4,.5,.6, 7., 8.]\n",
    "y=x\n",
    "\n",
    "from matplotlib import gridspec\n",
    "\n",
    "fig1=plt.figure(num=1,figsize=(16,4))\n",
    "#fig1.suptitle(ncname[22:37], fontsize=14)\n",
    "plt.subplots_adjust(left=0.1, right=0.9, top=0.8, bottom=0.3)\n",
    "  # deciding subplots sizes by indicating positions. 1 is the largest.\n",
    "gs = gridspec.GridSpec(1, 4, width_ratios=[1, 1, 1,1]) \n",
    "#gs = gridspec.GridSpec(1, 1) \n",
    "fig1.subplots_adjust( hspace=.1, wspace = 0.2 )\n",
    "\n",
    "# Plotting Spectra (in-clouds) on the main plot #################\n",
    "    #ax1=fig1.add_subplot(151)\n",
    "\n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.plot(df2['LWC083'], df2['LWC021'], \"b.\", alpha=0.6)\n",
    "ax0.set_xlabel('LWC083', color='k', size = 14)\n",
    "ax0.set_ylabel('LWC021', color='k', size = 14)\n",
    "#ax0.set_ylabel(r'LWC021 [g/m$^3$]', color='k')\n",
    "ax0.axis([0, 1.5, 0, 1.5])\n",
    "ax0.plot(x,y, \"r-\")\n",
    "ax0.yaxis.set_ticks(np.arange(0.3, 1.6, 0.3))\n",
    "ax0.xaxis.set_ticks(np.arange(0., 1.6, 0.3))\n",
    "\n",
    "ax1 = plt.subplot(gs[1])\n",
    "ax1.plot(df2['LWC021'], df2['LWCC'], \"b.\", alpha=0.6)\n",
    "ax1.set_xlabel('LWC021', color='k', size = 14)\n",
    "ax1.set_ylabel('CAS', color='k', size = 14)\n",
    "#ax1.axis([0, 1.5, 0, 1.5])\n",
    "ax1.axis([0, 1, 0, 1])\n",
    "ax1.plot(x,y, \"r-\")\n",
    "#ax1.yaxis.set_ticks(np.arange(0.3, 1.6, 0.3))\n",
    "ax1.yaxis.set_ticks(np.arange(0.2, 1.1, 0.2))\n",
    "#ax1.xaxis.set_ticks(np.arange(0., 1.6, 0.3))\n",
    "\n",
    "ax2 = plt.subplot(gs[2])\n",
    "#ax2.plot(df2['TWC156'], df2['LWCC']+df2['LWCCIP'], \"b.\", alpha=0.6)\n",
    "#ax2.set_xlabel('TWC156', color='k', size = 14)\n",
    "ax2.plot(df2['Wl'], df2['LWCC']+df2['LWCCIP'], \"b.\", alpha=0.6)\n",
    "ax2.set_xlabel(r'WCM (W$_{liq}$)', color='k', size = 14)\n",
    "ax2.set_ylabel('CAPS (CAS+CIP)', color='k', size = 14)\n",
    "ax2.axis([0, 1.5, 0, 1.5])\n",
    "ax2.plot(x,y, \"r-\")\n",
    "ax2.yaxis.set_ticks(np.arange(0.3, 1.6, 0.3))\n",
    "ax2.xaxis.set_ticks(np.arange(0., 1.6, 0.3))\n",
    "\n",
    "ax3 = plt.subplot(gs[3])\n",
    "ax3.plot(df2['Wl']+df2['Wi'], df2['Wl'], \"b.\", alpha=0.6)\n",
    "\n",
    "ax3.set_xlabel(r'W$_{liq}$ + W$_{ice}$', color='k', size = 14)\n",
    "ax3.set_ylabel(r'W$_{liq}$', color='k', size = 14)\n",
    "\n",
    "ax3.axis([0, 1.5, 0, 1.5])\n",
    "ax3.plot(x,y, \"r-\")\n",
    "ax3.yaxis.set_ticks(np.arange(0.3, 1.6, 0.3))\n",
    "ax3.xaxis.set_ticks(np.arange(0., 1.6, 0.3))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Print MP2 #############################################\n",
    "\n",
    "def Print_MP2(ncname, F_Desc, FType, df3, df4):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    ### Apply weights for MP and print ##########################################################################\n",
    "    import numpy as np\n",
    "\n",
    "    FDate = ncname[22:37]\n",
    "    Mon = int(ncname[26:28])\n",
    "    AvgTAS = df3['TAS'].mean()\n",
    "    Sec = len(df3)\n",
    "    Km = np.round(len(df3)*AvgTAS/1000,1)\n",
    "\n",
    "    AvgCDNC = np.round(df3['CDNC'].mean(),1);AvgReff = np.round(df3['Reff'].mean(),1);\n",
    "    AvgReffT = np.round(df3['Reff_Total'].mean(),1);AvgCDNC_CIP = np.round(df3['CIPTo'].mean(),3);\n",
    "    AvgP = np.round(df3['PStat'].mean(),1);MinP = np.round(np.max(df3[\"PStat\"]),0);MaxP = np.round(np.min(df3[\"PStat\"]),0);\n",
    "    AvgT = np.round(df3['TStat'].mean(),1);MinT = np.round(np.min(df3[\"TStat\"]), 1); MaxT = np.round(np.max(df3[\"TStat\"]),1);\n",
    "    AvgLWCC = np.round(df3['LWCC'].mean(),3);AvgLWC083 = np.round(df3['LWC083'].mean(),3);\n",
    "    AvgLWCHW = np.round(df3['LWCHW'].mean(),3);AvgLWC021 = np.round(df3['LWC021'].mean(),3);\n",
    "    AvgLWCCIP = np.round(df3['LWCCIP'].mean(),3);AvgTWC = np.round(df3['TWC156'].mean(),3);\n",
    "    AvgTWC2 = np.round(df3['Wl'].mean() + df3['Wi'].mean(),3);\n",
    "    AvgTWCCAPS = np.round(df3['TWCCAPS'].mean(),3);\n",
    "    AvgWind_D = np.round(df3['W_D'].mean(),0);AvgW_Spd = np.round(df3['W_S'].mean(),0);\n",
    "\n",
    "    df_Avg = pd.DataFrame({'FDate': FDate, 'Mon': Mon, 'Type': FType, 'Sec': Sec, 'Km': Km,\\\n",
    "                           'CDNC' : AvgCDNC, 'Reff' : AvgReff,'ReffT': AvgReffT,'CDNC_CIP': AvgCDNC_CIP,\\\n",
    "                           'AvgP' : AvgP, 'MinP': MinP, 'MaxP': MaxP,\\\n",
    "                           'AvgT': AvgT,'MinT': MinT, 'MaxT' : MaxT,\\\n",
    "                           'LWCC' : AvgLWCC, 'LWC083' : AvgLWC083,'LWCHW': AvgLWCHW, 'LWC021': AvgLWC021,\\\n",
    "                           'LWCCIP': AvgLWCCIP, 'TWC' : AvgTWC, 'TWC2' : AvgTWC2,'TWCCAPS' : AvgTWCCAPS,\\\n",
    "                           'Wind_D': AvgWind_D, 'W_Spd': AvgW_Spd} , index=[FDate])\n",
    "    return df_Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### 3-1 ###################################################################################\n",
    "##### Plotting MP and Spectra ##################################################\n",
    "\n",
    "import matplotlib ### for greek symbols ###\n",
    "#matplotlib.use('PDF')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "plt.rcParams['ps.useafm'] = True\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "plt.rcParams['pdf.fonttype'] = 42 \n",
    "\n",
    "from matplotlib import gridspec\n",
    "\n",
    "fig1=plt.figure(num=1,figsize=(16,5))\n",
    "fig1.suptitle(ncname[22:37], fontsize=14)\n",
    "plt.subplots_adjust(left=0.1, right=0.9, top=0.8, bottom=0.3)\n",
    "  # deciding subplots sizes by indicating positions. 1 is the largest.\n",
    "gs = gridspec.GridSpec(1, 4, width_ratios=[1.5, 1, 1, 1.5]) \n",
    "fig1.subplots_adjust( hspace=.1, wspace = 0.2 )\n",
    "\n",
    "#matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
    "#or matplotlib.backends is imported for the first time.\n",
    "\n",
    "# Plotting CDNC(in-clouds) on the main plot #################\n",
    "    #ax1=fig1.add_subplot(151)\n",
    "ax1 = plt.subplot(gs[0])\n",
    "#ax1.set_title('CDNC', size=12)\n",
    "ax1.set_xlabel('CDNC [#/$cm^{3}$]')\n",
    "ax1.set_ylabel('Pressure(hPa)')\n",
    "ax1.plot(df4['CDNC'], df4['PStat2'], 'r.-',label=\"CDNC\")\n",
    "ax1.plot(df4['CIPTo'], df4['PStat2'], 'g',label=\"CIPTo\")\n",
    "#ax1.errorbar(CDNC_Clouds_p, SPress,None,DevCDNC_Clouds_p/RootN)\n",
    "ax1.plot(df4['Reff'], df4['PStat2'], 'bs-', alpha=0.6, label='r$_{eff}$_CAS')\n",
    "ax1.plot(df4['Reff_Total'], df4['PStat2'], 'gs-', alpha=0.6, label='r$_{eff}$_CAS+CIP')\n",
    "ax1.axis([0,150, 1000, 650])\n",
    "ax1.set_xticks(np.arange(0, 150, 20))\n",
    "ax1.legend(loc=\"best\", prop={'size':10})\n",
    "ax1.grid(True, which='both')\n",
    "\n",
    "ax1b=ax1.twiny()\n",
    "ax1b.plot(df4['TStat'], df4['PStat2'],'y*--',label=\"TStat\")\n",
    "ax1b.axis([-15, 10, 1000,650])\n",
    "ax1b.legend(loc=\"best\", prop={'size':10})\n",
    "\n",
    "# Plotting R_eff(in-clouds) on the main plot#################\"\n",
    "ax2 = plt.subplot(gs[1],sharey=ax1 )    # Another way : ax2 = fig1.add_subplot(gs[1], sharey=ax1)\n",
    "plt.setp(ax2.get_yticklabels(), visible=False)  ### This makes yaxis lable invisible\n",
    "#ax2.set_title(\"R_eff\", size=12)\n",
    "ax2.set_xlabel(r'r$_{eff}$ [$\\mu$m]')   ### #$E^{\\alpha}_{\\beta}$\n",
    "ax2.plot(df4['Reff'], df4['PStat2'], 'bs-', alpha=0.6, label=\"CAS\")\n",
    "ax2.plot(df4['Reff_Total'], df4['PStat2'], 'gs-', alpha=0.6, label=\"CAS+CIP\")\n",
    "ax2.legend(loc=\"best\", prop={'size':10})\n",
    "ax2.axis([0,60, 1000, 650])\n",
    "ax2.grid(True, which='both') #'both' make display all lines\n",
    "\n",
    "# Plotting LWC (in-clouds) ####################################################################\n",
    "ax3 = plt.subplot(gs[2],sharey=ax1 )\n",
    "plt.setp(ax3.get_yticklabels(), visible=False) ### This makes yaxis lable invisible\n",
    "#ax3.set_title(\"LWC(in-clouds)\", size=12)\n",
    "ax3.set_xlabel(\"LWC [g/Kg]\")\n",
    "ax3.plot(df4['LWCC'], df4['PStat2'], 'bo-', alpha=0.6, label=\"CAS-LWC\")\n",
    "ax3.plot(df4['LWC083'], df4['PStat2'], 'ys-', label=\"WCM LWC083\")\n",
    "ax3.plot(df4['LWCHW'], df4['PStat2'], 'r*-', label=\"LWC-100\")\n",
    "ax3.plot(df4['TWCCAPS'], df4['PStat2'], 'go-', label=\"TWC (CAS+CIP)\")\n",
    "ax3.plot(df4['TWC156'], df4['PStat2'], 'rs-', label=\"TWC156\")\n",
    "ax3.plot(df4['LWCCIP'], df4['PStat2'], 'ko-', label=\"LWCCIP\")\n",
    "\n",
    "ax3.legend(loc=\"best\", prop={'size':10})\n",
    "ax3.axis([0, 1.5, 1000, 650])\n",
    "#ax3.errorbar(LWC_Clouds_p, SPress, None, DevLWC_Clouds_p/RootN, ecolor=\"b\")\n",
    "ax3.set_xticks(np.arange(0, 1.5, 0.2))\n",
    "ax3.grid(True, which='both')\n",
    "\n",
    "# Plotting Spectra (in-clouds) on the main plot #################\n",
    "ax5 = plt.subplot(gs[3])\n",
    "#ax5.set_title(\"Spectrum\", size=12)\n",
    "ax5.set_xlabel('Bin size [$\\mu$m]')\n",
    "ax5.set_ylabel('dN/DlogDp [#/$cm^{3}$]')\n",
    "ax5.yaxis.tick_right()\n",
    "ax5.set_xscale('log')\n",
    "ax5.set_yscale('log')\n",
    "#ax5.plot(Dp_CIP, Spectrum_CIP, 'go-')\n",
    "#ax5.plot(Dp_CIP, Spectrum_CIP, drawstyle='steps', label=\"CAS\", color='g', alpha=0.8, linewidth=2, linestyle=\"-\" )\n",
    "############## Step chart example ## 1) size should be +1 2) y[0] = 0 ########################################\n",
    "#D = [  0.54,   0.61,   0.68,   0.75,   0.82,   0.89,   0.96,   1.03,\\\n",
    "#         1.1 ,   1.17,   1.25,   1.5 ,   2.  ,   2.5 ,   3.  ,   3.5 ,\\\n",
    "#         4.  ,   5.  ,   6.5 ,   7.2 ,   7.9 ,  10.2 ,  12.5 ,  15.  ,\\\n",
    "#        20.  ,  25.  ,  30.  ,  35.  ,  40.  ,  45., 50  ]\n",
    "#Test = [0, 1,2,3,4,5,6,7,8,9,10, 11, 12, 13, 14, 15, 16, 17, 18, 19,20, 21,22,23,24,25,26,27,28,29,30]\n",
    "#ax5.step(D, Test)\n",
    "ax5.step(Dp, Spectrum, 'b-', linewidth=2)\n",
    "ax5.step(Dp_CIP, Spectrum_CIP, 'g-', linewidth=2)\n",
    "ax5.axis([0.4, 2000, 0.00001, 1000])\n",
    "ax5.grid(True, which='both')\n",
    "\n",
    "plt.tight_layout()  #when this apply, the fig title and subplots' titles are overlapped.\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
