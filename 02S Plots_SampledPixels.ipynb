{
 "metadata": {
  "name": "",
  "signature": "sha256:b34791e0aff7dbe5b80c9147def29f0df85ed3e7bbf250b265d6efdf38dbcdd9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Upgrading at 7th/Sep\n",
      "### ALL 5th/Sep/2016 --------------------------------------------------------"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### what this should do is ---- plot tracks and cal reff to plot reff of MODIS and aircraft\n",
      "#1. get Sync_sec                    ### The exact time AC and MODIS meet\n",
      "#2. Decide Target_st_sec, Target_end_sec ### For colleting AC clouds (+-15 mins)\n",
      "#3. get df & df_clouds              ### input(Target_st_sec, Target_end_sec), output(df, df_clouds)\n",
      "#2. get Target coordinates          ### input(target_st_time, target_end_time) output(target_coordinates)\n",
      "#4. plot flight track (green & red) ### Green: whole track during the target time (get all df), Red: cloud track\n",
      "                                    ### input(df,df_clouds ), output(None)\n",
      "#5. Cal ac avg                      ### input(df_clouds) output(reff, etc)\n",
      "\n",
      "#6. Cal MODIS avg                   ### input (target_coordinates) output(reff, etc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### 1. GetSyncSec: to get Synchronized time between aircraft ad MODIS\n",
      "def GetSyncSec (AC_st_time, MODIS_time):\n",
      "    \n",
      "    if FDate == '20130723_130219':   \n",
      "        Sync_sec = 5100\n",
      "    elif (FDate == \"20130806_151347\"):\n",
      "        Sync_sec = 3800\n",
      "    else:\n",
      "        Start_sec = int(AC_st_time[0:2])*3600 + int(AC_st_time[2:4])*60 + int(AC_st_time[4:6])\n",
      "        MODIS_time_local_sec = (int(MODIS_time[0:2])+10)*3600 + int(MODIS_time[2:4])*60 + int(MODIS_time[5:6])*6 ### seconds\n",
      "        Sync_sec = MODIS_time_local_sec - Start_sec ### Synchronized time between aircraft ad MODIS\n",
      "    \n",
      "    print \"Sync_sec : \", Sync_sec \n",
      "    \n",
      "    return Sync_sec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### 2. Decide the target start and end time\n",
      "def GetTargetSecs(FDate, Sync_sec, st_time_buffer, end_time_buffer):\n",
      "    '''\n",
      "    1) Exact time: Target_secs (6km)\n",
      "    2) +- 2 ms = Target_secs + 2*60 (12km)\n",
      "    3) +- 5 ms = Target_secs + 5*60 (30km)\n",
      "    4) +- 10 ms = Target_secs + 10*60 (60km)\n",
      "    '''\n",
      "    '''\n",
      "    ### for this flight, there is no clouds during MODIS overpass so decided 20 mis plus\n",
      "    if (FDate == \"20130614_133658\" or FDate == \"20140912_124317\"):\n",
      "        Target_st_sec = Sync_sec\n",
      "        Target_end_sec = Sync_sec + 20*60  ### 20 minutes plus after MODIS overpass\n",
      "    elif (FDate == \"20130707_125944\" or FDate == \"20131011_132432\"):\n",
      "        Target_st_sec = Sync_sec - 15*60  \n",
      "        Target_end_sec = Sync_sec + 15*60  ### 15 minutes plus minus from MODIS overpass  \n",
      "    else:\n",
      "        Target_st_sec = Sync_sec - 10*60  \n",
      "        Target_end_sec = Sync_sec + 10*60  ### 10 minutes plus minus from MODIS overpass\n",
      "    '''\n",
      "    Target_st_sec  = Sync_sec - st_time_buffer*60\n",
      "    Target_end_sec = Sync_sec + end_time_buffer*60  ### 15 minutes plus minus from MODIS overpass   \n",
      "\n",
      "    print FDate, \"Target_st_sec: \", Target_st_sec\n",
      "    \n",
      "    return Target_st_sec, Target_end_sec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def OpenNCFiles(ncname, ncname_S):\n",
      "    import netCDF4\n",
      "\n",
      "    ncfile = netCDF4.Dataset(ncname)        \n",
      "    ncfile_S = netCDF4.Dataset(ncname_S)   ### SODA nc file\n",
      "    \n",
      "    return ncfile, ncfile_S"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### define global variables----------------------------------------------------------------------\n",
      "### ---------------------------------------------------------------------------------------------\n",
      "\n",
      "import numpy as np\n",
      "import netCDF4\n",
      "\n",
      "ncname2 = \"../../../../Data/2013/nc/20130614_133658.nc\"\n",
      "ncfile2 = netCDF4.Dataset(ncname2) \n",
      "\n",
      "Dp = ncfile2.groups[\"CAS\"].variables['ForwardCounts_CAS'].getncattr('CellSizes')\n",
      "    ### Dp = Diameter of a particle detected in the bin = bin size\n",
      "    ### CellSizes changes by year: 2013 and 2014/2015 when Korolev Tips were equippted\n",
      "Dp = np.append(Dp,50)  ### inserting the size of the last bin maximum, so len(Dp)=31, len(Rp)=30\n",
      "    ### len(Dp) = 31, len(Rp) = 30\n",
      "Rp = [0.]*30         \n",
      "for i in range(30):\n",
      "    Rp[i] = np.sqrt([Dp[i]*Dp[i+1]])*.5   ### geometric mean r in n*r^3/n*r^2 ###\n",
      "\n",
      "###---CIP setting ----------------------------------------------------------\n",
      "CIPLastBin = 20 \n",
      "CIPDrizzleBin = 3 ### For discriminating drizzle ( > 125 microns) clouds' LWCCIP > 0.01 \n",
      "\n",
      "### len(Dp_CIP) = 20, len(Rp_CIP) = 19\n",
      "Dp_CIP = [62.5, 87.5, 112.5, 140, 175, 225, \\\n",
      "            275, 325, 400, 475, 550, \\\n",
      "            625, 700, 800, 900, 1000, \\\n",
      "            1200, 1400, 1700, 2000]\n",
      "\n",
      "Rp_CIP = [0.]*(CIPLastBin-1)  \n",
      "for i in range(CIPLastBin-1):\n",
      "    Rp_CIP[i] = np.sqrt([Dp_CIP[i]*Dp_CIP[i+1]])*.5   ### geometric mean r in n*r^3/n*r^2 ###"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ReadParameters(ncfile, ncfile_S, SP):\n",
      "########################################################################################################\n",
      "### Get parameters for a sampling duration (RL) \n",
      "### Reff will be calcuated after filtering the condition (eg clouds) \n",
      "#########################################################################################################\n",
      "    \n",
      "    import pandas as pd\n",
      "    \n",
      "    ### Sampling duration ---------------------------------------------------------------------------------\n",
      "    '''\n",
      "    Range_List = [0]*len(SP) \n",
      "    SamplingPeriod = [0]*len(SP)\n",
      "    for i in range(len(SP)):\n",
      "        Range_List[i] = range(SP[i][0],SP[i][1])\n",
      "        SamplingPeriod[i] = (SP[i][1]-SP[i][0])\n",
      "\n",
      "    RL = Range_List[0] ### RL = the list of sampling duration ([time_start, ... .., time_end])\n",
      "    '''\n",
      "    RL = range(SP[0][0], SP[0][1])\n",
      "    ### Read Airstate and CAS parameters ---------------------------------------------------------------------------------\n",
      "    long1 = ncfile.groups[\"OEM4\"].variables[\"Longitude\"][RL]\n",
      "    lat1 = ncfile.groups[\"OEM4\"].variables[\"Latitude\"][RL]#[LWC_CAS > 0.01] This part has gone to the later part\n",
      "\n",
      "    PStat = ncfile.groups[\"AirState\"].variables[\"StaticPress_Fuselage\"][RL]  \n",
      "    PA_FuseOEM = ncfile.groups[\"AirState\"].variables[\"PressureAltitudeCorrected_Fuselage\"][RL]#[LWC_CAS >0.01]\n",
      "    PA_Shadin = ncfile.groups[\"Shadin\"].variables[\"PressAltitude\"][RL]\n",
      "    TStat = ncfile.groups[\"AirState\"].variables[\"AmbientTemp_TP3S\"][RL]\n",
      "\n",
      "    CDNC_Clouds= ncfile.groups[\"CAS\"].variables[\"ForwardTotalConc_CAS\"][RL]\n",
      "    LWC_CAS= ncfile.groups[\"CAS\"].variables[\"LWC_CAS\"][RL]\n",
      "    LWCHotWire=ncfile.groups[\"CAS\"].variables[\"LWCHotWire_CAS\"][RL]\n",
      "\n",
      "    PLWC021= ncfile.groups[\"WCM\"].variables[\"PLWC021\"][RL]\n",
      "    PLWC083= ncfile.groups[\"WCM\"].variables[\"PLWC083\"][RL]\n",
      "    PTWC156 = ncfile.groups[\"WCM\"].variables[\"PTWC156\"][RL]\n",
      "\n",
      "    MeanDia_CAS  = ncfile.groups[\"CAS\"].variables[\"MeanDia_CAS\"][RL]\n",
      "    ### MeanDia_CIP  = ncfile.groups[\"CIP\"].variables[\"MeanDia_CIP\"][RL]\n",
      "    Wind_Speed  = ncfile.groups[\"AirState\"].variables[\"Wind_Speed\"][RL]\n",
      "    Wind_Direction  = ncfile.groups[\"AirState\"].variables[\"Wind_Direction\"][RL]\n",
      "    TAS = ncfile.groups[\"AirState\"].variables[\"TrueAirSpeedCorrected_TP3S\"][RL]\n",
      "\n",
      "    time = ncfile.variables[\"Time\"][RL]\n",
      "\n",
      "    ### Reads CIP(SODA) parameters-----------------------------------------------------------------------------------------\n",
      "    MeanDia_CIP  = ncfile_S.variables[\"MND100\"][RL]\n",
      "    CIPLWC= ncfile_S.variables['LWC'][RL]\n",
      "    CIPLWC_Allbins = CIPLWC\n",
      "    \n",
      "   ### for CIP ---------------------------------------------------------------------------------------                                                         \n",
      "    CDNC_CIP_bin = ncfile_S.variables['CONCENTRATION'][:] ### [#/m^4]\n",
      "    CDNC_CIP_bin = CDNC_CIP_bin.T                         ### swap the rows and columns\n",
      "    CDNC_CIP_bin = CDNC_CIP_bin[RL][:]\n",
      "\n",
      "    LWC_CIP_bin = CDNC_CIP_bin.copy()\n",
      "    ary_r = ncfile_S.variables['MIDBINS'][:]/2.\n",
      "        \n",
      "    for i in range(len(ary_r)):\n",
      "        CDNC_CIP_bin[:,i] = CDNC_CIP_bin[:,i]*(Dp_CIP[i+1]-Dp_CIP[i])*1e-12  ### Changed unit to [#/cm^3]\n",
      "           ### CDNC_CIP_bin [#/cc] = [#/cm^3], Dp_CIP[1e-6m], CONCENTRATION[#/m^4]\n",
      "        LWC_CIP_bin[:,i] = 4./3.*3.1415*np.power(ary_r[i],3)*CDNC_CIP_bin[:,i]*1e-6\n",
      "    \n",
      "    CIPLWC_Drizzle = [0.]*len(RL)\n",
      "    for i in range(len(RL)):\n",
      "        for j in range(CIPLastBin - CIPDrizzleBin):   ### repeat times\n",
      "             CIPLWC_Drizzle[i] += LWC_CIP_bin[i][j+CIPDrizzleBin-1]\n",
      "                                           \n",
      "\n",
      "    CIPConc = ncfile_S.variables['NT'][RL]   ### number concentration [#/m^3]\n",
      "    CIPConc = CIPConc*1e-6                   ### number concentration [#/cm^3]\n",
      "       ### CIPTotalConc  = ncfile.groups[\"CIP\"].variables[\"TotalConc_CIP\"][RL] # This is for CIP concentration, all bins\n",
      "\n",
      "    ### create df for the parameters ---------------------------------------------------------------------------------------\n",
      "    df= pd.DataFrame({'Time' : time, 'PStat' : PStat,'PA_FO' : PA_FuseOEM,'PA_S' : PA_Shadin,\\\n",
      "                  'long1': long1,'lat1': lat1,\\\n",
      "                  'TStat': TStat,'CDNC' : CDNC_Clouds, 'LWCC': LWC_CAS, 'LWCHW' : LWCHotWire, \\\n",
      "                  'LWC021' : PLWC021, 'LWC083' : PLWC083,'TWC156' : PTWC156, \\\n",
      "                  'CIPLWC_Drizzle': CIPLWC_Drizzle, 'LWCCIP': CIPLWC, 'LWCCIP_All': CIPLWC_Allbins,\\\n",
      "                  'CIPTo' : CIPConc, 'MD': MeanDia_CAS, 'MDCIP': MeanDia_CIP, \\\n",
      "                  'W_S': Wind_Speed, 'W_D': Wind_Direction, 'TAS': TAS})\n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def GetCDNCPerBin(ncfile, ncfile_S, SP, df, Dp_CIP):\n",
      "########################################################################################################\n",
      "### Get CDNCperBins [#/cc] = [#/cm^3] \n",
      "### CDNCperBins is required for calulating Reff and Spectra \n",
      "#########################################################################################################\n",
      "    import pandas as pd\n",
      "    import numpy as np\n",
      "    \n",
      "    #CIPLastBin = 20\n",
      "    RL = range(SP[0][0], SP[0][1])\n",
      "    ### for CAS ---------------------------------------------------------------------------------------\n",
      "    CDNC_bin = ncfile.groups[\"CAS\"].variables['ForwardConc_CAS'][RL] ### CAS forward-scatter concentration, per bin\n",
      "    LWC_bin = ncfile.groups[\"CAS\"].variables['LWCPerBin_CAS'][RL] ### CAS forward-scatter concentration, per bin\n",
      "    for m in range(30):\n",
      "        name = 'CDNC_bin'+ np.str(m)   \n",
      "        df[name] = pd.Series( CDNC_bin[:,m], index=df.index )   ### add CAS CDNCPerBin to df\n",
      "        name = 'LWC_bin'+ np.str(m)\n",
      "        df[name] = pd.Series( LWC_bin[:,m], index=df.index )   ### add CAS LWCPerBin to df\n",
      "\n",
      "    ### for CIP ---------------------------------------------------------------------------------------                                                         \n",
      "    CDNC_CIP_bin = ncfile_S.variables['CONCENTRATION'][:] ### [#/m^4]\n",
      "    CDNC_CIP_bin = CDNC_CIP_bin.T                         ### swap the rows and columns\n",
      "    CDNC_CIP_bin = CDNC_CIP_bin[RL][:]\n",
      "\n",
      "    LWC_CIP_bin = CDNC_CIP_bin.copy()\n",
      "    ary_r = ncfile_S.variables['MIDBINS'][:]/2.\n",
      "    for i in range(len(ary_r)):\n",
      "        CDNC_CIP_bin[:,i] = CDNC_CIP_bin[:,i]*(Dp_CIP[i+1]-Dp_CIP[i])*1e-12  ### Changed unit to [#/cm^3]\n",
      "           ### CDNC_CIP_bin [#/cc] = [#/cm^3], Dp_CIP[1e-6m], CONCENTRATION[#/m^4]\n",
      "        LWC_CIP_bin[:,i] = 4./3.*3.1415*np.power(ary_r[i],3)*CDNC_CIP_bin[:,i]*1e-6\n",
      "           ### LWC_CIP_bin[g/m^3]\n",
      "\n",
      "    ### add CIP_CDNCPerBin to df\n",
      "    for m in range(CIPLastBin-1): \n",
      "        name = 'CDNC_CIP_bin'+ np.str(m)   \n",
      "        df[name] = pd.Series( CDNC_CIP_bin[:,m], index=df.index )  \n",
      "        name = 'LWC_CIP_bin'+ np.str(m)   \n",
      "        df[name] = pd.Series( LWC_CIP_bin[:,m], index=df.index )\n",
      "    \n",
      "    return df, CDNC_bin, CDNC_CIP_bin"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Part of 3. ---------------------------------------------------------------------------------------------------\n",
      "### Be careful, this one doesn't matter in or base of clouds!\n",
      "def Query_forCloud(C_Flag):\n",
      "    if C_Flag == 'Liq':\n",
      "        #query_cloud ='(TWC156>0.01) & (LWCC+(LWCCIP-CIPLWC_Drizzle))>0.01 & (TWC156>LWC083)'  # or excluding cloud over and below\n",
      "        query_cloud ='((TWC156>0.01) | (LWCC + LWCCIP)>0.01 ) & CDNC > 3' ### include cloud base and top\n",
      "        #query_cloud ='(TWC156>0.005) | (LWCC + LWCCIP)>0.005' ### include cloud base and top\n",
      "    elif C_Flag == 'ND':\n",
      "        query_cloud ='((TWC156>0.01) | (LWCC + LWCCIP)>0.01 ) & CDNC > 3 & (CIPLWC_Drizzle<0.005)'\n",
      "    elif C_Flag == 'D':\n",
      "        ### CIPLWC_Drizzle ( >= 112.5) >= 0.005: is too low of drizzle         \n",
      "        query_cloud ='((TWC156>0.01) | (LWCC + LWCCIP)>0.01 ) & CDNC > 3 & (CIPLWC_Drizzle>=0.005)'\n",
      "    return query_cloud"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def InitialFiltering(df, query1, slope, ncname):\n",
      "#######################################################################################################\n",
      "### Then, filter with query 1 ##########################################################################  \n",
      "### df1 = after appling 1st query ###\n",
      "#######################################################################################################\n",
      "    import pandas as pd\n",
      "\n",
      "    df1 = df.query(query1)  ### same as df1 = df[(df.a < df.b) & (df.b < df.c)] \n",
      "                                              ### http://pandas.pydata.org/pandas-docs/dev/indexing.html\n",
      "    ### This is for calibration of WCM LWC083 ###       \n",
      "    offset = 1-slope ### However, offset0.45 is the best\n",
      "    df1['LWC083'] = df1['LWC083'] + offset*df1['TWC156']\n",
      "\n",
      "    beta = 0.1*1.12\n",
      "    Wi = (df1['TWC156']-df1['LWC083'])/(1.12-beta)\n",
      "    Wl = (df1['TWC156']-1.12*Wi)\n",
      "\n",
      "    df1['Wi'] = pd.Series(Wi, index=df1.index)\n",
      "    df1['Wl'] = pd.Series(Wl, index=df1.index)\n",
      "\n",
      "    ### process when Wi < 0   ### No zeroing needed\n",
      "    #index_minus = df1[df1['Wi'] < 0].index.tolist()\n",
      "    #df1.loc[index_minus, 'Wi'] = 0\n",
      "\n",
      "    Mew3 = df1['Wi']/(df1['Wi']+df1['Wl'])\n",
      "    df1['Mew3'] = pd.Series(Mew3, index=df1.index)    \n",
      "\n",
      "    if ncname == '../../../../Data/2013/nc/20130723_130219.nc':\n",
      "        df1['Mew3'] = pd.Series(0, index=df1.index) \n",
      "    else:\n",
      "        df1['Mew3'] = pd.Series(Mew3, index=df1.index)  \n",
      "    \n",
      "    return df1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def CalReff_CAS(CDNC_bin, df1, Dp, Rp):\n",
      "###########################################################################################################\n",
      "#### Reff: is calculated for the index item from df1 (after filtering) \n",
      "###########################################################################################################\n",
      "\n",
      "    import numpy as np\n",
      "    import pandas as pd\n",
      "\n",
      "    #RL = range(SP[0][0], SP[0][1])\n",
      "    #CDNC_bin = ncfile.groups[\"CAS\"].variables['ForwardConc_CAS'][RL] ### Range_List[0] = RL  ######\n",
      "    R_eff_Sec = [np.NaN] * len(df1.index)  ### List, only for the NECESSARY length, not len(Range_List[0]) ###\n",
      "    Child_Sec = [np.NaN] * len(df1.index)\n",
      "    Parent_Sec = [np.NaN] * len(df1.index)\n",
      "    N_bin = [0.]*30  ### total N for RL for each bin, for only Spectra\n",
      "    NoOfTime = 0   ### for only Spectra\n",
      "\n",
      "    for j in range(len(df1.index)):   ### only creates for the effective rows from df5 ###    \n",
      "        k = df1.index[j]\n",
      "        Child_Sec[j]  = 0.\n",
      "        Parent_Sec[j]  = 0.\n",
      "        for m in range(30):\n",
      "            a = np.float(CDNC_bin[k][m]*pow(Rp[m],3))      ### change array to float, otherwise ###\n",
      "                                                       ### Child_Sec[j]:array,(BUT Child_Sec: array list) ###\n",
      "            Child_Sec[j] = a + Child_Sec[j]  \n",
      "            b = np.float(CDNC_bin[k][m]*np.square(Rp[m]))\n",
      "            Parent_Sec[j] = b + Parent_Sec[j]\n",
      "            #N_bin[m] += CDNC_bin[k][m]   ### For only Spectra ###\n",
      "        NoOfTime = NoOfTime +1       ### For only Spectra ###\n",
      "        if Parent_Sec[j] <> 0:       ### added on 14/Sep/2015\n",
      "            R_eff_Sec[j] = Child_Sec[j]/Parent_Sec[j]    ### This division only possible with array ###\n",
      "\n",
      "    ### create and append the Reff row to df1 -------------------------------------------------------\n",
      "    df1['Reff'] = pd.Series(R_eff_Sec, index=df1.index)   \n",
      "\n",
      "    ### For Spectra (CAS) ------------------------------------------------------------------------------------\n",
      "\n",
      "    #Spectrum = [0.]*31\n",
      "    Spectrum = [np.NaN]*31\n",
      "    AvgN_bin = [0.]*30\n",
      "    \n",
      "    for i in range(30):\n",
      "        if NoOfTime <> 0:\n",
      "            AvgN_bin[i] = N_bin[i]/NoOfTime  ### AvgN_bin = dN\n",
      "\n",
      "    #Spectrum[0] = 0  ### for Step plot, making the y[0] = 0 ###\n",
      "    for i in range(30):\n",
      "         Spectrum[i+1] = AvgN_bin[i]/(np.log10(Dp[i+1])-np.log10(Dp[i]))  ### dN/dLogDp, dN = AvgN_bin\n",
      "\n",
      "    return df1, Spectrum"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def CalReff_Total(CDNC_bin, CDNC_CIP_bin, df1, Rp, Dp_CIP, Rp_CIP):\n",
      "###########################################################################################################\n",
      "#### Reff_Total including CIP \n",
      "###########################################################################################################\n",
      "\n",
      "    import numpy as np\n",
      "    import pandas as pd\n",
      "    \n",
      "    #CIPLastBin = 20\n",
      "    \n",
      "    R_eff_Total_Sec = [np.NaN] * len(df1.index)  ### List, only for the NECESSARY length, not len(Range_List[0]) ###\n",
      "    Child_Sec = [np.NaN] * len(df1.index)\n",
      "    Parent_Sec = [np.NaN] * len(df1.index)\n",
      "    N_bin = [0.]*30  ### total N for RL for each bin, for only Spectra\n",
      "    NoOfTime = 0   ### for only Spectra\n",
      "    N_CIP_bin = [0.]*(CIPLastBin-1)  ### Redefine N_CIP_bin for Spectra (1st bin ~ CIPLastBin bin) only\n",
      "\n",
      "    for j in range(len(df1.index)):   ### only creates for the effective rows from df5 ###    \n",
      "        k = df1.index[j]\n",
      "        Child_Sec[j]  = 0.\n",
      "        Parent_Sec[j]  = 0.\n",
      "\n",
      "        for m in range(30):\n",
      "            a = np.float(CDNC_bin[k][m]*pow(Rp[m],3))      ### change array to float, otherwise ###\n",
      "                                                       ### Child_Sec[j]:array,(BUT Child_Sec: array list) ###\n",
      "            Child_Sec[j] = a + Child_Sec[j]  \n",
      "            b = np.float(CDNC_bin[k][m]*np.square(Rp[m]))\n",
      "            Parent_Sec[j] = b + Parent_Sec[j]\n",
      "            N_bin[m] += CDNC_bin[k][m]   ### For Spectra only ###\n",
      "\n",
      "        for m in range(CIPLastBin-1):  ### repeat 31 times for Reff_Total, 3rd~33rd bins (33-3+1)\n",
      "            a2 = np.float(CDNC_CIP_bin[k][m]*pow(Rp_CIP[m],3))      ### change array to float, otherwise ###\n",
      "                                                       ### Child_Sec[j]:array,(BUT Child_Sec: array list) ###\n",
      "            Child_Sec[j] = a2 + Child_Sec[j]  \n",
      "            b2 = np.float(CDNC_CIP_bin[k][m]*np.square(Rp_CIP[m]))\n",
      "            Parent_Sec[j] = b2 + Parent_Sec[j]\n",
      "            N_CIP_bin[m] += CDNC_CIP_bin[k][m]   ### For Spectra only, so uncomment if you want to calculate for spectra###        \n",
      "        NoOfTime = NoOfTime +1       ### For Spectra only, so uncomment if you want to calculate for spectra ###\n",
      "        if Parent_Sec[j] <> 0:\n",
      "            R_eff_Total_Sec[j] = Child_Sec[j]/Parent_Sec[j]    ### This division only possible with array ###\n",
      "\n",
      "    ################## create and append the Reff row to df1 #############################################\n",
      "    df1['Reff_Total'] = pd.Series(R_eff_Total_Sec, index=df1.index)  \n",
      "\n",
      "    \n",
      "    #### For Spectra (CIP) ##############################################################################\n",
      "    ### N_CIP_bin & NoOfTime needs to calculate #########################################################\n",
      "\n",
      "    #CDNC_CIP_bin = ncfile.groups[\"CIP\"].variables['Conc_CIP'][RL] ### CIP concentration, per bin\n",
      "\n",
      "    for j in range(len(df1.index)):   ### only creates for the effective rows from df5 ###    \n",
      "        k = df1.index[j]\n",
      "        for m in range(CIPLastBin-1):\n",
      "            N_CIP_bin[m] += CDNC_CIP_bin[k][m]   ### For Spectra only from the 1st bin###\n",
      "        NoOfTime = NoOfTime +1       ### For Spectra only ###\n",
      "\n",
      "    Spectrum_CIP = [np.NaN]*(CIPLastBin-1)\n",
      "    AvgN_CIP_bin = [0.]*(CIPLastBin-1)\n",
      "    for i in range(CIPLastBin-1):  \n",
      "        if NoOfTime <> 0:\n",
      "            AvgN_CIP_bin[i] = N_CIP_bin[i]/NoOfTime   ### AvgN_CIP_bin = dN \n",
      "\n",
      "    #Spectrum_CIP[0] = 0  ### for Step plot, making the y[0] = 0 ###\n",
      "    for i in range(CIPLastBin-1): \n",
      "        Spectrum_CIP[i] = AvgN_CIP_bin[i]/(np.log10(Dp_CIP[i+1])-np.log10(Dp_CIP[i]))  ### dN/dLogDp, dN = AvgN_CIP_bin\n",
      "    \n",
      "    return df1, Spectrum_CIP"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def GetLiq_df3(df1, ncname):\n",
      "########################################################################################################\n",
      "### Get liquid clouds and Quality control   \n",
      "########################################################################################################\n",
      "    import pandas as pd\n",
      "    import numpy as np\n",
      "\n",
      "    ### Get liquid clouds -------------------------------------------------------------------------------\n",
      "    if ncname == '../../../Data/2013/nc/20130723_130219.nc':### For 0723, couldn't create Mew3 because of WCM no working\n",
      "        df_Liq2 = df1\n",
      "    else:                 \n",
      "        df_Liq2 = df1.query('(Mew3 <= 0.1 | TStat >= 0)')   ### New (10/Nov/2015) \n",
      "        ###df_Liq2 = df1.query('Mew3 > 0.1 & TStat <= 0')   ### for mixed phase clouds\n",
      "        '''### the following is not applied when using SODA\n",
      "        #### This is for deleting LWC CAPS outliers ########################################################\n",
      "        SD = (df_Liq2['TWC156']-(df_Liq2['LWCC']+df_Liq2['LWCCIP'])).std()\n",
      "        dftemp = df_Liq2[(df_Liq2['LWCC'] + df_Liq2['LWCCIP']- df_Liq2['TWC156']) > 2*SD]\n",
      "        index01 = df_Liq2.index.tolist()\n",
      "        index02 = dftemp.index.tolist()\n",
      "        minus = list(set(index01) - set(index02))\n",
      "        df_Liq2 = df_Liq2.loc[minus]\n",
      "        #################################################################################################\n",
      "        '''\n",
      "\n",
      "    df3 = df_Liq2   ### Need to separate df_Liq2 from df3 ### IMportant !!! #####################\n",
      "\n",
      "    df3.PStat = np.round (np.round(df3.PStat,-1)/10)*10 ### making the height as 10hPa unit eg. 762hPa => 760 ###\n",
      "\n",
      "    ###--------------Adding in additional info. to df3 for analysis -----------------------------------   \n",
      "    df3['TWCCAPS'] = pd.Series( df3['LWCC']+df3['LWCCIP'], index=df3.index ) ### this should be added to get std. of TWCCAPS\n",
      "    df3['FDate'] = pd.Series( ncname[22:37], index=df3.index )   \n",
      "    #df3['FType'] = pd.Series( FType, index=df3.index )          \n",
      "    df3['Mon'] = pd.Series( int(ncname[26:28]), index=df3.index )\n",
      "\n",
      "    return df3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def GetAvg_df4(df3):\n",
      "### Creating df4 #####################################################################################\n",
      "    ###del df3['Time']\n",
      "\n",
      "    import pandas as pd\n",
      "    import numpy as np\n",
      "\n",
      "    df4= df3.groupby('PStat').mean()    \n",
      "\n",
      "    ### Formatting ##################################################################\n",
      "    df4.PA_FO = np.round(df4.PA_FO ,0) ; df4.PA_S = np.round(df4.PA_S,0)\n",
      "    df4.lat1 = np.round(df4.lat1,1) ; df4.TStat = np.round(df4.TStat,1); df4.long1 = np.round(df4.long1,1) ;\n",
      "    df4.CDNC = np.round(df4.CDNC,1) ; df4.Reff = np.round(df4.Reff,1); df4.Reff_Total = np.round(df4.Reff_Total,1)\n",
      "\n",
      "    df4.LWCC = np.round(df4.LWCC,3) ; df4.LWCHW = np.round(df4.LWCHW,3)\n",
      "    df4.LWC021 = np.round(df4.LWC021,3) ; df4.LWC083 = np.round(df4.LWC083,3)\n",
      "    df4.LWCCIP = np.round(df4.LWCCIP,3) ; df4.LWCCIP_All = np.round(df4.LWCCIP_All,3)\n",
      "    df4.TWC156 = np.round(df4.TWC156,3) ; df4.TWCCAPS = np.round(df4.TWCCAPS,3); df4.Mew3 = np.round(df4.Mew3,2)\n",
      "\n",
      "    df4.MD = np.round(df4.MD,1) ;df4.CIPTo = np.round(df4.CIPTo,2);df4.MDCIP = np.round(df4.MDCIP,1)\n",
      "    df4.W_S = np.round(df4.W_S,0) ;df4.W_D = np.round(df4.W_D,0); df4.TAS = np.round(df4.TAS,0)\n",
      "\n",
      "    df4['PStat2'] = pd.Series(np.unique(df3['PStat']), index=df4.index) ### Because PStat is needed to plot, having PStat as\n",
      "                                                            ### a column is needed. \n",
      "    df4['Count'] = pd.Series(df3.groupby('PStat').count()['LWCHW'], index=df4.index)  ### adding count\n",
      "    #df4 = df4.query('CDNC > 1')\n",
      "    df4['std_CDNC'] = pd.Series((df3.groupby('PStat').std())['CDNC'], index=df4.index)\n",
      "    df4['std_CIPTo'] = pd.Series((df3.groupby('PStat').std())['CIPTo'], index=df4.index)\n",
      "    df4['std_Reff'] = pd.Series((df3.groupby('PStat').std())['Reff'], index=df4.index)\n",
      "    df4['std_ReffT'] = pd.Series((df3.groupby('PStat').std())['Reff_Total'], index=df4.index)\n",
      "    df4['std_LWCC'] = pd.Series((df3.groupby('PStat').std())['LWCC'], index=df4.index)\n",
      "    df4['std_LWCCIP'] = pd.Series((df3.groupby('PStat').std())['LWCCIP'], index=df4.index)\n",
      "    df4['std_TWCCAPS'] = pd.Series((df3.groupby('PStat').std())['TWCCAPS'], index=df4.index)\n",
      "\n",
      "    return df4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###3. get df & df_clouds              ### input(Target_st_sec, Target_end_sec), output(df, df_clouds)\n",
      "def Get_dfNdf_clouds (FDate, Target_st_sec, Target_end_sec, query1, slope, ncname_S):\n",
      "\n",
      "    import netCDF4\n",
      "    import pandas as pd\n",
      "    \n",
      "    if FDate[0:4] == '2013':\n",
      "        ncname = \"../../../../Data/2013/nc/\" + FDate + \".nc\"  \n",
      "    elif FDate[0:4] == '2014':\n",
      "        ncname = \"../../../../Data/2014/nc/\" + FDate + \".nc\"\n",
      "    elif FDate[0:4] == '2015':\n",
      "        ncname = \"../../../../Data/2015/nc/\" + FDate + \".nc\"\n",
      "        \n",
      "    SP = [[Target_st_sec,Target_end_sec]]\n",
      "    \n",
      "    ### Start of df_clouds ---------------------------------------------------------\n",
      "    ncfile, ncfile_S = OpenNCFiles(ncname, ncname_S)\n",
      "    df = ReadParameters(ncfile, ncfile_S, SP)\n",
      "    df, CDNC_bin, CDNC_CIP_bin = GetCDNCPerBin(ncfile, ncfile_S, SP, df, Dp_CIP)\n",
      "    df1 = InitialFiltering(df, query1, slope, ncname)\n",
      "    \n",
      "    df1, Spectrum = CalReff_CAS(CDNC_bin, df1, Dp, Rp)\n",
      "    df1, Spectrum_CIP = CalReff_Total(CDNC_bin, CDNC_CIP_bin, df1, Rp, Dp_CIP, Rp_CIP)\n",
      "    df_clouds = GetLiq_df3(df1, ncname)\n",
      "    df4 = GetAvg_df4(df_clouds)\n",
      "    \n",
      "    print \"len(df): \", len(df), \", len(df_clouds): \", len(df_clouds)\n",
      "    \n",
      "    return df, df_clouds, df4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Rain_Rate(df3):\n",
      "    \n",
      "    import dropvel ### import python object originally scripted by Fortran ## 01/Jul/2016\n",
      "    \n",
      "    df=df3\n",
      "\n",
      "    rhow=1e3\n",
      "    pi = 3.1415926\n",
      "    presPa = np.array(df['PStat']*100.)   ### PStat: hPa\n",
      "    # PDynamic = np.array(df['PDynamic']*100.) ### PDynamic: hPa, no need as drops spend more time in static pressure\n",
      "    # APress = presPa + PDynamic ### no need as drops spend more time in static pressure\n",
      "    tempK = np.array(df['TStat']+273.16)\n",
      "    rhoakgm3 = np.array(df['TWCCAPS'])\n",
      "    #PVapor = np.array(df['PVapor']) ### PVapor'unit: Pascal, partial water vapor pressure, no need as drops drop in dry air\n",
      "\n",
      "    ''' This is Thom's code\n",
      "    #dropradsm = ['Dp_CIP']/2.\n",
      "    #c2dca = df3['CDNC_CIP_bin'][5:33]\n",
      "    #CDNC_CIP_bin = ncfile.groups[\"CIP\"].variables['Conc_CIP'][RL]\n",
      "    #RainRate2DC(presPa,tempK,rhoakgm3,dropradsm,c2dca)\n",
      "    #dropvel.term_vel_bp(1e-4, 100000,273,1.22) ### (radius, pressure, temp, rho)\n",
      "                                           ### e-6, X 100, 273+ , mass/volume (kg/m^3)\n",
      "    '''\n",
      "    Rd = 287.058 #Specific gas constant for dry air J/(kg*K)\n",
      "    #Rv = 461.495\n",
      "    #Lv = 2.501*1e6\n",
      "    #Cpd = 1005.7\n",
      "    #g = 9.80\n",
      "    #sigma = 72.73e-3\n",
      "    \n",
      "    ary_RR = [0]*len(df)\n",
      "    rhoa = [0]*len(df)\n",
      "    for j in range(len(df)):\n",
      "        RR = 0.\n",
      "        #rhoa[j] = ( presPa[j]-PVapor[j] )/(Rd*tempK[j]) + PVapor[j]/(Rv*tempK[j]) ### Vivian used this with water vapor pressure\n",
      "                                                                            ### But I used below as drops will drop through dry air\n",
      "        rhoa[j] = presPa[j]/(Rd*tempK[j])  ### simple dry air density\n",
      "                                           ### http://www.brisbanehotairballooning.com.au/calculate-air-density/\n",
      "        for i in range(19):  ### Dp_CIP starts with 62.5 microns\n",
      "            r_median = (Dp_CIP[i] + (Dp_CIP[i+1]-Dp_CIP[i])/2.)/2.*1e-6 ### radius, unit [meter]            \n",
      "            tv = dropvel.term_vel_bp(r_median, presPa[j], tempK[j], rhoa[j]) ### terminal velocity or drop fall speed [m/sec]\n",
      "            RR += rhow*(4./3)*pi*r_median**3*df.at[df.index[j],'CDNC_CIP_bin'+np.str(i)]*1e6*tv # Be careful for the grammer\n",
      "        ary_RR[j] = RR*3600\n",
      "        \n",
      "    return np.average(ary_RR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### End of AC processing an START of MODIS ########################################################"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "km = '05km'\n",
      "print km[0:2], type(float(km[0:2]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "05 <type 'float'>\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### 5. Retrieve Reff for the coordinates from the existing MODIS file and compare this to AC's Reff\n",
      "def Get_MODISReff(FDate, df, km):\n",
      "    import numpy as npMODIS_reff_\n",
      "    import pandas as pd\n",
      "\n",
      "    ### Get coordinates from the existing MODIS file -----------------------------------\n",
      "    df_MODIS = pd.read_csv('MODIS_'+ FDate + '.csv')     ### Read(Get) MODIS data\n",
      "    #df_MODIS['CTT'] = (df_MODIS['CTT']/0.009999+15000)*0.01-273.15\n",
      "    df_MODIS['CTT'] = df_MODIS['CTT']-273.15\n",
      "  \n",
      "    if (FDate == \"20130806_151347\" ):     ### manually estimated \n",
      "        df_lat_min  = -43.05; df_lat_max  = -42.35\n",
      "        df_long_min = 143.6 ; df_long_max = 143.65\n",
      "    elif (FDate == \"20130723_130219\" ): \n",
      "        df_lat_min  = -44.7; df_lat_max  = -43.9\n",
      "        df_long_min = 146.8 ; df_long_max = 147.1\n",
      "    else:\n",
      "        df_lat_min  = df['lat1'].min()  ; df_lat_max  = df['lat1'].max()\n",
      "        df_long_min = df['long1'].min() ; df_long_max = df['long1'].max()   \n",
      "    \n",
      "    lat_min  = str( df_lat_min  - 0.01*float(km[0:2]) ) ### 1 degree = 100km, 0.05 = 5km\n",
      "    lat_max  = str( df_lat_max  + 0.01*float(km[0:2]) )\n",
      "    long_min = str( df_long_min - 0.01*float(km[0:2]) )\n",
      "    long_max = str( df_long_max + 0.01*float(km[0:2]) )    \n",
      "    \n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_16 > 0 & CPOP == 2'                                                                                \n",
      "    df_MODIS_16 = df_MODIS.query(query_Liq)  ### MODIS reff default = 1km\n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_21 > 0 & CPOP == 2'                                                                                \n",
      "    df_MODIS_21 = df_MODIS.query(query_Liq)  \n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_37 > 0 & CPOP == 2'                                                                                \n",
      "    df_MODIS_37 = df_MODIS.query(query_Liq)  \n",
      "    \n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_16_PCL > 0 & CPOP == 2'                                                                                \n",
      "    df_MODIS_16_PCL = df_MODIS.query(query_Liq)  ### MODIS reff default = 1km\n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_21_PCL > 0 & CPOP == 2'                                                                                \n",
      "    df_MODIS_21_PCL = df_MODIS.query(query_Liq)  \n",
      "    query_Liq = 'lat1 <'+lat_max+' & lat1 >'+lat_min+'& long1 >'+long_min+'& long1 <'+long_max+'& reff_37_PCL > 0 & CPOP == 2'                                                                                \n",
      "    df_MODIS_37_PCL = df_MODIS.query(query_Liq) \n",
      "    \n",
      "    print lat_min, lat_max, long_min, long_max\n",
      "    print \"len(16): \", len(df_MODIS_16), \" len(16_PCL): \", len(df_MODIS_16_PCL)\n",
      "    print \"len(21): \", len(df_MODIS_21), \" len(21_PCL): \", len(df_MODIS_21_PCL)\n",
      "    print \"len(37): \", len(df_MODIS_37), \" len(37_PCL): \", len(df_MODIS_37_PCL)\n",
      "\n",
      "    return df_MODIS_16, df_MODIS_21, df_MODIS_37,df_MODIS_16_PCL, df_MODIS_21_PCL, df_MODIS_37_PCL\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### ### Limiting the MODIS height as AC measurements -----\n",
      "\n",
      "def Align_ACHeight(df_clouds, df_MODIS, df_MODIS_PCL):\n",
      "    import numpy as np\n",
      "    \n",
      "    ### ### Limiting the MODIS height as AC measurements -----\n",
      "    Press_min = min(df_clouds['PStat']) - 30\n",
      "    Press_max = max(df_clouds['PStat']) + 30\n",
      "    query = 'CTP >'+str(Press_min)+ ' & CTP < '+ str(Press_max)\n",
      "    \n",
      "    df_MODIS = df_MODIS.query(query)  \n",
      "    df_MODIS_PCL = df_MODIS_PCL.query(query)\n",
      "    \n",
      "    print \"max, and min: \", Press_min, Press_max\n",
      "    print \"--After align the height-- len(MODIS): \", np.shape(df_MODIS), \" len(PCL): \", np.shape(df_MODIS_PCL)\n",
      "    \n",
      "    return df_MODIS, df_MODIS_PCL"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Merge MODIS channel with PCL --------------------------------------------------\n",
      "def Merge_PCL(df_M, df_M_PCL, Reff_M, Reff_M_PCL, Reff_M_MG):\n",
      "    \n",
      "    df_M = df_M.rename(columns={Reff_M: Reff_M_MG})\n",
      "    df_M_PCL = df_M_PCL.rename(columns={Reff_M_PCL: Reff_M_MG})\n",
      "    df3_M = pd.concat([df_M, df_M_PCL])\n",
      "    \n",
      "    return df3_M"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def GetAvg_df_MODIS(df3_M, Channel):\n",
      "    import pandas as pd\n",
      "    import numpy as np\n",
      "    \n",
      "    df4_M = df3_M.groupby('CTP').mean()     \n",
      "    \n",
      "    df4_M['CTP2'] = pd.Series(np.unique(df3_M['CTP']), index=df4_M.index) \n",
      "\n",
      "    Reff_M = 'reff_'+ Channel\n",
      "    \n",
      "    df4_M['std_reff'] = pd.Series((df3_M.groupby('CTP').std())[Reff_M], index=df4_M.index)\n",
      "    \n",
      "    return df4_M"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Plotting starts ############################################################################"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Subplot_Basemap(lat_min, lat_max, long_min, long_max ):\n",
      "    \n",
      "    from mpl_toolkits.basemap import Basemap\n",
      "    import numpy as np\n",
      "\n",
      "    latcorners = ([lat_min,lat_max])\n",
      "    loncorners = ([long_min,long_max])\n",
      "    m = Basemap(projection='cyl',llcrnrlat=latcorners[0],urcrnrlat=latcorners[1],\\\n",
      "                llcrnrlon=loncorners[0],urcrnrlon=loncorners[1],\\\n",
      "                resolution = 'i')\n",
      "    # Draw coastlines, state and country boundaries, edge of map.\n",
      "    m.drawcoastlines()\n",
      "    m.drawstates()\n",
      "    m.drawcountries()\n",
      "    parallels = np.arange(lat_min, lat_max,.5)\n",
      "    m.drawparallels(parallels,labels=[True,False,True,False],fontsize=8) \n",
      "    meridians = np.arange(long_min, long_max, .5)\n",
      "    m.drawmeridians(meridians,labels=[False,False,False,True],fontsize=8)\n",
      "    \n",
      "    return m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Convert(param):\n",
      "    \n",
      "    if param == 'reff_21':\n",
      "        param = 'Cloud_Effective_Radius'\n",
      "    elif param == 'reff_21_PCL':\n",
      "        param = 'Cloud_Effective_Radius_PCL'    \n",
      "    elif len(param) == 7:\n",
      "        param = 'Cloud_Effective_Radius_'+ param[5:7]   ### Cloud_Effective_Radius_16 or 37\n",
      "    else:\n",
      "        param = 'Cloud_Effective_Radius_'+ param[5:]   ### Cloud_Effective_Radius_16_PCL or 37_PCL\n",
      "    \n",
      "    return param"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Subplot_MODIS(f1, f2, m, ax, param):\n",
      "#    Subplot_MODIS(f1, f2, m, ax00, 'reff_21' )\n",
      "    \n",
      "    from scipy import array\n",
      "    from mpl_toolkits.basemap import cm\n",
      "    \n",
      "    param = Convert(param)\n",
      "    ### ----Get MODIS data from MODIS files ----------------------------------\n",
      "    data = array(f1.select(param).get()) * 0.01 ### 2.1 micron band\n",
      "    lat1 = array(f2.select('Latitude').get())  ### these lat, long are the same for Cloud phase\n",
      "    long1 = array(f2.select('Longitude').get())\n",
      "\n",
      "    # Draw filled contours.\n",
      "    clevs = np.arange(0,40,10)\n",
      "\n",
      "    # Plot every masked value as white\n",
      "    cmap = cm.GMT_drywet\n",
      "    \n",
      "    # Plot the data (MODIS reff)----------------------------------------------------\n",
      "    # make data as basemap coordinations\n",
      "    cs = m.contourf(long1,lat1,data,clevs,cmap=cmap,latlon=True)\n",
      "    #cs_PCL = m.contourf(long1,lat1,data_PCL,clevs,cmap=cmap,latlon=True)\n",
      "\n",
      "    # Add colorbar\n",
      "    cbar = m.colorbar(cs,location='right',pad=\"3%\")\n",
      "    cbar.set_label(r'r$_{eff}$ [$\\mu$m]')\n",
      "    #cbar = m.colorbar(cs_PCL,location='right',pad=\"3%\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Subplot_MODIS_Targetted(df_MODIS, m, ax, param):\n",
      "    \n",
      "    from scipy import array\n",
      "    \n",
      "    data= array(df_MODIS[param])         ### reff_21\n",
      "    lat1 = array(df_MODIS['lat1'])\n",
      "    long1 = array(df_MODIS['long1'])\n",
      "    \n",
      "    x,y = m(long1,lat1) ### MODIS pixels\n",
      "    m.plot(x,y,color=\"blue\",mfc=\"blue\",mec=\"blue\",marker=\"o\",markersize=4,alpha=0.5)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Subplot_CPOP(f1, f2, m, ax, param):\n",
      "    from scipy import array\n",
      "    from mpl_toolkits.basemap import cm\n",
      "    import matplotlib.pyplot as plt\n",
      "    \n",
      "    ### ----Get MODIS data from MODIS files ----------------------------------\n",
      "    data = array(f1.select(param).get())\n",
      "    lat1 = array(f2.select('Latitude').get())  ### these lat, long are the same for Cloud phase\n",
      "    long1 = array(f2.select('Longitude').get())\n",
      "    \n",
      "    # Draw filled contours.\n",
      "    clevs = np.arange(0.5,5.5,1) \n",
      "    cmap = plt.cm.gist_earth\n",
      "\n",
      "    # Plot the data\n",
      "    # make data as basemap coordinations\n",
      "    cs = m.contourf(long1,lat1,data,clevs,cmap=cmap,latlon=True)\n",
      "\n",
      "    # Add colorbar   \n",
      "    cbar = m.colorbar(cs,location='right',ticks=[1, 2, 3, 4], pad=\"3%\") ### this should be co-related to clevs values\n",
      "    cbar.set_ticklabels([ 'clear sky', 'Liquid', 'Ice', 'Undetermined \\n Cloud Phase']) \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Subplot_FTrack(df, m):\n",
      "    \n",
      "     ###-------- Plot Flight track------------------------------------------------\n",
      "    lat2 = list(df['lat1'][:])\n",
      "    long2 = list(df['long1'][:])\n",
      "\n",
      "    # convert the flight track latitude and longitude to base map coordinates\n",
      "    x,y = m(long2,lat2)\n",
      "    # plot the flight track\n",
      "    m.plot(x,y,color=\"red\",mfc=\"red\",mec=\"red\",marker=\",\",markersize=4,alpha=0.5)   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Get_0723_alldf():\n",
      "    \n",
      "    import netCDF4\n",
      "    import pandas as pd    \n",
      "    \n",
      "    ncname = \"../../../../Data/2013/nc/\" + FDate + \".nc\"\n",
      "    ncfile = netCDF4.Dataset(ncname)\n",
      "    long1 = ncfile.groups[\"OEM4\"].variables[\"Longitude\"][:]\n",
      "    lat1 = ncfile.groups[\"OEM4\"].variables[\"Latitude\"][:]\n",
      "    df = pd.DataFrame({'long1': long1,'lat1': lat1})\n",
      "    \n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###################################################################################################\n",
      "### Plots MODIS sampled pixels alighed with AC track ##############################################\n",
      "\n",
      "def Plot_MODISPixel(FDate, df, f1, f2, df_MODIS, df_MODIS_PCL, loc_bm):\n",
      "### 1st row: reff_21 pixels, reff_21_PCL pixels, CPOP\n",
      "### 2nd row: aligned height eff_21 pixels, reff_21_PCL pixels\n",
      "    \n",
      "    if FDate == '20130723_130219':\n",
      "        df = Get_0723_alldf()\n",
      "    \n",
      "    import matplotlib.pyplot as plt\n",
      "    #from scipy import array\n",
      "    #from mpl_toolkits.basemap import Basemap, cm\n",
      "    from pylab import imshow,colorbar,title,savefig\n",
      "    import numpy as np\n",
      "\n",
      "    from matplotlib import gridspec\n",
      "    from matplotlib import rc\n",
      "    rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
      "    plt.rcParams['ps.useafm'] = True\n",
      "    plt.rcParams['pdf.fonttype'] = 42 \n",
      "\n",
      "    fig1=plt.figure(num=1,figsize=(18,16))\n",
      "    fig1.suptitle(FDate+': reff_21', fontsize=14)\n",
      "    plt.subplots_adjust(left=0.04, right=0.9, top=0.9, bottom=0.1)\n",
      "      # deciding subplots sizes by indicating positions. 1 is the largest.\n",
      "    gs = gridspec.GridSpec(2, 3, width_ratios=[1, 1, 1]) \n",
      "    fig1.subplots_adjust( hspace=.2, wspace = 0.1 )\n",
      "\n",
      "    # Set the title and fonts for the whole figure\n",
      "    #font = {'weight' : 'bold', 'size' : 12}\n",
      "    font = {'size' : 12} ### this sets the font of color bar(cbar) tick label and lebel size\n",
      "    plt.rc('font', **font)\n",
      "\n",
      "### 1st ROW: plot MODIS reff oixels ############################################################################\n",
      "    ax00 = plt.subplot(gs[0])      \n",
      "    ax00.set_title(r'r$_{eff}$_21', size=12)\n",
      "    m = Subplot_Basemap(loc_bm[0], loc_bm[1], loc_bm[2], loc_bm[3])\n",
      "    Subplot_MODIS(f1, f2, m, ax00, 'reff_21')\n",
      "    Subplot_FTrack(df, m)\n",
      "\n",
      "    ax01 = plt.subplot(gs[1])\n",
      "    ax01.set_title(r'r$_{eff}$_21_PCL', size=12)\n",
      "    m = Subplot_Basemap(loc_bm[0], loc_bm[1], loc_bm[2], loc_bm[3])\n",
      "    Subplot_MODIS(f1, f2, m, ax01, 'reff_21_PCL' )\n",
      "    Subplot_FTrack(df, m)\n",
      "    \n",
      "    #### CPOP pixels\n",
      "    ax02 = plt.subplot(gs[2])\n",
      "    ax02.set_title('CPOP', size=12)\n",
      "    m = Subplot_Basemap(loc_bm[0], loc_bm[1], loc_bm[2], loc_bm[3])\n",
      "    Subplot_CPOP(f1, f2, m, ax02, 'Cloud_Phase_Optical_Properties')\n",
      "    Subplot_FTrack(df, m)  \n",
      "    \n",
      "### 2nd ROW: plot MODIS pixels after aligning heights ###################################################\n",
      "    ax10 = plt.subplot(gs[3])\n",
      "    ax10.set_title(r'r$_{eff}$_21 (Target Heights)', size=12)\n",
      "    m = Subplot_Basemap(loc_bm[0], loc_bm[1], loc_bm[2], loc_bm[3])\n",
      "    Subplot_MODIS_Targetted(df_MODIS, m, ax10, 'reff_21')\n",
      "    Subplot_FTrack(df, m)\n",
      "    \n",
      "    ax11 = plt.subplot(gs[4])\n",
      "    ax11.set_title(r'r$_{eff}$_21_PCL (Target Heights)', size=12)\n",
      "    m = Subplot_Basemap(loc_bm[0], loc_bm[1], loc_bm[2], loc_bm[3])\n",
      "    Subplot_MODIS_Targetted(df_MODIS_PCL, m, ax11, 'reff_21_PCL')\n",
      "    Subplot_FTrack(df, m)\n",
      "    \n",
      "    #plt.savefig(FDate+'ReffNCPhase.png',dpi=200)\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "######### Plot MODIS ###################################################################################\n",
      "#########################################################################################################\n",
      "\n",
      "def SubPlot_Reff(df4, df4_M, Reff_M, ax, lgnd_loc, reff_x, Press_y, lgnd_loc2):\n",
      "### df4: Aircraft, df4_M: MODIS, Reff_M: MODIS reff_cvariable  (df4 has std already)\n",
      "### lgnd_loc: reff_legend, lgnd_loc2: temp_legend, reff_x: x_axis, Press_y: y_axis\n",
      "\n",
      "    import matplotlib.pyplot as plt\n",
      "        \n",
      "    ax.set_ylabel(\"Pressure [hPa\")\n",
      "    ax.plot(df4['Reff'], df4['PStat2'], 'go:', alpha=0.6, label='r$_{eff}$_CAS')\n",
      "    ax.errorbar(df4['Reff'], df4['PStat2'], xerr=list(df4['std_Reff']),fmt='g') ### normal errorbar\n",
      "    ax.plot(df4['Reff_Total'], df4['PStat2'], 'bo-', alpha=0.6, label='r$_{eff}$_CAS+CIP')\n",
      "    ax.errorbar(df4['Reff_Total'], df4['PStat2'], xerr=list(df4['std_ReffT']),fmt='b') ### normal errorbar\n",
      "    \n",
      "    ax.plot(df4_M[Reff_M], df4_M['CTP2'], 'ro-', alpha=0.6, label='r$_{eff}$_MODIS_'+Reff_M[5:])\n",
      "    ax.errorbar(df4_M[Reff_M], df4_M['CTP2'], xerr=list(df4_M['std_reff']),fmt='r') ### normal errorbar\n",
      "\n",
      "    ax.axis([0, reff_x, 950, Press_y])\n",
      "    #ax00.set_xticks(np.arange(0, 50, 20))\n",
      "    ax.legend(loc=lgnd_loc, prop={'size':10})\n",
      "    ax.grid(True, which='both')\n",
      "\n",
      "    axb=ax.twiny()\n",
      "    axb.plot(df4['TStat'], df4['PStat2'],'y*--',label=\"TStat\")\n",
      "    axb.plot(df4_M['CTT'], df4_M['CTP2'],'r*',label=\"MODIS_T\")\n",
      "    axb.axis([-10, 10, 950,Press_y])\n",
      "    axb.legend(loc=lgnd_loc2, prop={'size':10})\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##### Plotting MP: Avg for MODIS ##################################################\n",
      "def Plot_Compare(FDate, df, f1, f2, df4, df4_M16, df4_M21, df4_M37,\\\n",
      "                 reff_x, Press_y, lgnd_loc, lgnd_loc2, loc_bm):\n",
      "#def Plot_Compare(df4, df4_M16, df4_M21, df4_M37, df4_M16_PCL, df4_M21_PCL, df4_M37_PCL, Flag, \\\n",
      "#                 reff_x, Press_y, lgnd_loc, lgnd_loc2):\n",
      "### 1st row: channel 16_ 21, 37 MG(overcase+PCL) pixels\n",
      "### 2nd row: Average reff of AC, MODIS_MG by Pressure  \n",
      "    \n",
      "    if FDate == '20130723_130219':\n",
      "        df = Get_0723_alldf()\n",
      "\n",
      "    import numpy as np\n",
      "    import matplotlib ### for greek symbols ###\n",
      "    import matplotlib.pyplot as plt\n",
      "    from matplotlib import rc\n",
      "    rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
      "    plt.rcParams['ps.useafm'] = True\n",
      "    rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
      "    plt.rcParams['pdf.fonttype'] = 42 \n",
      "\n",
      "    from matplotlib import gridspec\n",
      "\n",
      "    fig1=plt.figure(num=1,figsize=(18,16))\n",
      "    fig1.suptitle(FDate, fontsize=14)\n",
      "    plt.subplots_adjust(left=0.04, right=0.9, top=0.9, bottom=0.1)\n",
      "      # deciding subplots sizes by indicating positions. 1 is the largest.\n",
      "    gs = gridspec.GridSpec(2, 3, width_ratios=[1, 1,1]) \n",
      "    fig1.subplots_adjust( hspace=.2, wspace = 0.1 )\n",
      "\n",
      "    ### 1st COLUMN: 16 Channel ------------------------------------------------------------------\n",
      "    ax00 = plt.subplot(gs[0])\n",
      "    ax00.set_title(r'r$_{eff}$_16 (Merged)', size=12)\n",
      "    m = Subplot_Basemap(loc_bm[0], loc_bm[1], loc_bm[2], loc_bm[3])\n",
      "    Subplot_MODIS(f1, f2, m, ax00, 'reff_16')\n",
      "    Subplot_MODIS(f1, f2, m, ax00, 'reff_16_PCL')\n",
      "    Subplot_FTrack(df, m)\n",
      "\n",
      "    ax10 = plt.subplot(gs[3] ) \n",
      "    SubPlot_Reff(df4, df4_M16_MG, 'reff_16_MG', ax10, lgnd_loc, reff_x, Press_y, lgnd_loc2)    \n",
      "    \n",
      "    ### 2nd COLUMN: 21 Channel ------------------------------------------------------------------\n",
      "    ax01 = plt.subplot(gs[1], sharey = ax00)\n",
      "    ax01.set_title(r'r$_{eff}$_21 (Merged)', size=12)\n",
      "    m = Subplot_Basemap(loc_bm[0], loc_bm[1], loc_bm[2], loc_bm[3])\n",
      "    Subplot_MODIS(f1, f2, m, ax01, 'reff_21')\n",
      "    Subplot_MODIS(f1, f2, m, ax01, 'reff_21_PCL')\n",
      "    Subplot_FTrack(df, m)\n",
      "    \n",
      "    ax11 = plt.subplot(gs[4], sharey = ax10 )\n",
      "    plt.setp(ax11.get_yticklabels(), visible=False)\n",
      "    SubPlot_Reff(df4, df4_M21_MG, 'reff_21_MG', ax11, lgnd_loc, reff_x, Press_y, lgnd_loc2)    \n",
      "  \n",
      "    ### 3rd COLUMN:  37 Channel --------------------------------------------------------------------\n",
      "    ax02 = plt.subplot(gs[2], sharey = ax00)\n",
      "    ax02.set_title(r'r$_{eff}$_37 (Merged)', size=12)\n",
      "    m = Subplot_Basemap(loc_bm[0], loc_bm[1], loc_bm[2], loc_bm[3])\n",
      "    Subplot_MODIS(f1, f2, m, ax02, 'reff_37')\n",
      "    Subplot_MODIS(f1, f2, m, ax02, 'reff_37_PCL')\n",
      "    Subplot_FTrack(df, m)\n",
      "    \n",
      "    ax12 = plt.subplot(gs[5], sharey = ax10 )\n",
      "    plt.setp(ax12.get_yticklabels(), visible=False)\n",
      "    SubPlot_Reff(df4, df4_M37_MG, 'reff_37_MG', ax12, lgnd_loc, reff_x, Press_y, lgnd_loc2)   ### Plotting LWC (in-clouds) \n",
      "    \n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Save_MP(FDate, km, Sync_sec, Target_st_sec, df, df_clouds, df4, df_clouds_D, RR, \\\n",
      "            df_MODIS_16, df_MODIS_16_PCL, \\\n",
      "            df_MODIS_21, df_MODIS_21_PCL, \\\n",
      "            df_MODIS_37, df_MODIS_37_PCL, \\\n",
      "            df4_M16, df4_M21, df4_M37, \\\n",
      "            df4_M16_MG, df4_M21_MG, df4_M37_MG):\n",
      "    \n",
      "    import pandas as pd\n",
      "   \n",
      "    DFraction = len(df_clouds_D)/float(len(df_clouds))\n",
      "    df = pd.DataFrame({'FDate': FDate, 'km': km, 'Sync_sec': Sync_sec, 'Target_st_sec': Target_st_sec, \\\n",
      "                   'len_df': len(df), 'len_df_clouds': len(df_clouds),\\\n",
      "                   'DFraction': DFraction, 'RR': RR, \\\n",
      "                   'Reff'   : np.mean(df_clouds['Reff']),   'std_Reff' : np.std(df_clouds['Reff']),\\\n",
      "                   'Reff_Total'  : np.mean(df_clouds['Reff_Total']),  'std_ReffT': np.std(df_clouds['Reff_Total']),\\\n",
      "                   'len_16' : len(df_MODIS_16), 'len_16_PCL': len(df_MODIS_16_PCL), \\\n",
      "                   'len_21' : len(df_MODIS_21), 'len_21_PCL': len(df_MODIS_21_PCL), \\\n",
      "                   'len_37' : len(df_MODIS_37), 'len_37_PCL': len(df_MODIS_37_PCL),\\\n",
      "                   'Reff_16': np.mean(df4_M16['reff_16']), 'std_Reff_16': np.std(df4_M16['reff_16']),\\\n",
      "                   'Reff_21': np.mean(df4_M21['reff_21']), 'std_Reff_21': np.std(df4_M21['reff_21']),\\\n",
      "                   'Reff_37': np.mean(df4_M37['reff_37']), 'std_Reff_37': np.std(df4_M37['reff_37']), \\\n",
      "                   'Reff_16_MG': np.mean(df4_M16_MG['reff_16_MG']), 'std_Reff_16_MG': np.std(df4_M16_MG['reff_16_MG']),\\\n",
      "                   'Reff_21_MG': np.mean(df4_M21_MG['reff_21_MG']), 'std_Reff_21_MG': np.std(df4_M21_MG['reff_21_MG']),\\\n",
      "                   'Reff_37_MG': np.mean(df4_M37_MG['reff_37_MG']), 'std_Reff_37_MG': np.std(df4_M37_MG['reff_37_MG'])\\\n",
      "                    },index=[FDate])\n",
      "    \n",
      "    if FDate == \"20130614_133658\" :\n",
      "        df.to_csv('./CompareMP/CompareMP.csv', mode='w')\n",
      "    else:\n",
      "        df.to_csv('./CompareMP/CompareMP.csv', mode='a', header=False)\n",
      "        \n",
      "    ###"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "######################################################################################################\n",
      "### Main script ######################################################################################\n",
      "import pandas as pd\n",
      "\n",
      "#C_Flag = 'Liq'\n",
      "#df_FInfo= pd.read_csv('Flight_info2.csv')\n",
      "\n",
      "#km = '10km'\n",
      "#km = '05km'\n",
      "km = '10km'\n",
      "\n",
      "\n",
      "### (1) ------------------------------------------\n",
      "FDate = \"20130614_133658\"; AC_st_time = '133658'\n",
      "#MODIS_Time = '0421.6' ### This should be saved in the FlightInfo, and should be provide this form including decimal\n",
      "MODIS_Time = '0420.0'\n",
      "query1 = '(lat1 < -43.) & '+ Query_forCloud('Liq')\n",
      "queryD = '(lat1 < -43.) & '+ Query_forCloud('D')\n",
      "slope = 0.732\n",
      "M_fname1 = \"./20130614/Reff/MYD06_L2.A2013165.0420.006.2014266205611.hdf\"\n",
      "M_fname2 = \"./20130614/Reff/MYD03.A2013165.0420.006.2013165155508.hdf\"\n",
      "ncname_S = '../SODA/SODA_nc/06142013_133659_CIP10.nc' ## \n",
      "reff_x = 60; Press_y = 750;  lgnd_loc = \"upper right\"; lgnd_loc2 = \"upper left\"\n",
      "st_time_buffer = 0; end_time_buffer = 30   ### should be end_time_buffer = 30\n",
      "loc_bm = [-46, -41.5, 144.5, 149]\n",
      "'''\n",
      "### (2) ------------------------------------------\n",
      "FDate = \"20130628_130139\"\n",
      "AC_st_time = FDate[9:15]; MODIS_Time = '0434.0'   \n",
      "#query_part = df_FInfo[df_FInfo.query('F_date == '+FDate)]['Query1']\n",
      "#query1 = query_part + Query_forCloud(C_Flag) \n",
      "query1 = '(lat1 < -43.5 | long1 < 146) & '+ Query_forCloud('Liq') ### for long1<145.4, the result is same \n",
      "slope = 0.720\n",
      "M_fname1 = \"./20130628/Reff/MYD06_L2.A2013179.0430.006.2014267001301.hdf\"\n",
      "M_fname2 = \"./20130628/Reff/MYD03.A2013179.0430.006.2013179161739.hdf\"\n",
      "ncname_S = '../SODA/SODA_nc/06282013_130141_CIP10.nc'\n",
      "queryD = '(lat1 < -43.5 | long1 < 146) & '+ Query_forCloud('D')\n",
      "reff_x = 60; Press_y = 750;  lgnd_loc = \"upper right\"; lgnd_loc2 = \"upper left\"\n",
      "st_time_buffer = 15; end_time_buffer = 15\n",
      "loc_bm = [-46, -41.5, 144.5, 149]\n",
      "\n",
      "### (3) ------------------------------------------\n",
      "FDate = \"20130707_125944\"\n",
      "AC_st_time = '125944'\n",
      "MODIS_Time = '0428.0' ### This should be saved in the FlightInfo, and should be provide this form including decimal\n",
      "query1 = '(lat1 < -43.5 & long1 < 147.5) & '+ Query_forCloud('Liq')\n",
      "slope = 0.678\n",
      "M_fname1 = \"./20130707/Reff/MYD06_L2.A2013188.0425.006.2014267025147.hdf\"\n",
      "M_fname2 = \"./20130707/Reff/MYD03.A2013188.0425.006.2013188151355.hdf\"\n",
      "ncname_S = '../SODA/SODA_nc/07072013_073754_CIP10.nc'\n",
      "queryD = '(lat1 < -43.5 & long1 < 147.5) & '+ Query_forCloud('D')\n",
      "reff_x = 60; Press_y = 750;  lgnd_loc = \"lower right\"; lgnd_loc2 = \"upper right\"\n",
      "st_time_buffer = 15; end_time_buffer = 15\n",
      "loc_bm = [-46, -41.5, 144.5, 149]\n",
      "\n",
      "### (4) ------------------------------------------\n",
      "FDate = \"20130723_130219\"\n",
      "AC_st_time = FDate[9:15]; MODIS_Time = '0427.8'  \n",
      "F_Desc = \"Research\"\n",
      "query1 = '(LWCC+LWCCIP > 0.01) & CDNC > 3'\n",
      "slope = 0.75\n",
      "M_fname1 = \"./20130723/Reff/MYD06_L2.A2013204.0425.006.2014267101648.hdf\"  \n",
      "M_fname2 = \"./20130723/Reff/MYD03.A2013204.0425.006.2013205024031.hdf\"\n",
      "ncname_S = '../SODA/SODA_nc/07232013_130221_CIP10.nc'\n",
      "queryD = '(LWCC+LWCCIP > 0.01) & CDNC > 3 & LWCCIP > 0.005'\n",
      "reff_x = 60; Press_y = 750;  lgnd_loc = \"center right\"; lgnd_loc2 = \"upper right\"\n",
      "st_time_buffer = 15; end_time_buffer = 15\n",
      "loc_bm = [-46, -41.5, 144.5, 149]\n",
      "\n",
      "### (5) ------------------------------------------\n",
      "FDate = \"20130806_151347\" ### AC flew after MODIS overpass  \n",
      "AC_st_time = FDate[9:15]; MODIS_Time = '0440.0'\n",
      "F_Desc = \"Research\"\n",
      "query1 = '(long1 < 145.5 & lat1 < -42.1) & '+ Query_forCloud('Liq')\n",
      "slope = 0.75\n",
      "M_fname1 = \"./20130806/Reff/MYD06_L2.A2013218.0440.006.2014267174320.hdf\" ### AC flew after overpass\n",
      "M_fname2 = \"./20130806/Reff/MYD03.A2013218.0440.006.2013218171157.hdf\"\n",
      "ncname_S = '../SODA/SODA_nc/08062013_151349_CIP10.nc'\n",
      "queryD = '(long1 < 145.5 & lat1 < -42.1) & '+ Query_forCloud('D')\n",
      "reff_x = 60; Press_y = 750;  lgnd_loc = \"lower right\"; lgnd_loc2 = \"upper right\"\n",
      "st_time_buffer = 10; end_time_buffer = 20\n",
      "loc_bm = [-46, -41.5, 142,145.5]\n",
      "\n",
      "### (6) ------------------------------------------\n",
      "FDate = \"20130815_122404\" \n",
      "AC_st_time = FDate[9:15]; MODIS_Time = '0434.0'   \n",
      "F_Desc = \"Research, Non-Baseline, Ocean(W=>SW), Prefrontal(middle), Not MCC\"\n",
      "query1 = '(long1 < 145.2 | lat1 < -43.6) & '+ Query_forCloud('Liq')\n",
      "slope = 0.881\n",
      "M_fname1 = \"./20130815/Reff/MYD06_L2.A2013227.0430.006.2014267173440.hdf\"  \n",
      "M_fname2 = \"./20130815/Reff/MYD03.A2013227.0430.006.2013227204402.hdf\"\n",
      "ncname_S = '../SODA/SODA_nc/08152013_122405_CIP10.nc'\n",
      "queryD = '(long1 < 145.2 | lat1 < -43.6) & '+ Query_forCloud('D')\n",
      "reff_x = 60; Press_y = 700;  lgnd_loc = \"lower right\"; lgnd_loc2 = \"upper right\"\n",
      "st_time_buffer = 15; end_time_buffer = 15\n",
      "loc_bm = [-46, -41.5, 142.5, 147]\n",
      "\n",
      "### (7) ------------------------------------------\n",
      "FDate = \"20130907_122442\"\n",
      "AC_st_time = FDate[9:15]; MODIS_Time = '0439.0'   \n",
      "query1 = '(long1 < 145.6 | lat1 < -43.3) & '+ Query_forCloud('Liq')\n",
      "slope = 0.538\n",
      "M_fname1 = \"./20130907/Reff/MYD06_L2.A2013250.0435.006.2014267090313.hdf\"  \n",
      "M_fname2 = \"./20130907/Reff/MYD03.A2013250.0435.006.2013250172454.hdf\"\n",
      "ncname_S = '../SODA/SODA_nc/07072013_073754_CIP10.nc'\n",
      "queryD = '(long1 < 145.6 | lat1 < -43.3) & '+ Query_forCloud('D')\n",
      "reff_x = 60; Press_y = 750;  lgnd_loc = \"lower right\"; lgnd_loc2 = \"upper right\"\n",
      "st_time_buffer = 20; end_time_buffer = 10  ### end_time_buffer should be 10\n",
      "loc_bm = [-46, -41.5, 144.5, 149]\n",
      "\n",
      "### (8) ------------------------------------------\n",
      "FDate = \"20131011_132432\"\n",
      "AC_st_time = '132432'; MODIS_Time = '0427.6'  \n",
      "query1 = '(lat1 < -43.5) & '+ Query_forCloud('Liq')\n",
      "slope = 0.799\n",
      "M_fname1 = \"./20131011/Reff/MYD06_L2.A2013284.0425.006.2014268093706.hdf\"\n",
      "M_fname2 = \"./20131011/Reff/MYD03.A2013284.0425.006.2013298033119.hdf\"\n",
      "ncname_S = '../SODA/SODA_nc/10112013_132433_CIP10.nc'\n",
      "queryD = '(lat1 < -43.5) & '+ Query_forCloud('D')\n",
      "reff_x = 60; Press_y = 500;  lgnd_loc = \"lower right\"; lgnd_loc2 = \"upper right\"\n",
      "st_time_buffer = 15; end_time_buffer = 15\n",
      "loc_bm = [-46, -41.5, 144.5, 149]\n",
      "\n",
      "### (9) NOT included ------------------------------------------\n",
      "FDate=\"20140806_150804\"   ### Seeding flight\n",
      "AC_st_time = '150804' ; MODIS_Time = '0409.0'\n",
      "query1 ='(lat1 < -43 ) & '+ Query_forCloud('Liq')\n",
      "slope = 0.75\n",
      "M_fname1 = \"./20140806/Reff/MYD06_L2.A2014218.0405.006.2014271211204.hdf\"  \n",
      "M_fname2 = \"./20140806/Reff/MYD03.A2014218.0405.006.2014220175309.hdf\"\n",
      "ncname_S = '../SODA/SODA_nc/08062014_150806_CIP7.nc'\n",
      "query1 ='(lat1 < -43 ) & '+ Query_forCloud('D')\n",
      "reff_x = 60; Press_y = 500;  lgnd_loc = \"lower right\"\n",
      "\n",
      "### (10) ------------------------------------------\n",
      "FDate=\"20140903_124321\"\n",
      "AC_st_time = '124321' ; MODIS_Time = '0434.0'\n",
      "query1 ='((long1 < 146 & lat1 < -43.3 ) | lat1 < -43.5 ) & '+ Query_forCloud('Liq')\n",
      "slope = 0.774\n",
      "M_fname1 = \"./20140903/Reff/MYD06_L2.A2014246.0430.006.2014272144020.hdf\"  \n",
      "M_fname2 = \"./20140903/Reff/MYD03.A2014246.0430.006.2014246153856.hdf\"\n",
      "ncname_S = '../SODA/SODA_nc/09032014_124323_CIP7.nc'\n",
      "queryD='((long1 < 146 & lat1 < -43.3 ) | lat1 < -43.5 ) & '+ Query_forCloud('D')\n",
      "reff_x = 60; Press_y = 650;  lgnd_loc = \"center right\"; lgnd_loc2 = \"upper right\"\n",
      "st_time_buffer = 15; end_time_buffer = 15\n",
      "loc_bm = [-46, -41.5, 144.5, 149]\n",
      "\n",
      "### (11) ------------------------------------------\n",
      "FDate=\"20140912_124317\"\n",
      "AC_st_time = '124317' ; MODIS_Time = '0427.7'\n",
      "query1 ='lat1 < -43.7 & '+ Query_forCloud('Liq')\n",
      "slope = 0.744\n",
      "M_fname1 = \"./20140912/Reff/MYD06_L2.A2014255.0425.006.2014282201310.hdf\"  \n",
      "M_fname2 = \"./20140912/Reff/MYD03.A2014255.0425.006.2014261140010.hdf\"\n",
      "ncname_S = '../SODA/SODA_nc/09122014_124319_CIP7.nc'\n",
      "query1 ='lat1 < -43.7 & '+ Query_forCloud('D')\n",
      "reff_x = 60; Press_y = 700;  lgnd_loc = \"lower right\"; lgnd_loc2 = \"upper right\"\n",
      "st_time_buffer = 0; end_time_buffer = 30\n",
      "loc_bm = [-46, -41.5, 144.5, 149]\n",
      "\n",
      "### (12) ------------------------------------------\n",
      "FDate = \"20150830_130524\"\n",
      "AC_st_time = '130525'\n",
      "MODIS_Time = '0426.0'   ### should be provide this form including decimal\n",
      "F_Desc = \"Research, Baseline, Ocean(S), Not associated, Open MCC\"\n",
      "query1 = 'lat1 < -43.7 & '+ Query_forCloud('Liq') ### for long1<145.4, the result is same \n",
      "slope = 0.535\n",
      "M_fname1 = \"./20150830/Reff/MYD06_L2.A2015242.0425.006.2015243234239.hdf\"\n",
      "M_fname2 = \"./20150830/Reff/MYD03.A2015242.0425.006.2015243130645.hdf\"\n",
      "ncname_S = '../SODA/SODA_nc/08302015_130525_CIP7.nc'\n",
      "queryD = 'lat1 < -43.7 & '+ Query_forCloud('D')\n",
      "reff_x = 60; Press_y = 750;  lgnd_loc = \"upper right\"; lgnd_loc2 = \"upper left\"\n",
      "st_time_buffer = 15; end_time_buffer = 15\n",
      "loc_bm = [-46, -41.5, 144.5, 149]\n",
      "\n",
      "### (13) ------------------------------------------\n",
      "FDate = \"20151001_123025\"\n",
      "AC_st_time = FDate[9:15]\n",
      "MODIS_Time = '0427.5'   ### should be provide this form including decimal\n",
      "F_Desc = \"Research\"\n",
      "query1 = '(lat1 < -43.6 ) & '+ Query_forCloud('Liq')\n",
      "slope = 0.783\n",
      "M_fname1 = \"./20151001/Reff/MYD06_L2.A2015274.0425.006.2015274203619.hdf\"  \n",
      "M_fname2 = \"./20151001/Reff/MYD03.A2015274.0425.006.2015274154732.hdf\"\n",
      "ncname_S = '../SODA/SODA_nc/10012015_123026_CIP7.nc'\n",
      "queryD = '(lat1 < -43.6 ) & '+ Query_forCloud('D')\n",
      "reff_x = 60; Press_y = 750;  lgnd_loc = \"upper right\"; lgnd_loc2 = \"upper left\"\n",
      "st_time_buffer = 15; end_time_buffer = 15\n",
      "loc_bm = [-46, -41.5, 144.5, 149]\n",
      "'''\n",
      "print \"  \" "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/eunmia/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/io/excel.py:626: UserWarning: Installed openpyxl is not supported at this time. Use >=1.6.1 and <2.0.0.\n",
        "  .format(openpyxl_compat.start_ver, openpyxl_compat.stop_ver))\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyhdf.SD import SD\n",
      "\n",
      "Sync_sec = GetSyncSec(AC_st_time, MODIS_Time) ### 1. Synchronized time between aircraft ad MODIS\n",
      "\n",
      "Target_st_sec, Target_end_sec = GetTargetSecs(FDate, Sync_sec, st_time_buffer, end_time_buffer)  ### 2.Get target sec in AC\n",
      "\n",
      "df, df_clouds, df4 = Get_dfNdf_clouds(FDate, Target_st_sec, Target_end_sec, query1, slope, ncname_S) ### 3.Get AC df, df4(Avg)\n",
      "  ### df: aligned, df_clouds: whole flight in clouds\n",
      "\n",
      "RR = Rain_Rate(df_clouds)                                                                            ### 4.Cal RR\n",
      "### 4-1.Get Drizzle df\n",
      "df_D, df_clouds_D, df4_D = Get_dfNdf_clouds(FDate, Target_st_sec, Target_end_sec, queryD, slope, ncname_S)  \n",
      "    \n",
      "df_MODIS_16, df_MODIS_21, df_MODIS_37,\\\n",
      "                df_MODIS_16_PCL, df_MODIS_21_PCL, df_MODIS_37_PCL = Get_MODISReff(FDate, df, km)  ### 5. Cal MODIS df\n",
      "\n",
      "df_MODIS_16, df_MODIS_16_PCL = Align_ACHeight(df_clouds, df_MODIS_16, df_MODIS_16_PCL) ### 5-2 Limit the height of MODIS to align with AC height\n",
      "df_MODIS_21, df_MODIS_21_PCL = Align_ACHeight(df_clouds, df_MODIS_21, df_MODIS_21_PCL) \n",
      "df_MODIS_37, df_MODIS_37_PCL = Align_ACHeight(df_clouds, df_MODIS_37, df_MODIS_37_PCL) \n",
      "\n",
      "df4_M16 = GetAvg_df_MODIS (df_MODIS_16, '16')           ### 6.Cal MODIS avgMP\n",
      "df4_M21 = GetAvg_df_MODIS (df_MODIS_21, '21' )\n",
      "df4_M37 = GetAvg_df_MODIS (df_MODIS_37, '37')\n",
      "df4_M16_PCL = GetAvg_df_MODIS(df_MODIS_16_PCL, '16_PCL') \n",
      "df4_M21_PCL = GetAvg_df_MODIS(df_MODIS_21_PCL, '21_PCL')\n",
      "df4_M37_PCL = GetAvg_df_MODIS(df_MODIS_37_PCL, '37_PCL')\n",
      "\n",
      "\n",
      "df_M16_MG = Merge_PCL(df_MODIS_16, df_MODIS_16_PCL, 'reff_16', 'reff_16_PCL', 'reff_16_MG')  ###6-1. Merged_MODIS data with PCL\n",
      "df_M21_MG = Merge_PCL(df_MODIS_21, df_MODIS_21_PCL, 'reff_21', 'reff_21_PCL', 'reff_21_MG')\n",
      "df_M37_MG = Merge_PCL(df_MODIS_37, df_MODIS_37_PCL, 'reff_37', 'reff_37_PCL', 'reff_37_MG')\n",
      "\n",
      "df4_M16_MG = GetAvg_df_MODIS (df_M16_MG, '16_MG')        ### 6-1.Cal Merged_MODIS avgMP\n",
      "df4_M21_MG = GetAvg_df_MODIS (df_M21_MG, '21_MG')\n",
      "df4_M37_MG = GetAvg_df_MODIS (df_M37_MG, '37_MG')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Sync_sec :  5296\n",
        "20130707_125944 Target_st_sec:  4396\n",
        "len(df): "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1800 , len(df_clouds):  72\n",
        "len(df): "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1800 , len(df_clouds):  0\n",
        "-45.1447806217"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -43.8698352917 146.608313568 147.311468538\n",
        "len(16):  380  len(16_PCL):  234\n",
        "len(21):  842  len(21_PCL):  668\n",
        "len(37):  1079  len(37_PCL):  804\n",
        "max, and min:  750.0 870.0\n",
        "--After align the height-- len(MODIS):  (124, 32)  len(PCL):  (75, 32)\n",
        "max, and min: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 750.0 870.0\n",
        "--After align the height-- len(MODIS):  (306, 32)  len(PCL):  (269, 32)\n",
        "max, and min: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 750.0 870.0\n",
        "--After align the height-- len(MODIS):  (440, 32)  len(PCL):  (346, 32)\n"
       ]
      }
     ],
     "prompt_number": 144
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### read a file\n",
      "f1=SD(M_fname1)\n",
      "f2=SD(M_fname2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 145
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#df_MODIS = df_M21_MG\n",
      "#Plot_MODISPixel(FDate, df, f1, f2, df_MODIS)\n",
      "Plot_MODISPixel(FDate, df, f1, f2, df_MODIS_21, df_MODIS_21_PCL, loc_bm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "WARNING: x coordinate not montonically increasing - contour plot\n",
        "may not be what you expect.  If it looks odd, your can either\n",
        "adjust the map projection region to be consistent with your data, or\n",
        "(if your data is on a global lat/lon grid) use the shiftgrid\n",
        "function to adjust the data to be consistent with the map projection\n",
        "region (see examples/contour_demo.py).WARNING: x coordinate not montonically increasing - contour plot\n",
        "may not be what you expect.  If it looks odd, your can either\n",
        "adjust the map projection region to be consistent with your data, or\n",
        "(if your data is on a global lat/lon grid) use the shiftgrid\n",
        "function to adjust the data to be consistent with the map projection\n",
        "region (see examples/contour_demo.py)."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "WARNING: x coordinate not montonically increasing - contour plot\n",
        "may not be what you expect.  If it looks odd, your can either\n",
        "adjust the map projection region to be consistent with your data, or\n",
        "(if your data is on a global lat/lon grid) use the shiftgrid\n",
        "function to adjust the data to be consistent with the map projection\n",
        "region (see examples/contour_demo.py)."
       ]
      }
     ],
     "prompt_number": 146
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Plot_Compare(FDate, df, f1, f2, df4, df4_M16_MG, df4_M21_MG, df4_M37_MG, reff_x, Press_y, lgnd_loc, lgnd_loc2, loc_bm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "WARNING: x coordinate not montonically increasing - contour plot\n",
        "may not be what you expect.  If it looks odd, your can either\n",
        "adjust the map projection region to be consistent with your data, or\n",
        "(if your data is on a global lat/lon grid) use the shiftgrid\n",
        "function to adjust the data to be consistent with the map projection\n",
        "region (see examples/contour_demo.py).WARNING: x coordinate not montonically increasing - contour plot\n",
        "may not be what you expect.  If it looks odd, your can either\n",
        "adjust the map projection region to be consistent with your data, or\n",
        "(if your data is on a global lat/lon grid) use the shiftgrid\n",
        "function to adjust the data to be consistent with the map projection\n",
        "region (see examples/contour_demo.py)."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "WARNING: x coordinate not montonically increasing - contour plot\n",
        "may not be what you expect.  If it looks odd, your can either\n",
        "adjust the map projection region to be consistent with your data, or\n",
        "(if your data is on a global lat/lon grid) use the shiftgrid\n",
        "function to adjust the data to be consistent with the map projection\n",
        "region (see examples/contour_demo.py).WARNING: x coordinate not montonically increasing - contour plot\n",
        "may not be what you expect.  If it looks odd, your can either\n",
        "adjust the map projection region to be consistent with your data, or\n",
        "(if your data is on a global lat/lon grid) use the shiftgrid\n",
        "function to adjust the data to be consistent with the map projection\n",
        "region (see examples/contour_demo.py)."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "WARNING: x coordinate not montonically increasing - contour plot\n",
        "may not be what you expect.  If it looks odd, your can either\n",
        "adjust the map projection region to be consistent with your data, or\n",
        "(if your data is on a global lat/lon grid) use the shiftgrid\n",
        "function to adjust the data to be consistent with the map projection\n",
        "region (see examples/contour_demo.py).WARNING: x coordinate not montonically increasing - contour plot\n",
        "may not be what you expect.  If it looks odd, your can either\n",
        "adjust the map projection region to be consistent with your data, or\n",
        "(if your data is on a global lat/lon grid) use the shiftgrid\n",
        "function to adjust the data to be consistent with the map projection\n",
        "region (see examples/contour_demo.py)."
       ]
      }
     ],
     "prompt_number": 147
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### 7. save the df of MODIS and AC\n",
      "Save_MP(FDate, km, Sync_sec, Target_st_sec, df, df_clouds, df4, df_clouds_D, RR, \\\n",
      "        df_MODIS_16, df_MODIS_16_PCL, \\\n",
      "        df_MODIS_21, df_MODIS_21_PCL, \\\n",
      "        df_MODIS_37, df_MODIS_37_PCL, \\\n",
      "        df4_M16, df4_M21, df4_M37, \\\n",
      "        df4_M16_MG, df4_M21_MG, df4_M37_MG)\n",
      "\n",
      "#Plot_Compare(df4, df4_M16, df4_M21, df4_M37)                          ### 8. Plot the AvgMP by height"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "df_reff = pd.read_csv('./CompareMP/CompareMP.csv')\n",
      "df_reff"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Unnamed: 0</th>\n",
        "      <th>DFraction</th>\n",
        "      <th>FDate</th>\n",
        "      <th>RR</th>\n",
        "      <th>Reff</th>\n",
        "      <th>Reff_16</th>\n",
        "      <th>Reff_16_MG</th>\n",
        "      <th>Reff_21</th>\n",
        "      <th>Reff_21_MG</th>\n",
        "      <th>Reff_37</th>\n",
        "      <th>...</th>\n",
        "      <th>len_df</th>\n",
        "      <th>len_df_clouds</th>\n",
        "      <th>std_Reff</th>\n",
        "      <th>std_ReffT</th>\n",
        "      <th>std_Reff_16</th>\n",
        "      <th>std_Reff_16_MG</th>\n",
        "      <th>std_Reff_21</th>\n",
        "      <th>std_Reff_21_MG</th>\n",
        "      <th>std_Reff_37</th>\n",
        "      <th>std_Reff_37_MG</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> 20130614_133658</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 20130614_133658</td>\n",
        "      <td> 0.001087</td>\n",
        "      <td>  9.403660</td>\n",
        "      <td> 15.866180</td>\n",
        "      <td> 15.423497</td>\n",
        "      <td> 19.114405</td>\n",
        "      <td> 18.627216</td>\n",
        "      <td> 16.595825</td>\n",
        "      <td>...</td>\n",
        "      <td> 1800</td>\n",
        "      <td> 382</td>\n",
        "      <td> 1.469366</td>\n",
        "      <td>  1.541616</td>\n",
        "      <td> 1.151517</td>\n",
        "      <td> 0.325904</td>\n",
        "      <td> 0.757555</td>\n",
        "      <td> 0.255367</td>\n",
        "      <td> 0.131673</td>\n",
        "      <td> 0.296087</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> 20130628_130139</td>\n",
        "      <td> 0.858740</td>\n",
        "      <td> 20130628_130139</td>\n",
        "      <td> 0.416804</td>\n",
        "      <td> 14.326045</td>\n",
        "      <td> 16.269451</td>\n",
        "      <td> 16.456296</td>\n",
        "      <td> 24.325519</td>\n",
        "      <td> 23.519631</td>\n",
        "      <td> 19.924307</td>\n",
        "      <td>...</td>\n",
        "      <td> 1800</td>\n",
        "      <td> 984</td>\n",
        "      <td> 2.238889</td>\n",
        "      <td> 10.531464</td>\n",
        "      <td> 0.955419</td>\n",
        "      <td> 1.071699</td>\n",
        "      <td> 0.928177</td>\n",
        "      <td> 0.714832</td>\n",
        "      <td> 0.482414</td>\n",
        "      <td> 0.248204</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> 20130723_130219</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 20130723_130219</td>\n",
        "      <td> 0.000315</td>\n",
        "      <td>  8.240240</td>\n",
        "      <td> 14.041571</td>\n",
        "      <td> 13.812998</td>\n",
        "      <td> 13.201365</td>\n",
        "      <td> 13.303901</td>\n",
        "      <td> 12.501750</td>\n",
        "      <td>...</td>\n",
        "      <td> 1800</td>\n",
        "      <td> 538</td>\n",
        "      <td> 1.096719</td>\n",
        "      <td>  1.102153</td>\n",
        "      <td> 0.824969</td>\n",
        "      <td> 1.362789</td>\n",
        "      <td> 0.751053</td>\n",
        "      <td> 0.782253</td>\n",
        "      <td> 0.402979</td>\n",
        "      <td> 0.349276</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td> 20130806_151347</td>\n",
        "      <td> 0.394649</td>\n",
        "      <td> 20130806_151347</td>\n",
        "      <td> 0.637711</td>\n",
        "      <td> 10.841517</td>\n",
        "      <td> 14.272258</td>\n",
        "      <td> 14.647308</td>\n",
        "      <td> 20.299157</td>\n",
        "      <td> 19.967809</td>\n",
        "      <td> 17.562845</td>\n",
        "      <td>...</td>\n",
        "      <td> 1800</td>\n",
        "      <td> 299</td>\n",
        "      <td> 3.012660</td>\n",
        "      <td> 16.929414</td>\n",
        "      <td> 3.744780</td>\n",
        "      <td> 2.734815</td>\n",
        "      <td> 1.839470</td>\n",
        "      <td> 0.942758</td>\n",
        "      <td> 1.067422</td>\n",
        "      <td> 1.697256</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> 20130815_122404</td>\n",
        "      <td> 0.081218</td>\n",
        "      <td> 20130815_122404</td>\n",
        "      <td> 0.004736</td>\n",
        "      <td> 12.156745</td>\n",
        "      <td> 21.490401</td>\n",
        "      <td> 21.341664</td>\n",
        "      <td> 24.816555</td>\n",
        "      <td> 24.732294</td>\n",
        "      <td> 21.045329</td>\n",
        "      <td>...</td>\n",
        "      <td> 1800</td>\n",
        "      <td> 394</td>\n",
        "      <td> 2.512292</td>\n",
        "      <td>  3.030361</td>\n",
        "      <td> 1.022130</td>\n",
        "      <td> 0.961997</td>\n",
        "      <td> 0.308357</td>\n",
        "      <td> 0.358482</td>\n",
        "      <td> 0.481998</td>\n",
        "      <td> 0.520895</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> 20130907_122442</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 20130907_122442</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 12.797608</td>\n",
        "      <td> 17.394047</td>\n",
        "      <td> 17.979698</td>\n",
        "      <td> 21.021047</td>\n",
        "      <td> 20.942165</td>\n",
        "      <td> 18.976124</td>\n",
        "      <td>...</td>\n",
        "      <td> 1800</td>\n",
        "      <td> 370</td>\n",
        "      <td> 2.307220</td>\n",
        "      <td>  2.307220</td>\n",
        "      <td> 2.943272</td>\n",
        "      <td> 1.171807</td>\n",
        "      <td> 0.199941</td>\n",
        "      <td> 0.396880</td>\n",
        "      <td> 0.174439</td>\n",
        "      <td> 0.268517</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> 20131011_132432</td>\n",
        "      <td> 0.009346</td>\n",
        "      <td> 20131011_132432</td>\n",
        "      <td> 0.003654</td>\n",
        "      <td>  9.121534</td>\n",
        "      <td> 17.250120</td>\n",
        "      <td> 17.248757</td>\n",
        "      <td> 22.126398</td>\n",
        "      <td> 22.224958</td>\n",
        "      <td> 18.729374</td>\n",
        "      <td>...</td>\n",
        "      <td> 1800</td>\n",
        "      <td> 107</td>\n",
        "      <td> 2.789230</td>\n",
        "      <td>  2.879284</td>\n",
        "      <td> 3.759033</td>\n",
        "      <td> 3.758985</td>\n",
        "      <td> 3.126965</td>\n",
        "      <td> 2.817380</td>\n",
        "      <td> 1.320097</td>\n",
        "      <td> 1.272182</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> 20140912_124317</td>\n",
        "      <td> 1.000000</td>\n",
        "      <td> 20140912_124317</td>\n",
        "      <td> 0.112638</td>\n",
        "      <td> 13.370734</td>\n",
        "      <td> 18.862014</td>\n",
        "      <td> 18.706462</td>\n",
        "      <td> 21.173832</td>\n",
        "      <td> 21.223226</td>\n",
        "      <td> 20.391300</td>\n",
        "      <td>...</td>\n",
        "      <td> 1800</td>\n",
        "      <td> 141</td>\n",
        "      <td> 1.571283</td>\n",
        "      <td>  6.427618</td>\n",
        "      <td> 0.964548</td>\n",
        "      <td> 1.249976</td>\n",
        "      <td> 1.895209</td>\n",
        "      <td> 1.843306</td>\n",
        "      <td> 3.141282</td>\n",
        "      <td> 3.081055</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> 20140903_124321</td>\n",
        "      <td> 0.137143</td>\n",
        "      <td> 20140903_124321</td>\n",
        "      <td> 0.075872</td>\n",
        "      <td> 13.349361</td>\n",
        "      <td> 17.633566</td>\n",
        "      <td> 17.813239</td>\n",
        "      <td> 22.771398</td>\n",
        "      <td> 22.587286</td>\n",
        "      <td> 19.200386</td>\n",
        "      <td>...</td>\n",
        "      <td> 1800</td>\n",
        "      <td> 175</td>\n",
        "      <td> 1.811900</td>\n",
        "      <td> 18.780034</td>\n",
        "      <td> 2.584589</td>\n",
        "      <td> 2.068354</td>\n",
        "      <td> 1.077462</td>\n",
        "      <td> 0.606931</td>\n",
        "      <td> 0.574516</td>\n",
        "      <td> 0.963958</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> 20130707_125944</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 20130707_125944</td>\n",
        "      <td> 0.000726</td>\n",
        "      <td> 16.240305</td>\n",
        "      <td> 16.081327</td>\n",
        "      <td> 16.284573</td>\n",
        "      <td> 19.735683</td>\n",
        "      <td> 20.138280</td>\n",
        "      <td> 17.216631</td>\n",
        "      <td>...</td>\n",
        "      <td> 1800</td>\n",
        "      <td>  72</td>\n",
        "      <td> 2.778226</td>\n",
        "      <td>  2.695804</td>\n",
        "      <td> 1.744562</td>\n",
        "      <td> 1.210647</td>\n",
        "      <td> 1.143442</td>\n",
        "      <td> 1.211192</td>\n",
        "      <td> 0.679509</td>\n",
        "      <td> 0.448763</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> 20150830_130524</td>\n",
        "      <td> 0.884058</td>\n",
        "      <td> 20150830_130524</td>\n",
        "      <td> 1.008893</td>\n",
        "      <td> 12.791701</td>\n",
        "      <td> 20.772211</td>\n",
        "      <td> 20.897431</td>\n",
        "      <td> 26.151010</td>\n",
        "      <td> 26.922423</td>\n",
        "      <td> 25.225320</td>\n",
        "      <td>...</td>\n",
        "      <td> 1800</td>\n",
        "      <td> 621</td>\n",
        "      <td> 2.377355</td>\n",
        "      <td> 14.534009</td>\n",
        "      <td> 5.380581</td>\n",
        "      <td> 5.095698</td>\n",
        "      <td> 0.281223</td>\n",
        "      <td> 1.540328</td>\n",
        "      <td> 1.204997</td>\n",
        "      <td> 1.755678</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> 20151001_123025</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 20151001_123025</td>\n",
        "      <td> 0.000505</td>\n",
        "      <td>  6.299399</td>\n",
        "      <td> 15.146877</td>\n",
        "      <td> 15.019949</td>\n",
        "      <td> 19.571658</td>\n",
        "      <td> 19.607425</td>\n",
        "      <td> 13.340031</td>\n",
        "      <td>...</td>\n",
        "      <td> 1800</td>\n",
        "      <td> 253</td>\n",
        "      <td> 2.154309</td>\n",
        "      <td>  4.987713</td>\n",
        "      <td> 0.828412</td>\n",
        "      <td> 0.861696</td>\n",
        "      <td> 0.670045</td>\n",
        "      <td> 0.650354</td>\n",
        "      <td> 0.215079</td>\n",
        "      <td> 0.219046</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> 20150830_130524</td>\n",
        "      <td> 0.879675</td>\n",
        "      <td> 20150830_130524</td>\n",
        "      <td> 0.980457</td>\n",
        "      <td> 12.869213</td>\n",
        "      <td> 20.678834</td>\n",
        "      <td> 20.798840</td>\n",
        "      <td> 26.194615</td>\n",
        "      <td> 26.932535</td>\n",
        "      <td> 25.235992</td>\n",
        "      <td>...</td>\n",
        "      <td> 1800</td>\n",
        "      <td> 615</td>\n",
        "      <td> 2.410932</td>\n",
        "      <td> 14.700964</td>\n",
        "      <td> 5.347136</td>\n",
        "      <td> 5.122811</td>\n",
        "      <td> 0.339845</td>\n",
        "      <td> 1.534720</td>\n",
        "      <td> 1.198060</td>\n",
        "      <td> 1.760999</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>13 rows \u00d7 31 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "         Unnamed: 0  DFraction            FDate        RR       Reff  \\\n",
        "0   20130614_133658   0.000000  20130614_133658  0.001087   9.403660   \n",
        "1   20130628_130139   0.858740  20130628_130139  0.416804  14.326045   \n",
        "2   20130723_130219   0.000000  20130723_130219  0.000315   8.240240   \n",
        "3   20130806_151347   0.394649  20130806_151347  0.637711  10.841517   \n",
        "4   20130815_122404   0.081218  20130815_122404  0.004736  12.156745   \n",
        "5   20130907_122442   0.000000  20130907_122442  0.000000  12.797608   \n",
        "6   20131011_132432   0.009346  20131011_132432  0.003654   9.121534   \n",
        "7   20140912_124317   1.000000  20140912_124317  0.112638  13.370734   \n",
        "8   20140903_124321   0.137143  20140903_124321  0.075872  13.349361   \n",
        "9   20130707_125944   0.000000  20130707_125944  0.000726  16.240305   \n",
        "10  20150830_130524   0.884058  20150830_130524  1.008893  12.791701   \n",
        "11  20151001_123025   0.000000  20151001_123025  0.000505   6.299399   \n",
        "12  20150830_130524   0.879675  20150830_130524  0.980457  12.869213   \n",
        "\n",
        "      Reff_16  Reff_16_MG    Reff_21  Reff_21_MG    Reff_37    ...      \\\n",
        "0   15.866180   15.423497  19.114405   18.627216  16.595825    ...       \n",
        "1   16.269451   16.456296  24.325519   23.519631  19.924307    ...       \n",
        "2   14.041571   13.812998  13.201365   13.303901  12.501750    ...       \n",
        "3   14.272258   14.647308  20.299157   19.967809  17.562845    ...       \n",
        "4   21.490401   21.341664  24.816555   24.732294  21.045329    ...       \n",
        "5   17.394047   17.979698  21.021047   20.942165  18.976124    ...       \n",
        "6   17.250120   17.248757  22.126398   22.224958  18.729374    ...       \n",
        "7   18.862014   18.706462  21.173832   21.223226  20.391300    ...       \n",
        "8   17.633566   17.813239  22.771398   22.587286  19.200386    ...       \n",
        "9   16.081327   16.284573  19.735683   20.138280  17.216631    ...       \n",
        "10  20.772211   20.897431  26.151010   26.922423  25.225320    ...       \n",
        "11  15.146877   15.019949  19.571658   19.607425  13.340031    ...       \n",
        "12  20.678834   20.798840  26.194615   26.932535  25.235992    ...       \n",
        "\n",
        "    len_df  len_df_clouds  std_Reff  std_ReffT std_Reff_16  std_Reff_16_MG  \\\n",
        "0     1800            382  1.469366   1.541616    1.151517        0.325904   \n",
        "1     1800            984  2.238889  10.531464    0.955419        1.071699   \n",
        "2     1800            538  1.096719   1.102153    0.824969        1.362789   \n",
        "3     1800            299  3.012660  16.929414    3.744780        2.734815   \n",
        "4     1800            394  2.512292   3.030361    1.022130        0.961997   \n",
        "5     1800            370  2.307220   2.307220    2.943272        1.171807   \n",
        "6     1800            107  2.789230   2.879284    3.759033        3.758985   \n",
        "7     1800            141  1.571283   6.427618    0.964548        1.249976   \n",
        "8     1800            175  1.811900  18.780034    2.584589        2.068354   \n",
        "9     1800             72  2.778226   2.695804    1.744562        1.210647   \n",
        "10    1800            621  2.377355  14.534009    5.380581        5.095698   \n",
        "11    1800            253  2.154309   4.987713    0.828412        0.861696   \n",
        "12    1800            615  2.410932  14.700964    5.347136        5.122811   \n",
        "\n",
        "    std_Reff_21  std_Reff_21_MG  std_Reff_37  std_Reff_37_MG  \n",
        "0      0.757555        0.255367     0.131673        0.296087  \n",
        "1      0.928177        0.714832     0.482414        0.248204  \n",
        "2      0.751053        0.782253     0.402979        0.349276  \n",
        "3      1.839470        0.942758     1.067422        1.697256  \n",
        "4      0.308357        0.358482     0.481998        0.520895  \n",
        "5      0.199941        0.396880     0.174439        0.268517  \n",
        "6      3.126965        2.817380     1.320097        1.272182  \n",
        "7      1.895209        1.843306     3.141282        3.081055  \n",
        "8      1.077462        0.606931     0.574516        0.963958  \n",
        "9      1.143442        1.211192     0.679509        0.448763  \n",
        "10     0.281223        1.540328     1.204997        1.755678  \n",
        "11     0.670045        0.650354     0.215079        0.219046  \n",
        "12     0.339845        1.534720     1.198060        1.760999  \n",
        "\n",
        "[13 rows x 31 columns]"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "pd.set_option('display.max_columns', None)\n",
      "pd.set_option('display.max_rows', None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    }
   ],
   "metadata": {}
  }
 ]
}